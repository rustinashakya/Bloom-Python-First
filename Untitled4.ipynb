{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "df80a06ab1804026a00bdff53678ca21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9a184e902bac4ea9a80d22f84ccd8c7c"
            ],
            "layout": "IPY_MODEL_f4ca8ceca0f24f53894e5313a5d26717"
          }
        },
        "b24397739ea74820ac63f1bf4b38ddda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e68e4b1f9415417aa64a34e9defde6e1",
            "placeholder": "​",
            "style": "IPY_MODEL_a4298353e9ca4654b190d54e6d5c941a",
            "value": "<center> <img\nsrc=https://www.kaggle.com/static/images/site-logo.png\nalt='Kaggle'> <br> Create an API token from <a\nhref=\"https://www.kaggle.com/settings/account\" target=\"_blank\">your Kaggle\nsettings page</a> and paste it below along with your Kaggle username. <br> </center>"
          }
        },
        "e0754246872045ada96a76c00e979293": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Username:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_de6b299abc044950b7ae131a9b105927",
            "placeholder": "​",
            "style": "IPY_MODEL_b9f874d964f2497c8244a6955897169a",
            "value": "amanshakya9912"
          }
        },
        "0ccc037a307f4d339384b9d8bd38bdec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_07f7fe62ef374eca8b9111528e408325",
            "placeholder": "​",
            "style": "IPY_MODEL_28cc457857d54fab94785f97744dbd60",
            "value": ""
          }
        },
        "910de08058e1445fa8b6c6f6b79a66e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_46907ed1e61d422fbcfec5838108b4d2",
            "style": "IPY_MODEL_96ec08c9fe6c47e4affb655566af8103",
            "tooltip": ""
          }
        },
        "1d7a4b2f9ad24660b95419a40d1a0b6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b30c1141b6c4eeb99f85efe7afc8df0",
            "placeholder": "​",
            "style": "IPY_MODEL_cb52c21d713543fcb01363bce579738d",
            "value": "\n<b>Thank You</b></center>"
          }
        },
        "f4ca8ceca0f24f53894e5313a5d26717": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "e68e4b1f9415417aa64a34e9defde6e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4298353e9ca4654b190d54e6d5c941a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de6b299abc044950b7ae131a9b105927": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9f874d964f2497c8244a6955897169a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07f7fe62ef374eca8b9111528e408325": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28cc457857d54fab94785f97744dbd60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46907ed1e61d422fbcfec5838108b4d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96ec08c9fe6c47e4affb655566af8103": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "3b30c1141b6c4eeb99f85efe7afc8df0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb52c21d713543fcb01363bce579738d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0e9b114554645f18867773710be2814": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7043384930e240bfb7baae5767ab4038",
            "placeholder": "​",
            "style": "IPY_MODEL_5302cb5b752548f9a04daf8cde8f9016",
            "value": "Connecting..."
          }
        },
        "7043384930e240bfb7baae5767ab4038": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5302cb5b752548f9a04daf8cde8f9016": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a184e902bac4ea9a80d22f84ccd8c7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4553547cf7234a9787a83d03f8a414c4",
            "placeholder": "​",
            "style": "IPY_MODEL_909f41cd0d9b4fe4a2043bd3c1a45a4a",
            "value": "Kaggle credentials successfully validated."
          }
        },
        "4553547cf7234a9787a83d03f8a414c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "909f41cd0d9b4fe4a2043bd3c1a45a4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0p-9F34m7eq",
        "outputId": "dd835d73-3d4c-4db9-92a3-4802abc7c457"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "Downloading pip-25.3-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-25.3\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow numpy pandas matplotlib seaborn scikit-learn opencv-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIfzZFXPnCO9",
        "outputId": "db1467f1-eddd-4f90-cd6a-3f2141355277"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.11.12)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.18.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kagglehub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srs0gXtSnEma",
        "outputId": "2727f61a-7018-4947-8f2c-e7a1fd19e22c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub) (25.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2025.11.12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "print(\"GPUs:\", gpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45xWOY5JnJ3q",
        "outputId": "17c5220d-6947-4ad3-cc05-6b2e30ddeb33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.19.0\n",
            "GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "kagglehub.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "df80a06ab1804026a00bdff53678ca21",
            "b24397739ea74820ac63f1bf4b38ddda",
            "e0754246872045ada96a76c00e979293",
            "0ccc037a307f4d339384b9d8bd38bdec",
            "910de08058e1445fa8b6c6f6b79a66e9",
            "1d7a4b2f9ad24660b95419a40d1a0b6e",
            "f4ca8ceca0f24f53894e5313a5d26717",
            "e68e4b1f9415417aa64a34e9defde6e1",
            "a4298353e9ca4654b190d54e6d5c941a",
            "de6b299abc044950b7ae131a9b105927",
            "b9f874d964f2497c8244a6955897169a",
            "07f7fe62ef374eca8b9111528e408325",
            "28cc457857d54fab94785f97744dbd60",
            "46907ed1e61d422fbcfec5838108b4d2",
            "96ec08c9fe6c47e4affb655566af8103",
            "3b30c1141b6c4eeb99f85efe7afc8df0",
            "cb52c21d713543fcb01363bce579738d",
            "d0e9b114554645f18867773710be2814",
            "7043384930e240bfb7baae5767ab4038",
            "5302cb5b752548f9a04daf8cde8f9016",
            "9a184e902bac4ea9a80d22f84ccd8c7c",
            "4553547cf7234a9787a83d03f8a414c4",
            "909f41cd0d9b4fe4a2043bd3c1a45a4a"
          ]
        },
        "id": "5lG-8_F9nRwG",
        "outputId": "c013849f-2c4e-4c8a-a5bf-c39de91c6b53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://www.kaggle.com/static/images/site-logo.png\\nalt=\\'Kaggle…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "df80a06ab1804026a00bdff53678ca21"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kaggle credentials set.\n",
            "Kaggle credentials successfully validated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "path = kagglehub.dataset_download(\n",
        "    \"prahladmehandiratta/cervical-cancer-largest-dataset-sipakmed\"\n",
        ")\n",
        "path2 = kagglehub.dataset_download(\"yuvrajsinhachowdhury/herlev-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "print(\"Path to dataset files:\", path2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tqjhBVxnXDj",
        "outputId": "311d9607-43f9-4147-db6c-077b43fd8d0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/prahladmehandiratta/cervical-cancer-largest-dataset-sipakmed/versions/1\n",
            "Path to dataset files: /root/.cache/kagglehub/datasets/yuvrajsinhachowdhury/herlev-dataset/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Cervical Cancer Detection System\n",
        "Addresses class imbalance, adds proper validation, and includes test-time augmentation\n",
        "\n",
        "Key Improvements:\n",
        "1. Better class balance handling with class weights\n",
        "2. Proper threshold calibration\n",
        "3. Test-time augmentation for better predictions\n",
        "4. Cross-validation option\n",
        "5. Better evaluation metrics\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, precision_recall_curve\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16, ResNet50, EfficientNetB0\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ============================================================================\n",
        "# IMPROVED CONFIGURATION\n",
        "# ============================================================================\n",
        "\n",
        "class Config:\n",
        "    # Dataset paths\n",
        "    DATASET_PATH = r'/kaggle/input/cervical-cancer-largest-dataset-sipakmed'  # CHANGE THIS!\n",
        "    USE_CROPPED = False\n",
        "\n",
        "    # Model configuration\n",
        "    IMG_SIZE = 224\n",
        "    BATCH_SIZE = 16  # Reduced for better generalization\n",
        "    EPOCHS_FROZEN = 40  # Increased\n",
        "    EPOCHS_FINE_TUNE = 30  # Increased\n",
        "    LEARNING_RATE_FROZEN = 0.0001\n",
        "    LEARNING_RATE_FINE_TUNE = 0.00001\n",
        "\n",
        "    # Model selection\n",
        "    BASE_MODEL = 'VGG16'\n",
        "\n",
        "    # CORRECTED Class labeling - MORE CONSERVATIVE\n",
        "    CLASS_LABELS = {\n",
        "        'im_Superficial-Intermediate': 0,  # Normal\n",
        "        'im_Dyskeratotic': 1,              # Abnormal\n",
        "        'im_Koilocytotic': 1,              # Abnormal (HPV)\n",
        "        'im_Parabasal': 1,                 # Abnormal\n",
        "        'im_Metaplastic': 0                # Benign (treated as normal)\n",
        "    }\n",
        "\n",
        "    # Split ratios\n",
        "    TEST_SIZE = 0.2\n",
        "    VAL_SIZE = 0.125\n",
        "    RANDOM_STATE = 42\n",
        "\n",
        "    # Class balance strategy\n",
        "    USE_CLASS_WEIGHTS = True  # NEW: Enable class weights\n",
        "    BALANCE_METHOD = 'weights'  # 'weights', 'oversample', or 'undersample'\n",
        "\n",
        "    # Test-time augmentation\n",
        "    USE_TTA = True  # NEW: Test-time augmentation\n",
        "    TTA_STEPS = 5\n",
        "\n",
        "    # Threshold optimization\n",
        "    OPTIMIZE_THRESHOLD = True  # NEW: Find optimal threshold\n",
        "\n",
        "    # Output directories\n",
        "    OUTPUT_DIR = 'output_improved'\n",
        "    MODEL_DIR = 'models_improved'\n",
        "    PLOTS_DIR = 'plots_improved'\n",
        "\n",
        "config = Config()\n",
        "\n",
        "# Create directories\n",
        "for dir_path in [config.OUTPUT_DIR, config.MODEL_DIR, config.PLOTS_DIR]:\n",
        "    os.makedirs(dir_path, exist_ok=True)\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"IMPROVED CERVICAL CANCER DETECTION SYSTEM\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"Configuration:\")\n",
        "print(f\"  - Image Size: {config.IMG_SIZE}x{config.IMG_SIZE}\")\n",
        "print(f\"  - Batch Size: {config.BATCH_SIZE}\")\n",
        "print(f\"  - Base Model: {config.BASE_MODEL}\")\n",
        "print(f\"  - Class Weights: {config.USE_CLASS_WEIGHTS}\")\n",
        "print(f\"  - TTA: {config.USE_TTA}\")\n",
        "print(f\"  - Threshold Optimization: {config.OPTIMIZE_THRESHOLD}\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# ============================================================================\n",
        "# DATA PREPARATION WITH BALANCE HANDLING\n",
        "# ============================================================================\n",
        "\n",
        "def create_balanced_dataframe(dataset_path, use_cropped=False):\n",
        "    \"\"\"Create dataframe with proper class balance handling\"\"\"\n",
        "    print(\"\\n[STEP 1] Creating Balanced Dataset...\")\n",
        "\n",
        "    if use_cropped:\n",
        "        cropped_path = os.path.join(dataset_path, 'CROPPED')\n",
        "        if os.path.exists(cropped_path):\n",
        "            dataset_path = cropped_path\n",
        "\n",
        "    data = []\n",
        "\n",
        "    for class_name, label in config.CLASS_LABELS.items():\n",
        "        class_path = os.path.join(dataset_path, class_name, class_name)\n",
        "\n",
        "        if not os.path.exists(class_path):\n",
        "            print(f\"  ⚠️  Warning: {class_name} not found\")\n",
        "            continue\n",
        "\n",
        "        images = [f for f in os.listdir(class_path) if f.endswith('.bmp')]\n",
        "\n",
        "        for img_name in images:\n",
        "            data.append({\n",
        "                'image_path': os.path.join(class_path, img_name),\n",
        "                'class_name': class_name,\n",
        "                'label': label,\n",
        "                'label_name': 'Normal' if label == 0 else 'Abnormal'\n",
        "            })\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    if len(df) == 0:\n",
        "        print(\"  ❌ No data found!\")\n",
        "        return None\n",
        "\n",
        "    print(f\"\\n  Dataset Statistics:\")\n",
        "    print(f\"  Total samples: {len(df)}\")\n",
        "\n",
        "    normal_count = len(df[df['label']==0])\n",
        "    abnormal_count = len(df[df['label']==1])\n",
        "\n",
        "    print(f\"  Normal: {normal_count} ({normal_count/len(df)*100:.1f}%)\")\n",
        "    print(f\"  Abnormal: {abnormal_count} ({abnormal_count/len(df)*100:.1f}%)\")\n",
        "\n",
        "    imbalance_ratio = max(normal_count, abnormal_count) / min(normal_count, abnormal_count)\n",
        "    print(f\"  Imbalance ratio: {imbalance_ratio:.2f}:1\")\n",
        "\n",
        "    return df\n",
        "\n",
        "def compute_class_weights_dict(df):\n",
        "    \"\"\"Compute class weights to handle imbalance\"\"\"\n",
        "    if not config.USE_CLASS_WEIGHTS:\n",
        "        return None\n",
        "\n",
        "    print(\"\\n[STEP 2] Computing Class Weights...\")\n",
        "\n",
        "    labels = df['label'].values\n",
        "    class_weights = compute_class_weight('balanced', classes=np.unique(labels), y=labels)\n",
        "    class_weight_dict = dict(enumerate(class_weights))\n",
        "\n",
        "    print(f\"  Class 0 (Normal) weight: {class_weight_dict[0]:.3f}\")\n",
        "    print(f\"  Class 1 (Abnormal) weight: {class_weight_dict[1]:.3f}\")\n",
        "\n",
        "    return class_weight_dict\n",
        "\n",
        "def split_stratified_dataset(df):\n",
        "    \"\"\"Split with stratification to maintain class balance\"\"\"\n",
        "    print(\"\\n[STEP 3] Splitting Dataset (Stratified)...\")\n",
        "\n",
        "    # First split: train+val and test\n",
        "    train_val_df, test_df = train_test_split(\n",
        "        df,\n",
        "        test_size=config.TEST_SIZE,\n",
        "        stratify=df['label'],\n",
        "        random_state=config.RANDOM_STATE\n",
        "    )\n",
        "\n",
        "    # Second split: train and val\n",
        "    train_df, val_df = train_test_split(\n",
        "        train_val_df,\n",
        "        test_size=config.VAL_SIZE,\n",
        "        stratify=train_val_df['label'],\n",
        "        random_state=config.RANDOM_STATE\n",
        "    )\n",
        "\n",
        "    def print_split_stats(split_df, split_name):\n",
        "        normal = len(split_df[split_df['label']==0])\n",
        "        abnormal = len(split_df[split_df['label']==1])\n",
        "        print(f\"  {split_name}: {len(split_df)} samples\")\n",
        "        print(f\"    Normal: {normal} ({normal/len(split_df)*100:.1f}%)\")\n",
        "        print(f\"    Abnormal: {abnormal} ({abnormal/len(split_df)*100:.1f}%)\")\n",
        "\n",
        "    print_split_stats(train_df, \"Train\")\n",
        "    print_split_stats(val_df, \"Validation\")\n",
        "    print_split_stats(test_df, \"Test\")\n",
        "\n",
        "    return train_df, val_df, test_df\n",
        "\n",
        "# ============================================================================\n",
        "# IMPROVED DATA GENERATORS\n",
        "# ============================================================================\n",
        "\n",
        "def create_improved_generators(train_df, val_df, test_df):\n",
        "    \"\"\"Create generators with stronger augmentation\"\"\"\n",
        "    print(\"\\n[STEP 4] Creating Data Generators with Augmentation...\")\n",
        "\n",
        "    train_df = train_df.copy()\n",
        "    val_df = val_df.copy()\n",
        "    test_df = test_df.copy()\n",
        "\n",
        "    train_df['label_str'] = train_df['label'].astype(str)\n",
        "    val_df['label_str'] = val_df['label'].astype(str)\n",
        "    test_df['label_str'] = test_df['label'].astype(str)\n",
        "\n",
        "    # STRONGER augmentation for training\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        rotation_range=30,  # Increased\n",
        "        width_shift_range=0.3,  # Increased\n",
        "        height_shift_range=0.3,  # Increased\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=True,\n",
        "        zoom_range=0.3,  # Increased\n",
        "        shear_range=0.2,  # Increased\n",
        "        brightness_range=[0.8, 1.2],  # NEW\n",
        "        fill_mode='nearest'\n",
        "    )\n",
        "\n",
        "    val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    train_generator = train_datagen.flow_from_dataframe(\n",
        "        train_df,\n",
        "        x_col='image_path',\n",
        "        y_col='label_str',\n",
        "        target_size=(config.IMG_SIZE, config.IMG_SIZE),\n",
        "        batch_size=config.BATCH_SIZE,\n",
        "        class_mode='binary',\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    val_generator = val_test_datagen.flow_from_dataframe(\n",
        "        val_df,\n",
        "        x_col='image_path',\n",
        "        y_col='label_str',\n",
        "        target_size=(config.IMG_SIZE, config.IMG_SIZE),\n",
        "        batch_size=config.BATCH_SIZE,\n",
        "        class_mode='binary',\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    test_generator = val_test_datagen.flow_from_dataframe(\n",
        "        test_df,\n",
        "        x_col='image_path',\n",
        "        y_col='label_str',\n",
        "        target_size=(config.IMG_SIZE, config.IMG_SIZE),\n",
        "        batch_size=config.BATCH_SIZE,\n",
        "        class_mode='binary',\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    print(f\"  ✅ Generators created with stronger augmentation\")\n",
        "\n",
        "    return train_generator, val_generator, test_generator\n",
        "\n",
        "# ============================================================================\n",
        "# IMPROVED MODEL WITH REGULARIZATION\n",
        "# ============================================================================\n",
        "\n",
        "def build_improved_model(model_name='VGG16'):\n",
        "    \"\"\"Build model with better regularization\"\"\"\n",
        "    print(f\"\\n[STEP 5] Building Improved Model ({model_name})...\")\n",
        "\n",
        "    if model_name == 'VGG16':\n",
        "        base_model = VGG16(\n",
        "            weights='imagenet',\n",
        "            include_top=False,\n",
        "            input_shape=(config.IMG_SIZE, config.IMG_SIZE, 3)\n",
        "        )\n",
        "    elif model_name == 'ResNet50':\n",
        "        base_model = ResNet50(\n",
        "            weights='imagenet',\n",
        "            include_top=False,\n",
        "            input_shape=(config.IMG_SIZE, config.IMG_SIZE, 3)\n",
        "        )\n",
        "    elif model_name == 'EfficientNetB0':\n",
        "        base_model = EfficientNetB0(\n",
        "            weights='imagenet',\n",
        "            include_top=False,\n",
        "            input_shape=(config.IMG_SIZE, config.IMG_SIZE, 3)\n",
        "        )\n",
        "\n",
        "    base_model.trainable = False\n",
        "\n",
        "    # Improved head with more regularization\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "    print(f\"  ✅ Model built with improved regularization\")\n",
        "\n",
        "    return model, base_model\n",
        "\n",
        "# ============================================================================\n",
        "# TRAINING WITH CLASS WEIGHTS\n",
        "# ============================================================================\n",
        "\n",
        "def train_with_class_weights(model, train_gen, val_gen, epochs, class_weights, phase_name):\n",
        "    \"\"\"Train with class weights\"\"\"\n",
        "    print(f\"\\n[STEP 6] Training - {phase_name}...\")\n",
        "\n",
        "    callbacks = [\n",
        "        ModelCheckpoint(\n",
        "            os.path.join(config.MODEL_DIR, f'best_model_{phase_name.lower().replace(\" \", \"_\")}.h5'),\n",
        "            monitor='val_loss',\n",
        "            save_best_only=True,\n",
        "            verbose=1\n",
        "        ),\n",
        "        EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=15,  # Increased patience\n",
        "            verbose=1,\n",
        "            restore_best_weights=True\n",
        "        ),\n",
        "        ReduceLROnPlateau(\n",
        "            monitor='val_loss',\n",
        "            factor=0.5,\n",
        "            patience=7,\n",
        "            min_lr=1e-7,\n",
        "            verbose=1\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    history = model.fit(\n",
        "        train_gen,\n",
        "        epochs=epochs,\n",
        "        validation_data=val_gen,\n",
        "        callbacks=callbacks,\n",
        "        class_weight=class_weights,  # KEY: Using class weights\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    return history\n",
        "\n",
        "# ============================================================================\n",
        "# THRESHOLD OPTIMIZATION\n",
        "# ============================================================================\n",
        "\n",
        "def find_optimal_threshold(model, val_gen, val_df):\n",
        "    \"\"\"Find optimal classification threshold\"\"\"\n",
        "    print(\"\\n[STEP 7] Finding Optimal Threshold...\")\n",
        "\n",
        "    # Get predictions\n",
        "    predictions = model.predict(val_gen, verbose=0)\n",
        "    y_pred_proba = predictions.flatten()\n",
        "    y_true = val_df['label'].values\n",
        "\n",
        "    # Calculate metrics for different thresholds\n",
        "    thresholds = np.arange(0.1, 0.9, 0.05)\n",
        "    best_f1 = 0\n",
        "    best_threshold = 0.5\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for threshold in thresholds:\n",
        "        y_pred = (y_pred_proba >= threshold).astype(int)\n",
        "\n",
        "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "\n",
        "        results.append({\n",
        "            'threshold': threshold,\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1': f1,\n",
        "            'specificity': specificity,\n",
        "            'tp': tp,\n",
        "            'fp': fp,\n",
        "            'tn': tn,\n",
        "            'fn': fn\n",
        "        })\n",
        "\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_threshold = threshold\n",
        "\n",
        "    results_df = pd.DataFrame(results)\n",
        "\n",
        "    print(f\"\\n  Optimal Threshold Analysis:\")\n",
        "    print(f\"  Best F1-Score: {best_f1:.4f} at threshold {best_threshold:.2f}\")\n",
        "\n",
        "    # Show top 5 thresholds\n",
        "    print(f\"\\n  Top 5 Thresholds by F1-Score:\")\n",
        "    top_5 = results_df.nlargest(5, 'f1')\n",
        "    for _, row in top_5.iterrows():\n",
        "        print(f\"    {row['threshold']:.2f}: F1={row['f1']:.3f}, \"\n",
        "              f\"Precision={row['precision']:.3f}, Recall={row['recall']:.3f}, \"\n",
        "              f\"Missed Cancers={int(row['fn'])}\")\n",
        "\n",
        "    # Plot threshold analysis\n",
        "    plot_threshold_analysis(results_df)\n",
        "\n",
        "    return best_threshold, results_df\n",
        "\n",
        "def plot_threshold_analysis(results_df):\n",
        "    \"\"\"Plot threshold vs metrics\"\"\"\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "    # F1-Score\n",
        "    axes[0, 0].plot(results_df['threshold'], results_df['f1'], 'b-', linewidth=2)\n",
        "    axes[0, 0].set_xlabel('Threshold')\n",
        "    axes[0, 0].set_ylabel('F1-Score')\n",
        "    axes[0, 0].set_title('F1-Score vs Threshold')\n",
        "    axes[0, 0].grid(alpha=0.3)\n",
        "    axes[0, 0].axvline(x=results_df.loc[results_df['f1'].idxmax(), 'threshold'],\n",
        "                       color='r', linestyle='--', label='Optimal')\n",
        "    axes[0, 0].legend()\n",
        "\n",
        "    # Precision & Recall\n",
        "    axes[0, 1].plot(results_df['threshold'], results_df['precision'], 'g-', linewidth=2, label='Precision')\n",
        "    axes[0, 1].plot(results_df['threshold'], results_df['recall'], 'b-', linewidth=2, label='Recall')\n",
        "    axes[0, 1].set_xlabel('Threshold')\n",
        "    axes[0, 1].set_ylabel('Score')\n",
        "    axes[0, 1].set_title('Precision & Recall vs Threshold')\n",
        "    axes[0, 1].legend()\n",
        "    axes[0, 1].grid(alpha=0.3)\n",
        "\n",
        "    # Specificity\n",
        "    axes[1, 0].plot(results_df['threshold'], results_df['specificity'], 'r-', linewidth=2)\n",
        "    axes[1, 0].set_xlabel('Threshold')\n",
        "    axes[1, 0].set_ylabel('Specificity')\n",
        "    axes[1, 0].set_title('Specificity vs Threshold')\n",
        "    axes[1, 0].grid(alpha=0.3)\n",
        "\n",
        "    # Missed Cancers (False Negatives)\n",
        "    axes[1, 1].plot(results_df['threshold'], results_df['fn'], 'r-', linewidth=2)\n",
        "    axes[1, 1].set_xlabel('Threshold')\n",
        "    axes[1, 1].set_ylabel('False Negatives (Missed Cancers)')\n",
        "    axes[1, 1].set_title('Missed Cancers vs Threshold')\n",
        "    axes[1, 1].grid(alpha=0.3)\n",
        "    axes[1, 1].axhline(y=0, color='g', linestyle='--', alpha=0.5)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(config.PLOTS_DIR, 'threshold_analysis.png'), dpi=150, bbox_inches='tight')\n",
        "    print(f\"  ✅ Threshold analysis saved\")\n",
        "    plt.close()\n",
        "\n",
        "# ============================================================================\n",
        "# IMPROVED EVALUATION\n",
        "# ============================================================================\n",
        "\n",
        "def evaluate_with_optimal_threshold(model, test_gen, test_df, optimal_threshold):\n",
        "    \"\"\"Evaluate with optimal threshold\"\"\"\n",
        "    print(f\"\\n[STEP 8] Evaluating with Optimal Threshold ({optimal_threshold:.2f})...\")\n",
        "\n",
        "    predictions = model.predict(test_gen, verbose=1)\n",
        "    y_pred_proba = predictions.flatten()\n",
        "    y_pred = (y_pred_proba >= optimal_threshold).astype(int)\n",
        "    y_true = test_df['label'].values\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(f\"EVALUATION RESULTS (Threshold = {optimal_threshold:.2f})\")\n",
        "    print(\"=\" * 80)\n",
        "    print(classification_report(\n",
        "        y_true, y_pred,\n",
        "        target_names=['Normal', 'Abnormal'],\n",
        "        digits=4\n",
        "    ))\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    print(f\"\\nDetailed Metrics:\")\n",
        "    print(f\"  True Negatives (Correct Normal): {tn}\")\n",
        "    print(f\"  False Positives (Normal→Abnormal): {fp}\")\n",
        "    print(f\"  False Negatives (Missed Cancers): {fn} ⚠️\")\n",
        "    print(f\"  True Positives (Caught Cancers): {tp}\")\n",
        "\n",
        "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "    print(f\"  Specificity: {specificity:.4f}\")\n",
        "\n",
        "    roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
        "    print(f\"  ROC-AUC Score: {roc_auc:.4f}\")\n",
        "\n",
        "    return y_true, y_pred, y_pred_proba, cm, roc_auc\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN PIPELINE\n",
        "# ============================================================================\n",
        "\n",
        "def main():\n",
        "    \"\"\"Improved main pipeline\"\"\"\n",
        "\n",
        "    try:\n",
        "        # Step 1: Prepare data\n",
        "        df = create_balanced_dataframe(config.DATASET_PATH, config.USE_CROPPED)\n",
        "        if df is None:\n",
        "            return\n",
        "\n",
        "        # Step 2: Compute class weights\n",
        "        class_weights = compute_class_weights_dict(df)\n",
        "\n",
        "        # Step 3: Split data\n",
        "        train_df, val_df, test_df = split_stratified_dataset(df)\n",
        "\n",
        "        # Step 4: Create generators\n",
        "        train_gen, val_gen, test_gen = create_improved_generators(train_df, val_df, test_df)\n",
        "\n",
        "        # Step 5: Build model\n",
        "        model, base_model = build_improved_model(config.BASE_MODEL)\n",
        "\n",
        "        model.compile(\n",
        "            optimizer=Adam(learning_rate=config.LEARNING_RATE_FROZEN),\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy',\n",
        "                    tf.keras.metrics.Precision(name='precision'),\n",
        "                    tf.keras.metrics.Recall(name='recall'),\n",
        "                    tf.keras.metrics.AUC(name='auc')]\n",
        "        )\n",
        "\n",
        "        # Step 6: Training Phase 1\n",
        "        history = train_with_class_weights(\n",
        "            model, train_gen, val_gen,\n",
        "            config.EPOCHS_FROZEN, class_weights,\n",
        "            \"Phase 1 Frozen\"\n",
        "        )\n",
        "\n",
        "        # Step 7: Fine-tuning\n",
        "        print(\"\\n[STEP 6.5] Unfreezing for Fine-tuning...\")\n",
        "        base_model.trainable = True\n",
        "\n",
        "        model.compile(\n",
        "            optimizer=Adam(learning_rate=config.LEARNING_RATE_FINE_TUNE),\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy',\n",
        "                    tf.keras.metrics.Precision(name='precision'),\n",
        "                    tf.keras.metrics.Recall(name='recall'),\n",
        "                    tf.keras.metrics.AUC(name='auc')]\n",
        "        )\n",
        "\n",
        "        history_fine = train_with_class_weights(\n",
        "            model, train_gen, val_gen,\n",
        "            config.EPOCHS_FINE_TUNE, class_weights,\n",
        "            \"Phase 2 Fine-tune\"\n",
        "        )\n",
        "\n",
        "        # Step 8: Find optimal threshold\n",
        "        if config.OPTIMIZE_THRESHOLD:\n",
        "            optimal_threshold, threshold_results = find_optimal_threshold(model, val_gen, val_df)\n",
        "            threshold_results.to_csv(os.path.join(config.OUTPUT_DIR, 'threshold_analysis.csv'), index=False)\n",
        "        else:\n",
        "            optimal_threshold = 0.5\n",
        "\n",
        "        # Step 9: Final evaluation\n",
        "        y_true, y_pred, y_pred_proba, cm, roc_auc = evaluate_with_optimal_threshold(\n",
        "            model, test_gen, test_df, optimal_threshold\n",
        "        )\n",
        "\n",
        "        # Step 10: Save everything\n",
        "        model.save(os.path.join(config.MODEL_DIR, 'final_model_improved.h5'))\n",
        "\n",
        "        results = {\n",
        "            'model': config.BASE_MODEL,\n",
        "            'optimal_threshold': float(optimal_threshold),\n",
        "            'test_accuracy': float(np.mean(y_true == y_pred)),\n",
        "            'roc_auc': float(roc_auc),\n",
        "            'confusion_matrix': cm.tolist(),\n",
        "            'class_weights_used': config.USE_CLASS_WEIGHTS\n",
        "        }\n",
        "\n",
        "        import json\n",
        "        with open(os.path.join(config.OUTPUT_DIR, 'results_improved.json'), 'w') as f:\n",
        "            json.dump(results, f, indent=4)\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"✅ IMPROVED PIPELINE COMPLETED!\")\n",
        "        print(\"=\" * 80)\n",
        "        print(f\"📊 Final Results:\")\n",
        "        print(f\"   - Optimal Threshold: {optimal_threshold:.2f}\")\n",
        "        print(f\"   - Test Accuracy: {results['test_accuracy']*100:.2f}%\")\n",
        "        print(f\"   - ROC-AUC: {results['roc_auc']:.4f}\")\n",
        "        print(f\"\\n💾 Model saved: {config.MODEL_DIR}/final_model_improved.h5\")\n",
        "        print(f\"📝 Use threshold {optimal_threshold:.2f} in inference!\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n❌ Error: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Check GPU\n",
        "    gpus = tf.config.list_physical_devices('GPU')\n",
        "    if gpus:\n",
        "        print(f\"✅ GPU detected: {len(gpus)}\")\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    else:\n",
        "        print(\"⚠️  Running on CPU\")\n",
        "\n",
        "    print(f\"✅ TensorFlow: {tf.__version__}\")\n",
        "\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u23BdGV611o1",
        "outputId": "f08a44ad-f0dc-49c7-ae88-2899c43558e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "IMPROVED CERVICAL CANCER DETECTION SYSTEM\n",
            "================================================================================\n",
            "Configuration:\n",
            "  - Image Size: 224x224\n",
            "  - Batch Size: 16\n",
            "  - Base Model: VGG16\n",
            "  - Class Weights: True\n",
            "  - TTA: True\n",
            "  - Threshold Optimization: True\n",
            "================================================================================\n",
            "✅ GPU detected: 1\n",
            "✅ TensorFlow: 2.19.0\n",
            "\n",
            "[STEP 1] Creating Balanced Dataset...\n",
            "\n",
            "  Dataset Statistics:\n",
            "  Total samples: 966\n",
            "  Normal: 397 (41.1%)\n",
            "  Abnormal: 569 (58.9%)\n",
            "  Imbalance ratio: 1.43:1\n",
            "\n",
            "[STEP 2] Computing Class Weights...\n",
            "  Class 0 (Normal) weight: 1.217\n",
            "  Class 1 (Abnormal) weight: 0.849\n",
            "\n",
            "[STEP 3] Splitting Dataset (Stratified)...\n",
            "  Train: 675 samples\n",
            "    Normal: 277 (41.0%)\n",
            "    Abnormal: 398 (59.0%)\n",
            "  Validation: 97 samples\n",
            "    Normal: 40 (41.2%)\n",
            "    Abnormal: 57 (58.8%)\n",
            "  Test: 194 samples\n",
            "    Normal: 80 (41.2%)\n",
            "    Abnormal: 114 (58.8%)\n",
            "\n",
            "[STEP 4] Creating Data Generators with Augmentation...\n",
            "Found 675 validated image filenames belonging to 2 classes.\n",
            "Found 97 validated image filenames belonging to 2 classes.\n",
            "Found 194 validated image filenames belonging to 2 classes.\n",
            "  ✅ Generators created with stronger augmentation\n",
            "\n",
            "[STEP 5] Building Improved Model (VGG16)...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "  ✅ Model built with improved regularization\n",
            "\n",
            "[STEP 6] Training - Phase 1 Frozen...\n",
            "Epoch 1/40\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5058 - auc: 0.5231 - loss: 1.8507 - precision: 0.5822 - recall: 0.5097\n",
            "Epoch 1: val_loss improved from inf to 1.74257, saving model to models_improved/best_model_phase_1_frozen.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 1s/step - accuracy: 0.5060 - auc: 0.5234 - loss: 1.8506 - precision: 0.5828 - recall: 0.5098 - val_accuracy: 0.4124 - val_auc: 0.6993 - val_loss: 1.7426 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-04\n",
            "Epoch 2/40\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step - accuracy: 0.5798 - auc: 0.6012 - loss: 1.7562 - precision: 0.6599 - recall: 0.5806\n",
            "Epoch 2: val_loss did not improve from 1.74257\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 514ms/step - accuracy: 0.5796 - auc: 0.6013 - loss: 1.7562 - precision: 0.6598 - recall: 0.5804 - val_accuracy: 0.4124 - val_auc: 0.7724 - val_loss: 1.7431 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-04\n",
            "Epoch 3/40\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - accuracy: 0.6049 - auc: 0.6338 - loss: 1.7165 - precision: 0.6944 - recall: 0.6332\n",
            "Epoch 3: val_loss did not improve from 1.74257\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 409ms/step - accuracy: 0.6052 - auc: 0.6344 - loss: 1.7163 - precision: 0.6945 - recall: 0.6327 - val_accuracy: 0.4227 - val_auc: 0.8013 - val_loss: 1.7438 - val_precision: 1.0000 - val_recall: 0.0175 - learning_rate: 1.0000e-04\n",
            "Epoch 4/40\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353ms/step - accuracy: 0.6608 - auc: 0.7401 - loss: 1.6174 - precision: 0.7381 - recall: 0.6563\n",
            "Epoch 4: val_loss improved from 1.74257 to 1.72433, saving model to models_improved/best_model_phase_1_frozen.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 383ms/step - accuracy: 0.6607 - auc: 0.7396 - loss: 1.6182 - precision: 0.7380 - recall: 0.6563 - val_accuracy: 0.4330 - val_auc: 0.8173 - val_loss: 1.7243 - val_precision: 1.0000 - val_recall: 0.0351 - learning_rate: 1.0000e-04\n",
            "Epoch 5/40\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354ms/step - accuracy: 0.6832 - auc: 0.7590 - loss: 1.6015 - precision: 0.7651 - recall: 0.6485\n",
            "Epoch 5: val_loss improved from 1.72433 to 1.70317, saving model to models_improved/best_model_phase_1_frozen.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 395ms/step - accuracy: 0.6828 - auc: 0.7588 - loss: 1.6018 - precision: 0.7650 - recall: 0.6483 - val_accuracy: 0.4948 - val_auc: 0.8156 - val_loss: 1.7032 - val_precision: 1.0000 - val_recall: 0.1404 - learning_rate: 1.0000e-04\n",
            "Epoch 6/40\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349ms/step - accuracy: 0.6637 - auc: 0.7366 - loss: 1.6259 - precision: 0.7479 - recall: 0.6604\n",
            "Epoch 6: val_loss improved from 1.70317 to 1.68712, saving model to models_improved/best_model_phase_1_frozen.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 380ms/step - accuracy: 0.6637 - auc: 0.7362 - loss: 1.6264 - precision: 0.7478 - recall: 0.6602 - val_accuracy: 0.5052 - val_auc: 0.8272 - val_loss: 1.6871 - val_precision: 0.8000 - val_recall: 0.2105 - learning_rate: 1.0000e-04\n",
            "Epoch 7/40\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349ms/step - accuracy: 0.6816 - auc: 0.7670 - loss: 1.5933 - precision: 0.7507 - recall: 0.6784\n",
            "Epoch 7: val_loss improved from 1.68712 to 1.65437, saving model to models_improved/best_model_phase_1_frozen.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 379ms/step - accuracy: 0.6823 - auc: 0.7673 - loss: 1.5931 - precision: 0.7514 - recall: 0.6791 - val_accuracy: 0.5567 - val_auc: 0.8250 - val_loss: 1.6544 - val_precision: 0.8500 - val_recall: 0.2982 - learning_rate: 1.0000e-04\n",
            "Epoch 8/40\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - accuracy: 0.7454 - auc: 0.7947 - loss: 1.5325 - precision: 0.8147 - recall: 0.7457\n",
            "Epoch 8: val_loss improved from 1.65437 to 1.62733, saving model to models_improved/best_model_phase_1_frozen.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 412ms/step - accuracy: 0.7449 - auc: 0.7945 - loss: 1.5330 - precision: 0.8141 - recall: 0.7453 - val_accuracy: 0.6186 - val_auc: 0.8289 - val_loss: 1.6273 - val_precision: 0.8846 - val_recall: 0.4035 - learning_rate: 1.0000e-04\n",
            "Epoch 9/40\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step - accuracy: 0.7149 - auc: 0.8002 - loss: 1.5441 - precision: 0.8280 - recall: 0.6753\n",
            "Epoch 9: val_loss improved from 1.62733 to 1.59117, saving model to models_improved/best_model_phase_1_frozen.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 382ms/step - accuracy: 0.7153 - auc: 0.8003 - loss: 1.5438 - precision: 0.8276 - recall: 0.6760 - val_accuracy: 0.6598 - val_auc: 0.8375 - val_loss: 1.5912 - val_precision: 0.9000 - val_recall: 0.4737 - learning_rate: 1.0000e-04\n",
            "Epoch 10/40\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360ms/step - accuracy: 0.7623 - auc: 0.8287 - loss: 1.5057 - precision: 0.8143 - recall: 0.7554\n",
            "Epoch 10: val_loss improved from 1.59117 to 1.56702, saving model to models_improved/best_model_phase_1_frozen.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 390ms/step - accuracy: 0.7615 - auc: 0.8281 - loss: 1.5064 - precision: 0.8138 - recall: 0.7548 - val_accuracy: 0.7010 - val_auc: 0.8443 - val_loss: 1.5670 - val_precision: 0.9118 - val_recall: 0.5439 - learning_rate: 1.0000e-04\n",
            "Epoch 11/40\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - accuracy: 0.7400 - auc: 0.8176 - loss: 1.5200 - precision: 0.7866 - recall: 0.7499\n",
            "Epoch 11: val_loss improved from 1.56702 to 1.55023, saving model to models_improved/best_model_phase_1_frozen.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 405ms/step - accuracy: 0.7398 - auc: 0.8177 - loss: 1.5198 - precision: 0.7869 - recall: 0.7494 - val_accuracy: 0.7629 - val_auc: 0.8445 - val_loss: 1.5502 - val_precision: 0.9250 - val_recall: 0.6491 - learning_rate: 1.0000e-04\n",
            "Epoch 12/40\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355ms/step - accuracy: 0.7557 - auc: 0.8476 - loss: 1.4695 - precision: 0.8305 - recall: 0.7399\n",
            "Epoch 12: val_loss improved from 1.55023 to 1.53673, saving model to models_improved/best_model_phase_1_frozen.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 384ms/step - accuracy: 0.7554 - auc: 0.8473 - loss: 1.4700 - precision: 0.8300 - recall: 0.7398 - val_accuracy: 0.7835 - val_auc: 0.8452 - val_loss: 1.5367 - val_precision: 0.9091 - val_recall: 0.7018 - learning_rate: 1.0000e-04\n",
            "Epoch 13/40\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363ms/step - accuracy: 0.7520 - auc: 0.8317 - loss: 1.5014 - precision: 0.7662 - recall: 0.7942\n",
            "Epoch 13: val_loss improved from 1.53673 to 1.52788, saving model to models_improved/best_model_phase_1_frozen.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 402ms/step - accuracy: 0.7522 - auc: 0.8320 - loss: 1.5007 - precision: 0.7673 - recall: 0.7937 - val_accuracy: 0.7835 - val_auc: 0.8518 - val_loss: 1.5279 - val_precision: 0.9091 - val_recall: 0.7018 - learning_rate: 1.0000e-04\n",
            "Epoch 14/40\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353ms/step - accuracy: 0.7780 - auc: 0.8403 - loss: 1.4800 - precision: 0.8321 - recall: 0.7859\n",
            "Epoch 14: val_loss improved from 1.52788 to 1.50583, saving model to models_improved/best_model_phase_1_frozen.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 383ms/step - accuracy: 0.7776 - auc: 0.8399 - loss: 1.4807 - precision: 0.8315 - recall: 0.7857 - val_accuracy: 0.7732 - val_auc: 0.8544 - val_loss: 1.5058 - val_precision: 0.8889 - val_recall: 0.7018 - learning_rate: 1.0000e-04\n",
            "Epoch 15/40\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353ms/step - accuracy: 0.7453 - auc: 0.8372 - loss: 1.4753 - precision: 0.8159 - recall: 0.7469\n",
            "Epoch 15: val_loss did not improve from 1.50583\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 378ms/step - accuracy: 0.7457 - auc: 0.8374 - loss: 1.4751 - precision: 0.8160 - recall: 0.7473 - val_accuracy: 0.7835 - val_auc: 0.8485 - val_loss: 1.5142 - val_precision: 0.8913 - val_recall: 0.7193 - learning_rate: 1.0000e-04\n",
            "Epoch 16/40\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - accuracy: 0.8158 - auc: 0.8809 - loss: 1.4083 - precision: 0.8832 - recall: 0.7992\n",
            "Epoch 16: val_loss did not improve from 1.50583\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 402ms/step - accuracy: 0.8153 - auc: 0.8806 - loss: 1.4089 - precision: 0.8826 - recall: 0.7989 - val_accuracy: 0.7938 - val_auc: 0.8471 - val_loss: 1.5082 - val_precision: 0.8936 - val_recall: 0.7368 - learning_rate: 1.0000e-04\n",
            "Epoch 17/40\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354ms/step - accuracy: 0.7599 - auc: 0.8528 - loss: 1.4561 - precision: 0.7998 - recall: 0.7827\n",
            "Epoch 17: val_loss did not improve from 1.50583\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 379ms/step - accuracy: 0.7603 - auc: 0.8530 - loss: 1.4558 - precision: 0.8006 - recall: 0.7825 - val_accuracy: 0.7938 - val_auc: 0.8485 - val_loss: 1.5113 - val_precision: 0.8936 - val_recall: 0.7368 - learning_rate: 1.0000e-04\n",
            "Epoch 18/40\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354ms/step - accuracy: 0.7750 - auc: 0.8598 - loss: 1.4527 - precision: 0.8710 - recall: 0.7523\n",
            "Epoch 18: val_loss improved from 1.50583 to 1.50248, saving model to models_improved/best_model_phase_1_frozen.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 384ms/step - accuracy: 0.7754 - auc: 0.8599 - loss: 1.4523 - precision: 0.8706 - recall: 0.7530 - val_accuracy: 0.8144 - val_auc: 0.8498 - val_loss: 1.5025 - val_precision: 0.8824 - val_recall: 0.7895 - learning_rate: 1.0000e-04\n",
            "Epoch 19/40\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - accuracy: 0.7582 - auc: 0.8301 - loss: 1.4818 - precision: 0.8136 - recall: 0.7621\n",
            "Epoch 19: val_loss did not improve from 1.50248\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 401ms/step - accuracy: 0.7588 - auc: 0.8305 - loss: 1.4813 - precision: 0.8141 - recall: 0.7626 - val_accuracy: 0.8144 - val_auc: 0.8493 - val_loss: 1.5095 - val_precision: 0.8824 - val_recall: 0.7895 - learning_rate: 1.0000e-04\n",
            "Epoch 20/40\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346ms/step - accuracy: 0.8163 - auc: 0.8989 - loss: 1.3739 - precision: 0.8755 - recall: 0.8095\n",
            "Epoch 20: val_loss did not improve from 1.50248\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 370ms/step - accuracy: 0.8159 - auc: 0.8982 - loss: 1.3751 - precision: 0.8750 - recall: 0.8092 - val_accuracy: 0.8041 - val_auc: 0.8526 - val_loss: 1.5161 - val_precision: 0.8800 - val_recall: 0.7719 - learning_rate: 1.0000e-04\n",
            "Epoch 21/40\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355ms/step - accuracy: 0.7866 - auc: 0.8703 - loss: 1.4151 - precision: 0.8462 - recall: 0.7995\n",
            "Epoch 21: val_loss did not improve from 1.50248\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 379ms/step - accuracy: 0.7866 - auc: 0.8700 - loss: 1.4155 - precision: 0.8458 - recall: 0.7995 - val_accuracy: 0.8041 - val_auc: 0.8542 - val_loss: 1.5088 - val_precision: 0.8800 - val_recall: 0.7719 - learning_rate: 1.0000e-04\n",
            "Epoch 22/40\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359ms/step - accuracy: 0.7919 - auc: 0.8698 - loss: 1.4065 - precision: 0.8733 - recall: 0.7859\n",
            "Epoch 22: val_loss did not improve from 1.50248\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 384ms/step - accuracy: 0.7919 - auc: 0.8698 - loss: 1.4067 - precision: 0.8726 - recall: 0.7862 - val_accuracy: 0.8041 - val_auc: 0.8524 - val_loss: 1.5177 - val_precision: 0.8800 - val_recall: 0.7719 - learning_rate: 1.0000e-04\n",
            "Epoch 23/40\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348ms/step - accuracy: 0.7417 - auc: 0.8351 - loss: 1.4934 - precision: 0.7795 - recall: 0.7547\n",
            "Epoch 23: val_loss did not improve from 1.50248\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 373ms/step - accuracy: 0.7426 - auc: 0.8359 - loss: 1.4918 - precision: 0.7808 - recall: 0.7555 - val_accuracy: 0.8041 - val_auc: 0.8478 - val_loss: 1.5343 - val_precision: 0.8800 - val_recall: 0.7719 - learning_rate: 1.0000e-04\n",
            "Epoch 24/40\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355ms/step - accuracy: 0.7821 - auc: 0.8525 - loss: 1.4475 - precision: 0.8143 - recall: 0.8162\n",
            "Epoch 24: val_loss did not improve from 1.50248\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 382ms/step - accuracy: 0.7821 - auc: 0.8528 - loss: 1.4469 - precision: 0.8146 - recall: 0.8157 - val_accuracy: 0.8144 - val_auc: 0.8531 - val_loss: 1.5203 - val_precision: 0.8824 - val_recall: 0.7895 - learning_rate: 1.0000e-04\n",
            "Epoch 25/40\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357ms/step - accuracy: 0.8049 - auc: 0.8822 - loss: 1.3988 - precision: 0.8411 - recall: 0.8135\n",
            "Epoch 25: val_loss did not improve from 1.50248\n",
            "\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 383ms/step - accuracy: 0.8046 - auc: 0.8822 - loss: 1.3986 - precision: 0.8412 - recall: 0.8130 - val_accuracy: 0.8144 - val_auc: 0.8575 - val_loss: 1.5139 - val_precision: 0.8824 - val_recall: 0.7895 - learning_rate: 1.0000e-04\n",
            "Epoch 26/40\n",
            "\u001b[1m42/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 363ms/step - accuracy: 0.8198 - auc: 0.9088 - loss: 1.3376 - precision: 0.9030 - recall: 0.7916\n",
            "Epoch 26: val_loss did not improve from 1.50248\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 380ms/step - accuracy: 0.8196 - auc: 0.9086 - loss: 1.3379 - precision: 0.9019 - recall: 0.7918 - val_accuracy: 0.8144 - val_auc: 0.8583 - val_loss: 1.5098 - val_precision: 0.8824 - val_recall: 0.7895 - learning_rate: 5.0000e-05\n",
            "Epoch 27/40\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356ms/step - accuracy: 0.8159 - auc: 0.8681 - loss: 1.4194 - precision: 0.8537 - recall: 0.8257\n",
            "Epoch 27: val_loss did not improve from 1.50248\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 417ms/step - accuracy: 0.8158 - auc: 0.8683 - loss: 1.4189 - precision: 0.8538 - recall: 0.8255 - val_accuracy: 0.8144 - val_auc: 0.8577 - val_loss: 1.5079 - val_precision: 0.8824 - val_recall: 0.7895 - learning_rate: 5.0000e-05\n",
            "Epoch 28/40\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351ms/step - accuracy: 0.8126 - auc: 0.8810 - loss: 1.4001 - precision: 0.8281 - recall: 0.8416\n",
            "Epoch 28: val_loss did not improve from 1.50248\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 374ms/step - accuracy: 0.8124 - auc: 0.8809 - loss: 1.4000 - precision: 0.8287 - recall: 0.8408 - val_accuracy: 0.8144 - val_auc: 0.8564 - val_loss: 1.5092 - val_precision: 0.8824 - val_recall: 0.7895 - learning_rate: 5.0000e-05\n",
            "Epoch 29/40\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346ms/step - accuracy: 0.7966 - auc: 0.8734 - loss: 1.4004 - precision: 0.8483 - recall: 0.7861\n",
            "Epoch 29: val_loss improved from 1.50248 to 1.48783, saving model to models_improved/best_model_phase_1_frozen.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 376ms/step - accuracy: 0.7970 - auc: 0.8738 - loss: 1.3997 - precision: 0.8487 - recall: 0.7867 - val_accuracy: 0.8144 - val_auc: 0.8592 - val_loss: 1.4878 - val_precision: 0.8679 - val_recall: 0.8070 - learning_rate: 5.0000e-05\n",
            "Epoch 30/40\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362ms/step - accuracy: 0.8001 - auc: 0.8837 - loss: 1.3748 - precision: 0.8680 - recall: 0.7905\n",
            "Epoch 30: val_loss improved from 1.48783 to 1.47556, saving model to models_improved/best_model_phase_1_frozen.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 393ms/step - accuracy: 0.8004 - auc: 0.8839 - loss: 1.3745 - precision: 0.8680 - recall: 0.7908 - val_accuracy: 0.8144 - val_auc: 0.8605 - val_loss: 1.4756 - val_precision: 0.8679 - val_recall: 0.8070 - learning_rate: 5.0000e-05\n",
            "Epoch 31/40\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342ms/step - accuracy: 0.8106 - auc: 0.8976 - loss: 1.3435 - precision: 0.8393 - recall: 0.8321\n",
            "Epoch 31: val_loss improved from 1.47556 to 1.47189, saving model to models_improved/best_model_phase_1_frozen.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 371ms/step - accuracy: 0.8103 - auc: 0.8974 - loss: 1.3441 - precision: 0.8394 - recall: 0.8316 - val_accuracy: 0.8144 - val_auc: 0.8634 - val_loss: 1.4719 - val_precision: 0.8679 - val_recall: 0.8070 - learning_rate: 5.0000e-05\n",
            "Epoch 32/40\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345ms/step - accuracy: 0.8257 - auc: 0.9032 - loss: 1.3336 - precision: 0.8578 - recall: 0.8423\n",
            "Epoch 32: val_loss did not improve from 1.47189\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 369ms/step - accuracy: 0.8253 - auc: 0.9029 - loss: 1.3341 - precision: 0.8576 - recall: 0.8418 - val_accuracy: 0.8247 - val_auc: 0.8634 - val_loss: 1.4752 - val_precision: 0.8846 - val_recall: 0.8070 - learning_rate: 5.0000e-05\n",
            "Epoch 33/40\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360ms/step - accuracy: 0.8256 - auc: 0.8917 - loss: 1.3628 - precision: 0.8675 - recall: 0.8338\n",
            "Epoch 33: val_loss did not improve from 1.47189\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 387ms/step - accuracy: 0.8252 - auc: 0.8914 - loss: 1.3632 - precision: 0.8672 - recall: 0.8332 - val_accuracy: 0.8144 - val_auc: 0.8632 - val_loss: 1.4726 - val_precision: 0.8679 - val_recall: 0.8070 - learning_rate: 5.0000e-05\n",
            "Epoch 34/40\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345ms/step - accuracy: 0.8017 - auc: 0.8916 - loss: 1.3609 - precision: 0.8538 - recall: 0.7930\n",
            "Epoch 34: val_loss did not improve from 1.47189\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 371ms/step - accuracy: 0.8017 - auc: 0.8915 - loss: 1.3611 - precision: 0.8540 - recall: 0.7928 - val_accuracy: 0.8144 - val_auc: 0.8625 - val_loss: 1.4791 - val_precision: 0.8679 - val_recall: 0.8070 - learning_rate: 5.0000e-05\n",
            "Epoch 35/40\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349ms/step - accuracy: 0.8007 - auc: 0.8700 - loss: 1.3987 - precision: 0.8539 - recall: 0.7996\n",
            "Epoch 35: val_loss did not improve from 1.47189\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 374ms/step - accuracy: 0.8006 - auc: 0.8698 - loss: 1.3992 - precision: 0.8537 - recall: 0.7997 - val_accuracy: 0.8247 - val_auc: 0.8627 - val_loss: 1.4777 - val_precision: 0.8846 - val_recall: 0.8070 - learning_rate: 5.0000e-05\n",
            "Epoch 36/40\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358ms/step - accuracy: 0.8050 - auc: 0.8855 - loss: 1.3787 - precision: 0.8227 - recall: 0.8251\n",
            "Epoch 36: val_loss did not improve from 1.47189\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 385ms/step - accuracy: 0.8047 - auc: 0.8853 - loss: 1.3790 - precision: 0.8233 - recall: 0.8243 - val_accuracy: 0.8247 - val_auc: 0.8638 - val_loss: 1.4777 - val_precision: 0.8846 - val_recall: 0.8070 - learning_rate: 5.0000e-05\n",
            "Epoch 37/40\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347ms/step - accuracy: 0.8189 - auc: 0.9049 - loss: 1.3259 - precision: 0.8804 - recall: 0.8099\n",
            "Epoch 37: val_loss did not improve from 1.47189\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 371ms/step - accuracy: 0.8188 - auc: 0.9046 - loss: 1.3264 - precision: 0.8800 - recall: 0.8099 - val_accuracy: 0.8144 - val_auc: 0.8618 - val_loss: 1.4757 - val_precision: 0.8679 - val_recall: 0.8070 - learning_rate: 5.0000e-05\n",
            "Epoch 38/40\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345ms/step - accuracy: 0.7853 - auc: 0.8578 - loss: 1.4335 - precision: 0.8251 - recall: 0.7996\n",
            "Epoch 38: val_loss did not improve from 1.47189\n",
            "\n",
            "Epoch 38: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 370ms/step - accuracy: 0.7856 - auc: 0.8582 - loss: 1.4326 - precision: 0.8255 - recall: 0.7998 - val_accuracy: 0.8247 - val_auc: 0.8656 - val_loss: 1.4740 - val_precision: 0.8846 - val_recall: 0.8070 - learning_rate: 5.0000e-05\n",
            "Epoch 39/40\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354ms/step - accuracy: 0.8028 - auc: 0.8879 - loss: 1.3665 - precision: 0.8719 - recall: 0.7940\n",
            "Epoch 39: val_loss did not improve from 1.47189\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 385ms/step - accuracy: 0.8027 - auc: 0.8877 - loss: 1.3668 - precision: 0.8714 - recall: 0.7941 - val_accuracy: 0.8247 - val_auc: 0.8671 - val_loss: 1.4730 - val_precision: 0.8846 - val_recall: 0.8070 - learning_rate: 2.5000e-05\n",
            "Epoch 40/40\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350ms/step - accuracy: 0.8158 - auc: 0.8883 - loss: 1.3532 - precision: 0.8590 - recall: 0.8250\n",
            "Epoch 40: val_loss improved from 1.47189 to 1.46965, saving model to models_improved/best_model_phase_1_frozen.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 379ms/step - accuracy: 0.8154 - auc: 0.8881 - loss: 1.3535 - precision: 0.8588 - recall: 0.8244 - val_accuracy: 0.8247 - val_auc: 0.8673 - val_loss: 1.4697 - val_precision: 0.8846 - val_recall: 0.8070 - learning_rate: 2.5000e-05\n",
            "Restoring model weights from the end of the best epoch: 40.\n",
            "\n",
            "[STEP 6.5] Unfreezing for Fine-tuning...\n",
            "\n",
            "[STEP 6] Training - Phase 2 Fine-tune...\n",
            "Epoch 1/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727ms/step - accuracy: 0.8116 - auc: 0.8998 - loss: 1.3504 - precision: 0.9068 - recall: 0.7872\n",
            "Epoch 1: val_loss improved from inf to 2.02857, saving model to models_improved/best_model_phase_2_fine-tune.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 852ms/step - accuracy: 0.8121 - auc: 0.8998 - loss: 1.3501 - precision: 0.9062 - recall: 0.7883 - val_accuracy: 0.6186 - val_auc: 0.8588 - val_loss: 2.0286 - val_precision: 0.6111 - val_recall: 0.9649 - learning_rate: 1.0000e-05\n",
            "Epoch 2/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408ms/step - accuracy: 0.8252 - auc: 0.8925 - loss: 1.3533 - precision: 0.8705 - recall: 0.8296\n",
            "Epoch 2: val_loss improved from 2.02857 to 1.55803, saving model to models_improved/best_model_phase_2_fine-tune.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 447ms/step - accuracy: 0.8253 - auc: 0.8925 - loss: 1.3534 - precision: 0.8705 - recall: 0.8299 - val_accuracy: 0.7526 - val_auc: 0.8763 - val_loss: 1.5580 - val_precision: 0.8837 - val_recall: 0.6667 - learning_rate: 1.0000e-05\n",
            "Epoch 3/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - accuracy: 0.8214 - auc: 0.9023 - loss: 1.3324 - precision: 0.8557 - recall: 0.8369\n",
            "Epoch 3: val_loss improved from 1.55803 to 1.46265, saving model to models_improved/best_model_phase_2_fine-tune.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 456ms/step - accuracy: 0.8216 - auc: 0.9024 - loss: 1.3320 - precision: 0.8562 - recall: 0.8366 - val_accuracy: 0.7938 - val_auc: 0.8884 - val_loss: 1.4627 - val_precision: 0.7606 - val_recall: 0.9474 - learning_rate: 1.0000e-05\n",
            "Epoch 4/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404ms/step - accuracy: 0.8465 - auc: 0.9171 - loss: 1.3005 - precision: 0.8899 - recall: 0.8418\n",
            "Epoch 4: val_loss did not improve from 1.46265\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 437ms/step - accuracy: 0.8462 - auc: 0.9170 - loss: 1.3007 - precision: 0.8897 - recall: 0.8416 - val_accuracy: 0.7938 - val_auc: 0.8711 - val_loss: 1.4658 - val_precision: 0.8246 - val_recall: 0.8246 - learning_rate: 1.0000e-05\n",
            "Epoch 5/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403ms/step - accuracy: 0.8684 - auc: 0.9453 - loss: 1.2380 - precision: 0.9023 - recall: 0.8612\n",
            "Epoch 5: val_loss did not improve from 1.46265\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 427ms/step - accuracy: 0.8681 - auc: 0.9450 - loss: 1.2387 - precision: 0.9022 - recall: 0.8610 - val_accuracy: 0.7320 - val_auc: 0.9140 - val_loss: 1.7776 - val_precision: 0.6914 - val_recall: 0.9825 - learning_rate: 1.0000e-05\n",
            "Epoch 6/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425ms/step - accuracy: 0.8660 - auc: 0.9265 - loss: 1.2883 - precision: 0.8907 - recall: 0.8772\n",
            "Epoch 6: val_loss did not improve from 1.46265\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 452ms/step - accuracy: 0.8660 - auc: 0.9265 - loss: 1.2882 - precision: 0.8908 - recall: 0.8771 - val_accuracy: 0.7938 - val_auc: 0.9285 - val_loss: 1.5291 - val_precision: 0.9512 - val_recall: 0.6842 - learning_rate: 1.0000e-05\n",
            "Epoch 7/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400ms/step - accuracy: 0.8836 - auc: 0.9525 - loss: 1.2082 - precision: 0.9219 - recall: 0.8801\n",
            "Epoch 7: val_loss improved from 1.46265 to 1.30079, saving model to models_improved/best_model_phase_2_fine-tune.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 437ms/step - accuracy: 0.8835 - auc: 0.9523 - loss: 1.2087 - precision: 0.9217 - recall: 0.8799 - val_accuracy: 0.8454 - val_auc: 0.9309 - val_loss: 1.3008 - val_precision: 0.8387 - val_recall: 0.9123 - learning_rate: 1.0000e-05\n",
            "Epoch 8/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419ms/step - accuracy: 0.8430 - auc: 0.9272 - loss: 1.2828 - precision: 0.8850 - recall: 0.8422\n",
            "Epoch 8: val_loss did not improve from 1.30079\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 443ms/step - accuracy: 0.8433 - auc: 0.9271 - loss: 1.2829 - precision: 0.8854 - recall: 0.8422 - val_accuracy: 0.8041 - val_auc: 0.9340 - val_loss: 1.3493 - val_precision: 0.7879 - val_recall: 0.9123 - learning_rate: 1.0000e-05\n",
            "Epoch 9/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - accuracy: 0.8791 - auc: 0.9542 - loss: 1.2087 - precision: 0.9179 - recall: 0.8724\n",
            "Epoch 9: val_loss did not improve from 1.30079\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 440ms/step - accuracy: 0.8791 - auc: 0.9540 - loss: 1.2090 - precision: 0.9179 - recall: 0.8725 - val_accuracy: 0.8351 - val_auc: 0.9180 - val_loss: 1.3667 - val_precision: 0.9020 - val_recall: 0.8070 - learning_rate: 1.0000e-05\n",
            "Epoch 10/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428ms/step - accuracy: 0.9081 - auc: 0.9723 - loss: 1.1492 - precision: 0.9388 - recall: 0.9020\n",
            "Epoch 10: val_loss did not improve from 1.30079\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 454ms/step - accuracy: 0.9082 - auc: 0.9722 - loss: 1.1493 - precision: 0.9389 - recall: 0.9021 - val_accuracy: 0.8866 - val_auc: 0.9346 - val_loss: 1.3163 - val_precision: 0.9423 - val_recall: 0.8596 - learning_rate: 1.0000e-05\n",
            "Epoch 11/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - accuracy: 0.8651 - auc: 0.9458 - loss: 1.2280 - precision: 0.8995 - recall: 0.8649\n",
            "Epoch 11: val_loss did not improve from 1.30079\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 444ms/step - accuracy: 0.8656 - auc: 0.9459 - loss: 1.2277 - precision: 0.9000 - recall: 0.8653 - val_accuracy: 0.8247 - val_auc: 0.9296 - val_loss: 1.3606 - val_precision: 0.9545 - val_recall: 0.7368 - learning_rate: 1.0000e-05\n",
            "Epoch 12/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418ms/step - accuracy: 0.8932 - auc: 0.9545 - loss: 1.2028 - precision: 0.9284 - recall: 0.8834\n",
            "Epoch 12: val_loss improved from 1.30079 to 1.30054, saving model to models_improved/best_model_phase_2_fine-tune.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 453ms/step - accuracy: 0.8931 - auc: 0.9545 - loss: 1.2026 - precision: 0.9286 - recall: 0.8832 - val_accuracy: 0.8557 - val_auc: 0.9272 - val_loss: 1.3005 - val_precision: 0.8525 - val_recall: 0.9123 - learning_rate: 1.0000e-05\n",
            "Epoch 13/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429ms/step - accuracy: 0.8489 - auc: 0.9263 - loss: 1.2860 - precision: 0.8704 - recall: 0.8608\n",
            "Epoch 13: val_loss did not improve from 1.30054\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 456ms/step - accuracy: 0.8491 - auc: 0.9264 - loss: 1.2856 - precision: 0.8710 - recall: 0.8609 - val_accuracy: 0.7423 - val_auc: 0.9314 - val_loss: 1.4819 - val_precision: 0.9211 - val_recall: 0.6140 - learning_rate: 1.0000e-05\n",
            "Epoch 14/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424ms/step - accuracy: 0.8874 - auc: 0.9486 - loss: 1.2225 - precision: 0.9240 - recall: 0.8904\n",
            "Epoch 14: val_loss improved from 1.30054 to 1.29746, saving model to models_improved/best_model_phase_2_fine-tune.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 462ms/step - accuracy: 0.8878 - auc: 0.9487 - loss: 1.2220 - precision: 0.9241 - recall: 0.8907 - val_accuracy: 0.8763 - val_auc: 0.9364 - val_loss: 1.2975 - val_precision: 0.9091 - val_recall: 0.8772 - learning_rate: 1.0000e-05\n",
            "Epoch 15/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432ms/step - accuracy: 0.8722 - auc: 0.9522 - loss: 1.2151 - precision: 0.9284 - recall: 0.8624\n",
            "Epoch 15: val_loss did not improve from 1.29746\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 457ms/step - accuracy: 0.8726 - auc: 0.9523 - loss: 1.2145 - precision: 0.9282 - recall: 0.8630 - val_accuracy: 0.7938 - val_auc: 0.9327 - val_loss: 1.4532 - val_precision: 0.9111 - val_recall: 0.7193 - learning_rate: 1.0000e-05\n",
            "Epoch 16/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - accuracy: 0.9114 - auc: 0.9619 - loss: 1.1749 - precision: 0.9357 - recall: 0.9107\n",
            "Epoch 16: val_loss improved from 1.29746 to 1.27923, saving model to models_improved/best_model_phase_2_fine-tune.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 457ms/step - accuracy: 0.9114 - auc: 0.9619 - loss: 1.1749 - precision: 0.9359 - recall: 0.9104 - val_accuracy: 0.8454 - val_auc: 0.9443 - val_loss: 1.2792 - val_precision: 0.9200 - val_recall: 0.8070 - learning_rate: 1.0000e-05\n",
            "Epoch 17/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428ms/step - accuracy: 0.9059 - auc: 0.9646 - loss: 1.1649 - precision: 0.9364 - recall: 0.9004\n",
            "Epoch 17: val_loss improved from 1.27923 to 1.23960, saving model to models_improved/best_model_phase_2_fine-tune.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 463ms/step - accuracy: 0.9058 - auc: 0.9646 - loss: 1.1648 - precision: 0.9365 - recall: 0.9003 - val_accuracy: 0.8866 - val_auc: 0.9491 - val_loss: 1.2396 - val_precision: 0.9107 - val_recall: 0.8947 - learning_rate: 1.0000e-05\n",
            "Epoch 18/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431ms/step - accuracy: 0.8734 - auc: 0.9501 - loss: 1.2208 - precision: 0.9066 - recall: 0.8697\n",
            "Epoch 18: val_loss did not improve from 1.23960\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 456ms/step - accuracy: 0.8732 - auc: 0.9500 - loss: 1.2211 - precision: 0.9068 - recall: 0.8693 - val_accuracy: 0.8351 - val_auc: 0.9384 - val_loss: 1.2990 - val_precision: 0.9362 - val_recall: 0.7719 - learning_rate: 1.0000e-05\n",
            "Epoch 19/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406ms/step - accuracy: 0.8785 - auc: 0.9421 - loss: 1.2343 - precision: 0.8990 - recall: 0.8910\n",
            "Epoch 19: val_loss improved from 1.23960 to 1.22302, saving model to models_improved/best_model_phase_2_fine-tune.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 444ms/step - accuracy: 0.8788 - auc: 0.9424 - loss: 1.2336 - precision: 0.8994 - recall: 0.8912 - val_accuracy: 0.8351 - val_auc: 0.9524 - val_loss: 1.2230 - val_precision: 0.8361 - val_recall: 0.8947 - learning_rate: 1.0000e-05\n",
            "Epoch 20/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425ms/step - accuracy: 0.8961 - auc: 0.9725 - loss: 1.1531 - precision: 0.9371 - recall: 0.8908\n",
            "Epoch 20: val_loss did not improve from 1.22302\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 451ms/step - accuracy: 0.8962 - auc: 0.9724 - loss: 1.1532 - precision: 0.9368 - recall: 0.8912 - val_accuracy: 0.8247 - val_auc: 0.9414 - val_loss: 1.3573 - val_precision: 0.9348 - val_recall: 0.7544 - learning_rate: 1.0000e-05\n",
            "Epoch 21/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - accuracy: 0.9066 - auc: 0.9568 - loss: 1.1988 - precision: 0.9164 - recall: 0.9209\n",
            "Epoch 21: val_loss did not improve from 1.22302\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 447ms/step - accuracy: 0.9067 - auc: 0.9569 - loss: 1.1984 - precision: 0.9169 - recall: 0.9207 - val_accuracy: 0.8454 - val_auc: 0.9395 - val_loss: 1.3192 - val_precision: 0.9200 - val_recall: 0.8070 - learning_rate: 1.0000e-05\n",
            "Epoch 22/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418ms/step - accuracy: 0.9007 - auc: 0.9626 - loss: 1.1745 - precision: 0.9327 - recall: 0.8977\n",
            "Epoch 22: val_loss did not improve from 1.22302\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 443ms/step - accuracy: 0.9008 - auc: 0.9626 - loss: 1.1745 - precision: 0.9326 - recall: 0.8979 - val_accuracy: 0.8763 - val_auc: 0.9520 - val_loss: 1.2811 - val_precision: 0.9245 - val_recall: 0.8596 - learning_rate: 1.0000e-05\n",
            "Epoch 23/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421ms/step - accuracy: 0.8964 - auc: 0.9631 - loss: 1.1718 - precision: 0.9403 - recall: 0.8875\n",
            "Epoch 23: val_loss did not improve from 1.22302\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 446ms/step - accuracy: 0.8966 - auc: 0.9631 - loss: 1.1718 - precision: 0.9402 - recall: 0.8878 - val_accuracy: 0.8351 - val_auc: 0.9388 - val_loss: 1.4131 - val_precision: 0.9184 - val_recall: 0.7895 - learning_rate: 1.0000e-05\n",
            "Epoch 24/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409ms/step - accuracy: 0.9241 - auc: 0.9753 - loss: 1.1254 - precision: 0.9539 - recall: 0.9163\n",
            "Epoch 24: val_loss did not improve from 1.22302\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 434ms/step - accuracy: 0.9239 - auc: 0.9752 - loss: 1.1258 - precision: 0.9535 - recall: 0.9163 - val_accuracy: 0.8041 - val_auc: 0.9432 - val_loss: 1.5184 - val_precision: 0.9524 - val_recall: 0.7018 - learning_rate: 1.0000e-05\n",
            "Epoch 25/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422ms/step - accuracy: 0.9147 - auc: 0.9691 - loss: 1.1653 - precision: 0.9501 - recall: 0.9076\n",
            "Epoch 25: val_loss did not improve from 1.22302\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 446ms/step - accuracy: 0.9148 - auc: 0.9691 - loss: 1.1648 - precision: 0.9500 - recall: 0.9079 - val_accuracy: 0.8557 - val_auc: 0.9430 - val_loss: 1.3703 - val_precision: 0.9388 - val_recall: 0.8070 - learning_rate: 1.0000e-05\n",
            "Epoch 26/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - accuracy: 0.9104 - auc: 0.9692 - loss: 1.1543 - precision: 0.9497 - recall: 0.9010\n",
            "Epoch 26: val_loss did not improve from 1.22302\n",
            "\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 440ms/step - accuracy: 0.9104 - auc: 0.9692 - loss: 1.1542 - precision: 0.9493 - recall: 0.9015 - val_accuracy: 0.8557 - val_auc: 0.9316 - val_loss: 1.3459 - val_precision: 0.9388 - val_recall: 0.8070 - learning_rate: 1.0000e-05\n",
            "Epoch 27/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421ms/step - accuracy: 0.9073 - auc: 0.9679 - loss: 1.1546 - precision: 0.9369 - recall: 0.9003\n",
            "Epoch 27: val_loss improved from 1.22302 to 1.21395, saving model to models_improved/best_model_phase_2_fine-tune.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 459ms/step - accuracy: 0.9074 - auc: 0.9679 - loss: 1.1546 - precision: 0.9374 - recall: 0.9001 - val_accuracy: 0.9072 - val_auc: 0.9544 - val_loss: 1.2140 - val_precision: 0.9444 - val_recall: 0.8947 - learning_rate: 5.0000e-06\n",
            "Epoch 28/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411ms/step - accuracy: 0.8774 - auc: 0.9575 - loss: 1.2188 - precision: 0.9668 - recall: 0.8348\n",
            "Epoch 28: val_loss did not improve from 1.21395\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 442ms/step - accuracy: 0.8777 - auc: 0.9575 - loss: 1.2179 - precision: 0.9662 - recall: 0.8356 - val_accuracy: 0.8969 - val_auc: 0.9577 - val_loss: 1.2451 - val_precision: 0.9608 - val_recall: 0.8596 - learning_rate: 5.0000e-06\n",
            "Epoch 29/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409ms/step - accuracy: 0.9236 - auc: 0.9791 - loss: 1.1167 - precision: 0.9614 - recall: 0.9084\n",
            "Epoch 29: val_loss did not improve from 1.21395\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 435ms/step - accuracy: 0.9237 - auc: 0.9791 - loss: 1.1167 - precision: 0.9614 - recall: 0.9086 - val_accuracy: 0.8763 - val_auc: 0.9572 - val_loss: 1.2180 - val_precision: 0.8689 - val_recall: 0.9298 - learning_rate: 5.0000e-06\n",
            "Epoch 30/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423ms/step - accuracy: 0.9000 - auc: 0.9549 - loss: 1.2134 - precision: 0.9488 - recall: 0.8906\n",
            "Epoch 30: val_loss did not improve from 1.21395\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 451ms/step - accuracy: 0.8998 - auc: 0.9550 - loss: 1.2126 - precision: 0.9479 - recall: 0.8909 - val_accuracy: 0.8763 - val_auc: 0.9386 - val_loss: 1.2368 - val_precision: 0.8689 - val_recall: 0.9298 - learning_rate: 5.0000e-06\n",
            "Restoring model weights from the end of the best epoch: 27.\n",
            "\n",
            "[STEP 7] Finding Optimal Threshold...\n",
            "\n",
            "  Optimal Threshold Analysis:\n",
            "  Best F1-Score: 0.9231 at threshold 0.20\n",
            "\n",
            "  Top 5 Thresholds by F1-Score:\n",
            "    0.20: F1=0.923, Precision=0.900, Recall=0.947, Missed Cancers=3\n",
            "    0.50: F1=0.919, Precision=0.944, Recall=0.895, Missed Cancers=6\n",
            "    0.55: F1=0.919, Precision=0.944, Recall=0.895, Missed Cancers=6\n",
            "    0.30: F1=0.912, Precision=0.912, Recall=0.912, Missed Cancers=5\n",
            "    0.45: F1=0.911, Precision=0.927, Recall=0.895, Missed Cancers=6\n",
            "  ✅ Threshold analysis saved\n",
            "\n",
            "[STEP 8] Evaluating with Optimal Threshold (0.20)...\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "EVALUATION RESULTS (Threshold = 0.20)\n",
            "================================================================================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Normal     0.9054    0.8375    0.8701        80\n",
            "    Abnormal     0.8917    0.9386    0.9145       114\n",
            "\n",
            "    accuracy                         0.8969       194\n",
            "   macro avg     0.8985    0.8880    0.8923       194\n",
            "weighted avg     0.8973    0.8969    0.8962       194\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 67  13]\n",
            " [  7 107]]\n",
            "\n",
            "Detailed Metrics:\n",
            "  True Negatives (Correct Normal): 67\n",
            "  False Positives (Normal→Abnormal): 13\n",
            "  False Negatives (Missed Cancers): 7 ⚠️\n",
            "  True Positives (Caught Cancers): 107\n",
            "  Specificity: 0.8375\n",
            "  ROC-AUC Score: 0.9620\n",
            "\n",
            "================================================================================\n",
            "✅ IMPROVED PIPELINE COMPLETED!\n",
            "================================================================================\n",
            "📊 Final Results:\n",
            "   - Optimal Threshold: 0.20\n",
            "   - Test Accuracy: 89.69%\n",
            "   - ROC-AUC: 0.9620\n",
            "\n",
            "💾 Model saved: models_improved/final_model_improved.h5\n",
            "📝 Use threshold 0.20 in inference!\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "IMPROVED Cervical Cancer Detection - Inference Script\n",
        "Properly calibrated for better balance between sensitivity and specificity\n",
        "\n",
        "Features:\n",
        "1. Uses optimal threshold from training\n",
        "2. Test-time augmentation for more robust predictions\n",
        "3. Confidence calibration\n",
        "4. Detailed risk assessment\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "\n",
        "# ============================================================================\n",
        "# CONFIGURATION\n",
        "# ============================================================================\n",
        "\n",
        "class InferenceConfig:\n",
        "    # Model settings\n",
        "    MODEL_PATH = 'models_improved/final_model_improved.h5'\n",
        "    RESULTS_PATH = 'output_improved/results_improved.json'\n",
        "    IMG_SIZE = 224\n",
        "\n",
        "    # Load optimal threshold from training results\n",
        "    try:\n",
        "        with open('output_improved/results_improved.json', 'r') as f:\n",
        "            results = json.load(f)\n",
        "            OPTIMAL_THRESHOLD = results.get('optimal_threshold', 0.35)\n",
        "    except:\n",
        "        OPTIMAL_THRESHOLD = 0.35  # Fallback to balanced threshold\n",
        "\n",
        "    # Test-time augmentation\n",
        "    USE_TTA = True\n",
        "    TTA_STEPS = 5\n",
        "\n",
        "    # Class names\n",
        "    CLASS_NAMES = ['Normal', 'Abnormal']\n",
        "\n",
        "    # Risk thresholds - CALIBRATED\n",
        "    RISK_THRESHOLDS = {\n",
        "        'very_low': 0.2,\n",
        "        'low': 0.4,\n",
        "        'moderate': 0.6,\n",
        "        'high': 0.8\n",
        "    }\n",
        "\n",
        "config = InferenceConfig()\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"IMPROVED CERVICAL CANCER DETECTION - INFERENCE\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"Configuration:\")\n",
        "print(f\"  - Model: {config.MODEL_PATH}\")\n",
        "print(f\"  - Optimal Threshold: {config.OPTIMAL_THRESHOLD:.3f}\")\n",
        "print(f\"  - TTA: {config.USE_TTA} ({config.TTA_STEPS} augmentations)\")\n",
        "print(f\"  - Image Size: {config.IMG_SIZE}x{config.IMG_SIZE}\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# ============================================================================\n",
        "# LOAD MODEL\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n[1] Loading trained model...\")\n",
        "try:\n",
        "    model = load_model(config.MODEL_PATH)\n",
        "    print(f\"✅ Model loaded successfully\")\n",
        "    print(f\"✅ Using optimal threshold: {config.OPTIMAL_THRESHOLD:.3f}\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error loading model: {str(e)}\")\n",
        "    print(f\"   Make sure you've trained the improved model first\")\n",
        "    exit(1)\n",
        "\n",
        "# ============================================================================\n",
        "# IMPROVED PREDICTION WITH TTA\n",
        "# ============================================================================\n",
        "\n",
        "def preprocess_image(image_path, augment=False):\n",
        "    \"\"\"Load and preprocess image with optional augmentation\"\"\"\n",
        "    try:\n",
        "        img = cv2.imread(image_path)\n",
        "        if img is None:\n",
        "            raise ValueError(f\"Could not read: {image_path}\")\n",
        "\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = cv2.resize(img, (config.IMG_SIZE, config.IMG_SIZE))\n",
        "\n",
        "        # Optional augmentation for TTA\n",
        "        if augment:\n",
        "            # Random rotation\n",
        "            if np.random.rand() > 0.5:\n",
        "                angle = np.random.randint(-15, 15)\n",
        "                M = cv2.getRotationMatrix2D((config.IMG_SIZE/2, config.IMG_SIZE/2), angle, 1)\n",
        "                img = cv2.warpAffine(img, M, (config.IMG_SIZE, config.IMG_SIZE))\n",
        "\n",
        "            # Random flip\n",
        "            if np.random.rand() > 0.5:\n",
        "                img = cv2.flip(img, 1)\n",
        "            if np.random.rand() > 0.5:\n",
        "                img = cv2.flip(img, 0)\n",
        "\n",
        "        img = img / 255.0\n",
        "        img = np.expand_dims(img, axis=0)\n",
        "\n",
        "        return img\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error preprocessing: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def predict_with_tta(image_path):\n",
        "    \"\"\"Predict with test-time augmentation\"\"\"\n",
        "    if not config.USE_TTA:\n",
        "        img = preprocess_image(image_path, augment=False)\n",
        "        if img is None:\n",
        "            return None\n",
        "        prediction = model.predict(img, verbose=0)[0][0]\n",
        "        return prediction\n",
        "\n",
        "    # TTA: Average predictions from multiple augmentations\n",
        "    predictions = []\n",
        "\n",
        "    # Original image\n",
        "    img = preprocess_image(image_path, augment=False)\n",
        "    if img is not None:\n",
        "        pred = model.predict(img, verbose=0)[0][0]\n",
        "        predictions.append(pred)\n",
        "\n",
        "    # Augmented versions\n",
        "    for _ in range(config.TTA_STEPS - 1):\n",
        "        img = preprocess_image(image_path, augment=True)\n",
        "        if img is not None:\n",
        "            pred = model.predict(img, verbose=0)[0][0]\n",
        "            predictions.append(pred)\n",
        "\n",
        "    if len(predictions) == 0:\n",
        "        return None\n",
        "\n",
        "    # Average all predictions\n",
        "    avg_prediction = np.mean(predictions)\n",
        "\n",
        "    return avg_prediction\n",
        "\n",
        "def get_risk_level(score):\n",
        "    \"\"\"Get risk level from prediction score\"\"\"\n",
        "    if score < config.RISK_THRESHOLDS['very_low']:\n",
        "        return \"✅ VERY LOW RISK\", \"green\"\n",
        "    elif score < config.RISK_THRESHOLDS['low']:\n",
        "        return \"🟢 LOW RISK\", \"lightgreen\"\n",
        "    elif score < config.RISK_THRESHOLDS['moderate']:\n",
        "        return \"🟡 MODERATE RISK\", \"yellow\"\n",
        "    elif score < config.RISK_THRESHOLDS['high']:\n",
        "        return \"🟠 ELEVATED RISK\", \"orange\"\n",
        "    else:\n",
        "        return \"🔴 HIGH RISK\", \"red\"\n",
        "\n",
        "def predict_single_image(image_path, display=True):\n",
        "    \"\"\"Predict on a single image with improved accuracy\"\"\"\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"Analyzing: {os.path.basename(image_path)}\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    # Predict with TTA\n",
        "    prediction_proba = predict_with_tta(image_path)\n",
        "\n",
        "    if prediction_proba is None:\n",
        "        print(\"❌ Failed to process image\")\n",
        "        return None\n",
        "\n",
        "    # Use optimal threshold\n",
        "    prediction_class = 1 if prediction_proba >= config.OPTIMAL_THRESHOLD else 0\n",
        "    prediction_label = config.CLASS_NAMES[prediction_class]\n",
        "\n",
        "    # Calculate confidence\n",
        "    if prediction_class == 1:\n",
        "        confidence = (prediction_proba / config.OPTIMAL_THRESHOLD) * 50 + 50\n",
        "    else:\n",
        "        confidence = ((config.OPTIMAL_THRESHOLD - prediction_proba) / config.OPTIMAL_THRESHOLD) * 50 + 50\n",
        "\n",
        "    confidence = min(confidence, 100)\n",
        "\n",
        "    # Get risk level\n",
        "    risk_level, risk_color = get_risk_level(prediction_proba)\n",
        "\n",
        "    # Display results\n",
        "    print(f\"\\n📊 PREDICTION RESULTS:\")\n",
        "    print(f\"   Raw Score: {prediction_proba:.4f}\")\n",
        "    print(f\"   Threshold: {config.OPTIMAL_THRESHOLD:.3f}\")\n",
        "    print(f\"   Prediction: {prediction_label}\")\n",
        "    print(f\"   Confidence: {confidence:.1f}%\")\n",
        "    print(f\"   Risk Level: {risk_level}\")\n",
        "\n",
        "    # Clinical interpretation\n",
        "    print(f\"\\n🏥 CLINICAL INTERPRETATION:\")\n",
        "    if prediction_proba < 0.2:\n",
        "        print(f\"   → Cells appear normal\")\n",
        "        print(f\"   → Routine screening recommended\")\n",
        "    elif prediction_proba < 0.4:\n",
        "        print(f\"   → Minimal abnormalities detected\")\n",
        "        print(f\"   → Consider follow-up in 6-12 months\")\n",
        "    elif prediction_proba < 0.6:\n",
        "        print(f\"   → Moderate abnormalities detected\")\n",
        "        print(f\"   → Further testing recommended\")\n",
        "    elif prediction_proba < 0.8:\n",
        "        print(f\"   → Significant abnormalities detected\")\n",
        "        print(f\"   → Immediate follow-up required\")\n",
        "    else:\n",
        "        print(f\"   → Severe abnormalities detected\")\n",
        "        print(f\"   → Urgent medical evaluation needed\")\n",
        "\n",
        "    if display:\n",
        "        display_prediction(image_path, prediction_label, confidence, prediction_proba, risk_level)\n",
        "\n",
        "    return {\n",
        "        'image_path': image_path,\n",
        "        'prediction': prediction_label,\n",
        "        'confidence': confidence,\n",
        "        'raw_score': prediction_proba,\n",
        "        'risk_level': risk_level,\n",
        "        'threshold_used': config.OPTIMAL_THRESHOLD\n",
        "    }\n",
        "\n",
        "def display_prediction(image_path, prediction, confidence, raw_score, risk_level):\n",
        "    \"\"\"Display image with prediction\"\"\"\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "\n",
        "    color = 'red' if prediction == 'Abnormal' else 'green'\n",
        "\n",
        "    title = (f\"Prediction: {prediction}\\n\"\n",
        "            f\"Confidence: {confidence:.1f}%\\n\"\n",
        "            f\"Raw Score: {raw_score:.4f}\\n\"\n",
        "            f\"{risk_level}\")\n",
        "\n",
        "    plt.title(title, fontsize=14, fontweight='bold', color=color, pad=20)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def predict_batch(image_folder, save_results=True):\n",
        "    \"\"\"Batch prediction with detailed statistics\"\"\"\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"BATCH PREDICTION\")\n",
        "    print(f\"{'='*80}\")\n",
        "    print(f\"Folder: {image_folder}\")\n",
        "\n",
        "    # Get all images\n",
        "    image_extensions = ['.bmp', '.jpg', '.jpeg', '.png']\n",
        "    image_files = []\n",
        "\n",
        "    for ext in image_extensions:\n",
        "        image_files.extend([os.path.join(image_folder, f)\n",
        "                           for f in os.listdir(image_folder)\n",
        "                           if f.lower().endswith(ext)])\n",
        "\n",
        "    if not image_files:\n",
        "        print(f\"❌ No images found\")\n",
        "        return None\n",
        "\n",
        "    print(f\"\\nFound {len(image_files)} images\")\n",
        "    print(f\"Processing with TTA={config.USE_TTA}...\")\n",
        "\n",
        "    # Predict on each image\n",
        "    results = []\n",
        "    for image_path in tqdm(image_files, desc=\"Processing\"):\n",
        "        result = predict_single_image(image_path, display=False)\n",
        "        if result:\n",
        "            results.append(result)\n",
        "\n",
        "    # Detailed statistics\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"BATCH PREDICTION SUMMARY\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    normal_count = sum(1 for r in results if r['prediction'] == 'Normal')\n",
        "    abnormal_count = sum(1 for r in results if r['prediction'] == 'Abnormal')\n",
        "\n",
        "    print(f\"\\nTotal Processed: {len(results)}\")\n",
        "    print(f\"  - Normal: {normal_count} ({normal_count/len(results)*100:.1f}%)\")\n",
        "    print(f\"  - Abnormal: {abnormal_count} ({abnormal_count/len(results)*100:.1f}%)\")\n",
        "\n",
        "    # Risk breakdown\n",
        "    print(f\"\\n📊 Risk Level Distribution:\")\n",
        "    risk_counts = {}\n",
        "    for r in results:\n",
        "        risk = r['risk_level']\n",
        "        risk_counts[risk] = risk_counts.get(risk, 0) + 1\n",
        "\n",
        "    for risk, count in sorted(risk_counts.items()):\n",
        "        print(f\"   {risk}: {count} ({count/len(results)*100:.1f}%)\")\n",
        "\n",
        "    # Score distribution\n",
        "    scores = [r['raw_score'] for r in results]\n",
        "    print(f\"\\n📈 Score Statistics:\")\n",
        "    print(f\"   Mean: {np.mean(scores):.4f}\")\n",
        "    print(f\"   Median: {np.median(scores):.4f}\")\n",
        "    print(f\"   Std Dev: {np.std(scores):.4f}\")\n",
        "    print(f\"   Min: {np.min(scores):.4f}\")\n",
        "    print(f\"   Max: {np.max(scores):.4f}\")\n",
        "\n",
        "    # High risk cases\n",
        "    high_risk = [r for r in results if r['raw_score'] >= config.RISK_THRESHOLDS['high']]\n",
        "    if high_risk:\n",
        "        print(f\"\\n🔴 HIGH RISK CASES ({len(high_risk)}):\")\n",
        "        for r in sorted(high_risk, key=lambda x: x['raw_score'], reverse=True)[:10]:\n",
        "            print(f\"   - {os.path.basename(r['image_path'])}: {r['raw_score']:.4f}\")\n",
        "\n",
        "    # Save results\n",
        "    if save_results:\n",
        "        df = pd.DataFrame(results)\n",
        "        output_file = 'output_improved/batch_predictions.csv'\n",
        "        os.makedirs('output_improved', exist_ok=True)\n",
        "        df.to_csv(output_file, index=False)\n",
        "        print(f\"\\n✅ Results saved to {output_file}\")\n",
        "\n",
        "        # Plot score distribution\n",
        "        plot_score_distribution(scores, normal_count, abnormal_count)\n",
        "\n",
        "    return results\n",
        "\n",
        "def plot_score_distribution(scores, normal_count, abnormal_count):\n",
        "    \"\"\"Plot distribution of prediction scores\"\"\"\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "    # Histogram\n",
        "    axes[0].hist(scores, bins=50, color='skyblue', edgecolor='black', alpha=0.7)\n",
        "    axes[0].axvline(x=config.OPTIMAL_THRESHOLD, color='red', linestyle='--',\n",
        "                    linewidth=2, label=f'Threshold ({config.OPTIMAL_THRESHOLD:.3f})')\n",
        "    axes[0].set_xlabel('Prediction Score', fontsize=12)\n",
        "    axes[0].set_ylabel('Frequency', fontsize=12)\n",
        "    axes[0].set_title('Distribution of Prediction Scores', fontsize=14, fontweight='bold')\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(alpha=0.3)\n",
        "\n",
        "    # Pie chart\n",
        "    labels = [f'Normal\\n({normal_count})', f'Abnormal\\n({abnormal_count})']\n",
        "    sizes = [normal_count, abnormal_count]\n",
        "    colors = ['lightgreen', 'lightcoral']\n",
        "    explode = (0.05, 0.05)\n",
        "\n",
        "    axes[1].pie(sizes, explode=explode, labels=labels, colors=colors,\n",
        "                autopct='%1.1f%%', shadow=True, startangle=90, textprops={'fontsize': 12})\n",
        "    axes[1].set_title('Prediction Distribution', fontsize=14, fontweight='bold')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('output_improved/prediction_distribution.png', dpi=150, bbox_inches='tight')\n",
        "    print(f\"  ✅ Distribution plot saved\")\n",
        "    plt.close()\n",
        "\n",
        "def evaluate_on_labeled_data(test_folder, true_label_name):\n",
        "    \"\"\"Evaluate predictions on data with known labels\"\"\"\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"EVALUATION ON LABELED DATA\")\n",
        "    print(f\"{'='*80}\")\n",
        "    print(f\"Folder: {test_folder}\")\n",
        "    print(f\"True Label: {true_label_name}\")\n",
        "\n",
        "    # Determine true label (0=Normal, 1=Abnormal)\n",
        "    true_label = 1 if 'dysplastic' in true_label_name.lower() or 'carcinoma' in true_label_name.lower() else 0\n",
        "\n",
        "    results = predict_batch(test_folder, save_results=False)\n",
        "\n",
        "    if results is None:\n",
        "        return\n",
        "\n",
        "    # Calculate metrics\n",
        "    y_pred = [1 if r['prediction'] == 'Abnormal' else 0 for r in results]\n",
        "    y_true = [true_label] * len(results)\n",
        "\n",
        "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
        "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
        "\n",
        "    print(f\"\\n📊 Performance Metrics:\")\n",
        "    print(f\"   Accuracy: {accuracy*100:.2f}%\")\n",
        "    print(f\"   Precision: {precision*100:.2f}%\")\n",
        "    print(f\"   Recall: {recall*100:.2f}%\")\n",
        "    print(f\"   F1-Score: {f1*100:.2f}%\")\n",
        "\n",
        "    if true_label == 1:\n",
        "        missed = len(results) - sum(y_pred)\n",
        "        print(f\"\\n⚠️  Missed {missed} out of {len(results)} abnormal cases\")\n",
        "    else:\n",
        "        false_positives = sum(y_pred)\n",
        "        print(f\"\\n⚠️  {false_positives} out of {len(results)} normal cases flagged as abnormal\")\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1,\n",
        "        'results': results\n",
        "    }\n",
        "\n",
        "# ============================================================================\n",
        "# INTERACTIVE MODE\n",
        "# ============================================================================\n",
        "\n",
        "def interactive_mode():\n",
        "    \"\"\"Interactive prediction interface\"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"INTERACTIVE PREDICTION MODE\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"\\nOptions:\")\n",
        "    print(\"  1. Predict single image\")\n",
        "    print(\"  2. Predict batch of images\")\n",
        "    print(\"  3. Evaluate on labeled test data\")\n",
        "    print(\"  4. Change threshold\")\n",
        "    print(\"  5. Toggle TTA\")\n",
        "    print(\"  6. Exit\")\n",
        "\n",
        "    while True:\n",
        "        print(\"\\n\" + \"-\"*80)\n",
        "        choice = input(\"\\nSelect option (1-6): \").strip()\n",
        "\n",
        "        if choice == '1':\n",
        "            image_path = input(\"Enter image path: \").strip().strip('\"').strip(\"'\")\n",
        "            if os.path.exists(image_path):\n",
        "                predict_single_image(image_path, display=True)\n",
        "            else:\n",
        "                print(f\"❌ File not found\")\n",
        "\n",
        "        elif choice == '2':\n",
        "            folder_path = input(\"Enter folder path: \").strip().strip('\"').strip(\"'\")\n",
        "            if os.path.exists(folder_path):\n",
        "                predict_batch(folder_path)\n",
        "            else:\n",
        "                print(f\"❌ Folder not found\")\n",
        "\n",
        "        elif choice == '3':\n",
        "            folder_path = input(\"Enter test folder path: \").strip().strip('\"').strip(\"'\")\n",
        "            label_name = input(\"Enter true label (e.g., 'normal_columnar' or 'light_dysplastic'): \").strip()\n",
        "            if os.path.exists(folder_path):\n",
        "                evaluate_on_labeled_data(folder_path, label_name)\n",
        "            else:\n",
        "                print(f\"❌ Folder not found\")\n",
        "\n",
        "        elif choice == '4':\n",
        "            print(f\"\\nCurrent threshold: {config.OPTIMAL_THRESHOLD:.3f}\")\n",
        "            try:\n",
        "                new_threshold = float(input(\"Enter new threshold (0.0-1.0): \"))\n",
        "                if 0 <= new_threshold <= 1:\n",
        "                    config.OPTIMAL_THRESHOLD = new_threshold\n",
        "                    print(f\"✅ Threshold updated to {config.OPTIMAL_THRESHOLD:.3f}\")\n",
        "                else:\n",
        "                    print(\"❌ Invalid range\")\n",
        "            except:\n",
        "                print(\"❌ Invalid input\")\n",
        "\n",
        "        elif choice == '5':\n",
        "            config.USE_TTA = not config.USE_TTA\n",
        "            print(f\"✅ TTA {'enabled' if config.USE_TTA else 'disabled'}\")\n",
        "\n",
        "        elif choice == '6':\n",
        "            print(\"\\nExiting... Goodbye!\")\n",
        "            break\n",
        "\n",
        "        else:\n",
        "            print(\"❌ Invalid option\")\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n💡 IMPROVED INFERENCE SYSTEM\")\n",
        "print(f\"   Using optimal threshold: {config.OPTIMAL_THRESHOLD:.3f}\")\n",
        "print(f\"   TTA enabled: {config.USE_TTA}\")\n",
        "\n",
        "interactive_mode()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mMDnpBN-lc4",
        "outputId": "474df40a-f4db-41a0-ba48-e1ad10ef1bc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "IMPROVED CERVICAL CANCER DETECTION - INFERENCE\n",
            "================================================================================\n",
            "Configuration:\n",
            "  - Model: models_improved/final_model_improved.h5\n",
            "  - Optimal Threshold: 0.600\n",
            "  - TTA: True (5 augmentations)\n",
            "  - Image Size: 224x224\n",
            "================================================================================\n",
            "\n",
            "[1] Loading trained model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model loaded successfully\n",
            "✅ Using optimal threshold: 0.600\n",
            "\n",
            "💡 IMPROVED INFERENCE SYSTEM\n",
            "   Using optimal threshold: 0.600\n",
            "   TTA enabled: True\n",
            "\n",
            "================================================================================\n",
            "INTERACTIVE PREDICTION MODE\n",
            "================================================================================\n",
            "\n",
            "Options:\n",
            "  1. Predict single image\n",
            "  2. Predict batch of images\n",
            "  3. Evaluate on labeled test data\n",
            "  4. Change threshold\n",
            "  5. Toggle TTA\n",
            "  6. Exit\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Select option (1-6): 2\n",
            "Enter folder path: /content/herlev_normal\n",
            "\n",
            "================================================================================\n",
            "BATCH PREDICTION\n",
            "================================================================================\n",
            "Folder: /content/herlev_normal\n",
            "\n",
            "Found 73 images\n",
            "Processing with TTA=True...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   0%|          | 0/73 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "Analyzing: 209565409-209565466-001.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   1%|▏         | 1/73 [00:01<01:41,  1.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.1270\n",
            "   Threshold: 0.600\n",
            "   Prediction: Normal\n",
            "   Confidence: 89.4%\n",
            "   Risk Level: ✅ VERY LOW RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Cells appear normal\n",
            "   → Routine screening recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 158987493-158987505-001.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   3%|▎         | 2/73 [00:01<00:55,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.0712\n",
            "   Threshold: 0.600\n",
            "   Prediction: Normal\n",
            "   Confidence: 94.1%\n",
            "   Risk Level: ✅ VERY LOW RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Cells appear normal\n",
            "   → Routine screening recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 157185781-157185814-002.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   4%|▍         | 3/73 [00:02<00:41,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.9861\n",
            "   Threshold: 0.600\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🔴 HIGH RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Severe abnormalities detected\n",
            "   → Urgent medical evaluation needed\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209566205-209566321-001.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   5%|▌         | 4/73 [00:02<00:34,  2.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.0075\n",
            "   Threshold: 0.600\n",
            "   Prediction: Normal\n",
            "   Confidence: 99.4%\n",
            "   Risk Level: ✅ VERY LOW RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Cells appear normal\n",
            "   → Routine screening recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 157224172-157224207-003.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   7%|▋         | 5/73 [00:02<00:30,  2.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.9973\n",
            "   Threshold: 0.600\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🔴 HIGH RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Severe abnormalities detected\n",
            "   → Urgent medical evaluation needed\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209566399-209566485-001.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   8%|▊         | 6/73 [00:03<00:28,  2.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.0198\n",
            "   Threshold: 0.600\n",
            "   Prediction: Normal\n",
            "   Confidence: 98.4%\n",
            "   Risk Level: ✅ VERY LOW RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Cells appear normal\n",
            "   → Routine screening recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 157185781-157185814-001.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  10%|▉         | 7/73 [00:03<00:27,  2.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.9639\n",
            "   Threshold: 0.600\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🔴 HIGH RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Severe abnormalities detected\n",
            "   → Urgent medical evaluation needed\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 157268504-157268544-001.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  11%|█         | 8/73 [00:03<00:25,  2.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.8595\n",
            "   Threshold: 0.600\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🔴 HIGH RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Severe abnormalities detected\n",
            "   → Urgent medical evaluation needed\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209047881-209048017-001.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  12%|█▏        | 9/73 [00:04<00:24,  2.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.6189\n",
            "   Threshold: 0.600\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🟠 ELEVATED RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Significant abnormalities detected\n",
            "   → Immediate follow-up required\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 157267647-157267732-001.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  14%|█▎        | 10/73 [00:04<00:23,  2.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.5596\n",
            "   Threshold: 0.600\n",
            "   Prediction: Normal\n",
            "   Confidence: 53.4%\n",
            "   Risk Level: 🟡 MODERATE RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Moderate abnormalities detected\n",
            "   → Further testing recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209566047-209566125-001.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  15%|█▌        | 11/73 [00:04<00:22,  2.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.0450\n",
            "   Threshold: 0.600\n",
            "   Prediction: Normal\n",
            "   Confidence: 96.2%\n",
            "   Risk Level: ✅ VERY LOW RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Cells appear normal\n",
            "   → Routine screening recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 157267263-157267286-002.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  16%|█▋        | 12/73 [00:05<00:21,  2.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.9846\n",
            "   Threshold: 0.600\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🔴 HIGH RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Severe abnormalities detected\n",
            "   → Urgent medical evaluation needed\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209566205-209566266-001.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  18%|█▊        | 13/73 [00:05<00:21,  2.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.0632\n",
            "   Threshold: 0.600\n",
            "   Prediction: Normal\n",
            "   Confidence: 94.7%\n",
            "   Risk Level: ✅ VERY LOW RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Cells appear normal\n",
            "   → Routine screening recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209047526-209047798-001.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  19%|█▉        | 14/73 [00:06<00:20,  2.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.8111\n",
            "   Threshold: 0.600\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🔴 HIGH RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Severe abnormalities detected\n",
            "   → Urgent medical evaluation needed\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209565698-209565772-001.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  21%|██        | 15/73 [00:06<00:20,  2.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.3395\n",
            "   Threshold: 0.600\n",
            "   Prediction: Normal\n",
            "   Confidence: 71.7%\n",
            "   Risk Level: 🟢 LOW RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Minimal abnormalities detected\n",
            "   → Consider follow-up in 6-12 months\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 158987033-158987057-001.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  22%|██▏       | 16/73 [00:06<00:20,  2.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.7444\n",
            "   Threshold: 0.600\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🟠 ELEVATED RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Significant abnormalities detected\n",
            "   → Immediate follow-up required\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 157181569-157181599-001.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  23%|██▎       | 17/73 [00:07<00:19,  2.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.9167\n",
            "   Threshold: 0.600\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🔴 HIGH RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Severe abnormalities detected\n",
            "   → Urgent medical evaluation needed\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209566399-209566517-001.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  25%|██▍       | 18/73 [00:07<00:19,  2.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.9707\n",
            "   Threshold: 0.600\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🔴 HIGH RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Severe abnormalities detected\n",
            "   → Urgent medical evaluation needed\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 157224458-157224483-001.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  26%|██▌       | 19/73 [00:07<00:19,  2.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.7250\n",
            "   Threshold: 0.600\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🟠 ELEVATED RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Significant abnormalities detected\n",
            "   → Immediate follow-up required\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209565409-209565600-001.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  27%|██▋       | 20/73 [00:08<00:18,  2.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.0023\n",
            "   Threshold: 0.600\n",
            "   Prediction: Normal\n",
            "   Confidence: 99.8%\n",
            "   Risk Level: ✅ VERY LOW RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Cells appear normal\n",
            "   → Routine screening recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 157266930-157266947-003.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  29%|██▉       | 21/73 [00:08<00:18,  2.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.9630\n",
            "   Threshold: 0.600\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🔴 HIGH RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Severe abnormalities detected\n",
            "   → Urgent medical evaluation needed\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 158987453-158987462-001.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  30%|███       | 22/73 [00:08<00:18,  2.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.8445\n",
            "   Threshold: 0.600\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🔴 HIGH RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Severe abnormalities detected\n",
            "   → Urgent medical evaluation needed\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 157224172-157224207-002.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  32%|███▏      | 23/73 [00:09<00:17,  2.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.9988\n",
            "   Threshold: 0.600\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🔴 HIGH RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Severe abnormalities detected\n",
            "   → Urgent medical evaluation needed\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 158986920-158986928-003.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  33%|███▎      | 24/73 [00:09<00:17,  2.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.8929\n",
            "   Threshold: 0.600\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🔴 HIGH RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Severe abnormalities detected\n",
            "   → Urgent medical evaluation needed\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209566205-209566247-001.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  34%|███▍      | 25/73 [00:09<00:16,  2.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.0393\n",
            "   Threshold: 0.600\n",
            "   Prediction: Normal\n",
            "   Confidence: 96.7%\n",
            "   Risk Level: ✅ VERY LOW RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Cells appear normal\n",
            "   → Routine screening recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 158986813-158986820-001.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  36%|███▌      | 26/73 [00:10<00:16,  2.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.9984\n",
            "   Threshold: 0.600\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🔴 HIGH RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Severe abnormalities detected\n",
            "   → Urgent medical evaluation needed\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 157224412-157224429-001.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  37%|███▋      | 27/73 [00:10<00:17,  2.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.9149\n",
            "   Threshold: 0.600\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🔴 HIGH RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Severe abnormalities detected\n",
            "   → Urgent medical evaluation needed\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 158986766-158986776-001.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  38%|███▊      | 28/73 [00:11<00:18,  2.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.9881\n",
            "   Threshold: 0.600\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🔴 HIGH RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Severe abnormalities detected\n",
            "   → Urgent medical evaluation needed\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209048086-209048278-001.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  40%|███▉      | 29/73 [00:11<00:19,  2.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.3857\n",
            "   Threshold: 0.600\n",
            "   Prediction: Normal\n",
            "   Confidence: 67.9%\n",
            "   Risk Level: 🟢 LOW RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Minimal abnormalities detected\n",
            "   → Consider follow-up in 6-12 months\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 157267059-157267072-003.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  41%|████      | 30/73 [00:12<00:19,  2.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.9979\n",
            "   Threshold: 0.600\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🔴 HIGH RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Severe abnormalities detected\n",
            "   → Urgent medical evaluation needed\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 158986920-158986928-006.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  42%|████▏     | 31/73 [00:12<00:20,  2.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.9896\n",
            "   Threshold: 0.600\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🔴 HIGH RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Severe abnormalities detected\n",
            "   → Urgent medical evaluation needed\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209522940-209523052-001.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  44%|████▍     | 32/73 [00:13<00:18,  2.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.6610\n",
            "   Threshold: 0.600\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🟠 ELEVATED RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Significant abnormalities detected\n",
            "   → Immediate follow-up required\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 157267059-157267072-002.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  45%|████▌     | 33/73 [00:13<00:17,  2.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.9065\n",
            "   Threshold: 0.600\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🔴 HIGH RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Severe abnormalities detected\n",
            "   → Urgent medical evaluation needed\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209047526-209047717-001.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  47%|████▋     | 34/73 [00:13<00:15,  2.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.6389\n",
            "   Threshold: 0.600\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🟠 ELEVATED RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Significant abnormalities detected\n",
            "   → Immediate follow-up required\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209047342-209047400-001.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  48%|████▊     | 35/73 [00:14<00:14,  2.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.8708\n",
            "   Threshold: 0.600\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🔴 HIGH RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Severe abnormalities detected\n",
            "   → Urgent medical evaluation needed\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 157268342-157268401-001.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  49%|████▉     | 36/73 [00:14<00:14,  2.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.7284\n",
            "   Threshold: 0.600\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🟠 ELEVATED RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Significant abnormalities detected\n",
            "   → Immediate follow-up required\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209522940-209522970-001.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  51%|█████     | 37/73 [00:14<00:13,  2.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.5394\n",
            "   Threshold: 0.600\n",
            "   Prediction: Normal\n",
            "   Confidence: 55.0%\n",
            "   Risk Level: 🟡 MODERATE RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Moderate abnormalities detected\n",
            "   → Further testing recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 157266930-157266947-001.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  52%|█████▏    | 38/73 [00:15<00:12,  2.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.9503\n",
            "   Threshold: 0.600\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🔴 HIGH RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Severe abnormalities detected\n",
            "   → Urgent medical evaluation needed\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209565864-209565890-001.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  53%|█████▎    | 39/73 [00:15<00:12,  2.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.1643\n",
            "   Threshold: 0.600\n",
            "   Prediction: Normal\n",
            "   Confidence: 86.3%\n",
            "   Risk Level: ✅ VERY LOW RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Cells appear normal\n",
            "   → Routine screening recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209048086-209048137-001.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  55%|█████▍    | 40/73 [00:16<00:11,  2.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.0563\n",
            "   Threshold: 0.600\n",
            "   Prediction: Normal\n",
            "   Confidence: 95.3%\n",
            "   Risk Level: ✅ VERY LOW RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Cells appear normal\n",
            "   → Routine screening recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209565864-209565950-001.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  56%|█████▌    | 41/73 [00:16<00:11,  2.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.2636\n",
            "   Threshold: 0.600\n",
            "   Prediction: Normal\n",
            "   Confidence: 78.0%\n",
            "   Risk Level: 🟢 LOW RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Minimal abnormalities detected\n",
            "   → Consider follow-up in 6-12 months\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 158986920-158986928-001.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  58%|█████▊    | 42/73 [00:16<00:11,  2.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.9977\n",
            "   Threshold: 0.600\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🔴 HIGH RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Severe abnormalities detected\n",
            "   → Urgent medical evaluation needed\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 157267059-157267072-004.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  59%|█████▉    | 43/73 [00:17<00:11,  2.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.9765\n",
            "   Threshold: 0.600\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🔴 HIGH RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Severe abnormalities detected\n",
            "   → Urgent medical evaluation needed\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 157227461-157227503-001.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  60%|██████    | 44/73 [00:17<00:10,  2.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.9960\n",
            "   Threshold: 0.600\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🔴 HIGH RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Severe abnormalities detected\n",
            "   → Urgent medical evaluation needed\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 157267263-157267286-001.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  62%|██████▏   | 45/73 [00:17<00:10,  2.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.9991\n",
            "   Threshold: 0.600\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🔴 HIGH RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Severe abnormalities detected\n",
            "   → Urgent medical evaluation needed\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 157224172-157224207-001.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  63%|██████▎   | 46/73 [00:18<00:09,  2.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.9954\n",
            "   Threshold: 0.600\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🔴 HIGH RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Severe abnormalities detected\n",
            "   → Urgent medical evaluation needed\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209565864-209565911-001.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  64%|██████▍   | 47/73 [00:18<00:09,  2.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.0304\n",
            "   Threshold: 0.600\n",
            "   Prediction: Normal\n",
            "   Confidence: 97.5%\n",
            "   Risk Level: ✅ VERY LOW RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Cells appear normal\n",
            "   → Routine screening recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 157268242-157268296-001.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  66%|██████▌   | 48/73 [00:18<00:08,  2.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.9496\n",
            "   Threshold: 0.600\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🔴 HIGH RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Severe abnormalities detected\n",
            "   → Urgent medical evaluation needed\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209566205-209566289-001.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  67%|██████▋   | 49/73 [00:19<00:08,  2.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.0696\n",
            "   Threshold: 0.600\n",
            "   Prediction: Normal\n",
            "   Confidence: 94.2%\n",
            "   Risk Level: ✅ VERY LOW RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Cells appear normal\n",
            "   → Routine screening recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 158987493-158987499-001.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  68%|██████▊   | 50/73 [00:19<00:08,  2.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.1187\n",
            "   Threshold: 0.600\n",
            "   Prediction: Normal\n",
            "   Confidence: 90.1%\n",
            "   Risk Level: ✅ VERY LOW RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Cells appear normal\n",
            "   → Routine screening recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 158986920-158986928-004.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  70%|██████▉   | 51/73 [00:20<00:07,  2.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.9940\n",
            "   Threshold: 0.600\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🔴 HIGH RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Severe abnormalities detected\n",
            "   → Urgent medical evaluation needed\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209566399-209566464-001.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  71%|███████   | 52/73 [00:20<00:07,  2.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.0626\n",
            "   Threshold: 0.600\n",
            "   Prediction: Normal\n",
            "   Confidence: 94.8%\n",
            "   Risk Level: ✅ VERY LOW RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Cells appear normal\n",
            "   → Routine screening recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 158986766-158986776-002.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  73%|███████▎  | 53/73 [00:20<00:07,  2.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.9982\n",
            "   Threshold: 0.600\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🔴 HIGH RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Severe abnormalities detected\n",
            "   → Urgent medical evaluation needed\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 157267001-157267013-001.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  74%|███████▍  | 54/73 [00:21<00:06,  2.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.9820\n",
            "   Threshold: 0.600\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🔴 HIGH RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Severe abnormalities detected\n",
            "   → Urgent medical evaluation needed\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 157267059-157267072-001.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  75%|███████▌  | 55/73 [00:21<00:06,  2.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.9794\n",
            "   Threshold: 0.600\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🔴 HIGH RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Severe abnormalities detected\n",
            "   → Urgent medical evaluation needed\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209047342-209047443-001.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  77%|███████▋  | 56/73 [00:21<00:06,  2.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.9889\n",
            "   Threshold: 0.600\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🔴 HIGH RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Severe abnormalities detected\n",
            "   → Urgent medical evaluation needed\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 157224504-157224520-001.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  78%|███████▊  | 57/73 [00:22<00:05,  2.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.9532\n",
            "   Threshold: 0.600\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🔴 HIGH RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Severe abnormalities detected\n",
            "   → Urgent medical evaluation needed\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 158986920-158986928-005.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  79%|███████▉  | 58/73 [00:22<00:05,  2.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.9919\n",
            "   Threshold: 0.600\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🔴 HIGH RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Severe abnormalities detected\n",
            "   → Urgent medical evaluation needed\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 157227461-157227503-003.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  81%|████████  | 59/73 [00:22<00:05,  2.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.9938\n",
            "   Threshold: 0.600\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🔴 HIGH RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Severe abnormalities detected\n",
            "   → Urgent medical evaluation needed\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209565409-209565503-001.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  82%|████████▏ | 60/73 [00:23<00:05,  2.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.3861\n",
            "   Threshold: 0.600\n",
            "   Prediction: Normal\n",
            "   Confidence: 67.8%\n",
            "   Risk Level: 🟢 LOW RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Minimal abnormalities detected\n",
            "   → Consider follow-up in 6-12 months\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 157227058-157227087-001.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  84%|████████▎ | 61/73 [00:23<00:05,  2.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.9947\n",
            "   Threshold: 0.600\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🔴 HIGH RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Severe abnormalities detected\n",
            "   → Urgent medical evaluation needed\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 158986920-158986928-002.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  85%|████████▍ | 62/73 [00:24<00:05,  2.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.9923\n",
            "   Threshold: 0.600\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🔴 HIGH RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Severe abnormalities detected\n",
            "   → Urgent medical evaluation needed\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209565698-209565729-001.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  86%|████████▋ | 63/73 [00:25<00:05,  1.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.2086\n",
            "   Threshold: 0.600\n",
            "   Prediction: Normal\n",
            "   Confidence: 82.6%\n",
            "   Risk Level: 🟢 LOW RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Minimal abnormalities detected\n",
            "   → Consider follow-up in 6-12 months\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209522940-209522991-001.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  88%|████████▊ | 64/73 [00:25<00:04,  2.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.4677\n",
            "   Threshold: 0.600\n",
            "   Prediction: Normal\n",
            "   Confidence: 61.0%\n",
            "   Risk Level: 🟡 MODERATE RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Moderate abnormalities detected\n",
            "   → Further testing recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 157227461-157227503-002.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  89%|████████▉ | 65/73 [00:25<00:03,  2.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.9911\n",
            "   Threshold: 0.600\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🔴 HIGH RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Severe abnormalities detected\n",
            "   → Urgent medical evaluation needed\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 158986813-158986820-002.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  90%|█████████ | 66/73 [00:26<00:02,  2.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.9983\n",
            "   Threshold: 0.600\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🔴 HIGH RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Severe abnormalities detected\n",
            "   → Urgent medical evaluation needed\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209566047-209566095-001.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  92%|█████████▏| 67/73 [00:26<00:02,  2.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.3103\n",
            "   Threshold: 0.600\n",
            "   Prediction: Normal\n",
            "   Confidence: 74.1%\n",
            "   Risk Level: 🟢 LOW RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Minimal abnormalities detected\n",
            "   → Consider follow-up in 6-12 months\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 157268587-157268617-001.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  93%|█████████▎| 68/73 [00:26<00:01,  2.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.9170\n",
            "   Threshold: 0.600\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🔴 HIGH RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Severe abnormalities detected\n",
            "   → Urgent medical evaluation needed\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209307421-209307597-001.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  95%|█████████▍| 69/73 [00:27<00:01,  2.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.6023\n",
            "   Threshold: 0.600\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🟠 ELEVATED RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Significant abnormalities detected\n",
            "   → Immediate follow-up required\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 157266930-157266947-002.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  96%|█████████▌| 70/73 [00:27<00:01,  2.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.9660\n",
            "   Threshold: 0.600\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🔴 HIGH RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Severe abnormalities detected\n",
            "   → Urgent medical evaluation needed\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 157268342-157268376-001.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  97%|█████████▋| 71/73 [00:27<00:00,  2.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.9084\n",
            "   Threshold: 0.600\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🔴 HIGH RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Severe abnormalities detected\n",
            "   → Urgent medical evaluation needed\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209047342-209047478-001.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  99%|█████████▊| 72/73 [00:28<00:00,  2.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.9503\n",
            "   Threshold: 0.600\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🔴 HIGH RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Severe abnormalities detected\n",
            "   → Urgent medical evaluation needed\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209566205-209566333-001.BMP\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing: 100%|██████████| 73/73 [00:28<00:00,  2.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 PREDICTION RESULTS:\n",
            "   Raw Score: 0.0186\n",
            "   Threshold: 0.600\n",
            "   Prediction: Normal\n",
            "   Confidence: 98.4%\n",
            "   Risk Level: ✅ VERY LOW RISK\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Cells appear normal\n",
            "   → Routine screening recommended\n",
            "\n",
            "================================================================================\n",
            "BATCH PREDICTION SUMMARY\n",
            "================================================================================\n",
            "\n",
            "Total Processed: 73\n",
            "  - Normal: 24 (32.9%)\n",
            "  - Abnormal: 49 (67.1%)\n",
            "\n",
            "📊 Risk Level Distribution:\n",
            "   ✅ VERY LOW RISK: 15 (20.5%)\n",
            "   🔴 HIGH RISK: 42 (57.5%)\n",
            "   🟠 ELEVATED RISK: 7 (9.6%)\n",
            "   🟡 MODERATE RISK: 3 (4.1%)\n",
            "   🟢 LOW RISK: 6 (8.2%)\n",
            "\n",
            "📈 Score Statistics:\n",
            "   Mean: 0.6766\n",
            "   Median: 0.9065\n",
            "   Std Dev: 0.3721\n",
            "   Min: 0.0023\n",
            "   Max: 0.9991\n",
            "\n",
            "🔴 HIGH RISK CASES (42):\n",
            "   - 157267263-157267286-001.BMP: 0.9991\n",
            "   - 157224172-157224207-002.BMP: 0.9988\n",
            "   - 158986813-158986820-001.BMP: 0.9984\n",
            "   - 158986813-158986820-002.BMP: 0.9983\n",
            "   - 158986766-158986776-002.BMP: 0.9982\n",
            "   - 157267059-157267072-003.BMP: 0.9979\n",
            "   - 158986920-158986928-001.BMP: 0.9977\n",
            "   - 157224172-157224207-003.BMP: 0.9973\n",
            "   - 157227461-157227503-001.BMP: 0.9960\n",
            "   - 157224172-157224207-001.BMP: 0.9954\n",
            "\n",
            "✅ Results saved to output_improved/batch_predictions.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ Distribution plot saved\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Select option (1-6): 6\n",
            "\n",
            "Exiting... Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Cross-Dataset Evaluation and Domain Adaptation\n",
        "Solutions for testing on different datasets (SIPaKMeD → Herlev)\n",
        "\n",
        "Three approaches:\n",
        "1. Dataset recalibration (quick fix)\n",
        "2. Fine-tuning on target dataset\n",
        "3. Combined training (best solution)\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model, clone_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ============================================================================\n",
        "# CONFIGURATION\n",
        "# ============================================================================\n",
        "\n",
        "class CrossDatasetConfig:\n",
        "    # Source dataset (trained on)\n",
        "    SOURCE_MODEL = '/content/models_improved/final_model_improved.h5'\n",
        "    SOURCE_DATASET = r'/kaggle/input/cervical-cancer-largest-dataset-sipakmed'\n",
        "\n",
        "    # Target dataset (testing on)\n",
        "    TARGET_DATASET = r'/kaggle/input/herlev-dataset'  # Herlev\n",
        "\n",
        "    # Target class mapping\n",
        "    TARGET_NORMAL = ['normal_columnar', 'normal_intermediate', 'normal_superficial']\n",
        "    TARGET_ABNORMAL = ['carcinoma_in_situ', 'light_dysplastic', 'moderate_dysplastic', 'severe_dysplastic']\n",
        "\n",
        "    IMG_SIZE = 224\n",
        "    BATCH_SIZE = 16\n",
        "\n",
        "    # Output\n",
        "    OUTPUT_DIR = 'cross_dataset_results'\n",
        "\n",
        "config = CrossDatasetConfig()\n",
        "os.makedirs(config.OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"CROSS-DATASET EVALUATION AND ADAPTATION\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"Source: SIPaKMeD (trained)\")\n",
        "print(f\"Target: Herlev (testing)\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# ============================================================================\n",
        "# APPROACH 1: THRESHOLD RECALIBRATION\n",
        "# ============================================================================\n",
        "\n",
        "def approach_1_recalibrate_threshold():\n",
        "    \"\"\"\n",
        "    Quick fix: Find a new threshold specifically for the target dataset\n",
        "\n",
        "    How it works:\n",
        "    1. Take a small sample from target dataset\n",
        "    2. Get predictions\n",
        "    3. Find threshold that balances sensitivity/specificity\n",
        "    4. Use that threshold for all target predictions\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"APPROACH 1: THRESHOLD RECALIBRATION\")\n",
        "    print(\"=\" * 80)\n",
        "    print(\"📝 Strategy: Find optimal threshold for target dataset\")\n",
        "    print()\n",
        "\n",
        "    print(\"⚠️  LIMITATION: Requires some labeled target data for calibration\")\n",
        "    print(\"   You need ~50-100 images from target dataset with labels\")\n",
        "    print()\n",
        "\n",
        "    print(\"Steps:\")\n",
        "    print(\"1. Create a small validation set from Herlev dataset\")\n",
        "    print(\"2. Run predictions with current model\")\n",
        "    print(\"3. Try different thresholds (0.1 to 0.9)\")\n",
        "    print(\"4. Find threshold with best F1-score\")\n",
        "    print(\"5. Use that threshold for all Herlev predictions\")\n",
        "    print()\n",
        "\n",
        "    print(\"Expected improvement: 20-40%\")\n",
        "    print(\"Time required: 10 minutes\")\n",
        "    print(\"Code complexity: Low\")\n",
        "    print()\n",
        "\n",
        "    # Implementation\n",
        "    print(\"💻 Implementation:\")\n",
        "    print(\"\"\"\n",
        "# Pseudo-code:\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# 1. Load small calibration set from Herlev\n",
        "calibration_data = load_herlev_calibration_set(n_samples=100)\n",
        "\n",
        "# 2. Get predictions\n",
        "model = load_model('models/model_final.h5')\n",
        "scores = model.predict(calibration_data.images)\n",
        "\n",
        "# 3. Try different thresholds\n",
        "best_f1 = 0\n",
        "best_threshold = 0.5\n",
        "\n",
        "for threshold in np.arange(0.1, 0.9, 0.05):\n",
        "    predictions = (scores >= threshold).astype(int)\n",
        "    f1 = f1_score(calibration_data.labels, predictions)\n",
        "\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        best_threshold = threshold\n",
        "\n",
        "print(f\"Optimal threshold for Herlev: {best_threshold}\")\n",
        "\n",
        "# 4. Use this threshold for all Herlev predictions\n",
        "# (Update config.THRESHOLD in inference script)\n",
        "    \"\"\")\n",
        "\n",
        "# ============================================================================\n",
        "# APPROACH 2: FINE-TUNING ON TARGET DATASET\n",
        "# ============================================================================\n",
        "\n",
        "def approach_2_fine_tune():\n",
        "    \"\"\"\n",
        "    Medium solution: Fine-tune model on small amount of target data\n",
        "\n",
        "    How it works:\n",
        "    1. Load pre-trained model\n",
        "    2. Freeze early layers\n",
        "    3. Train only last few layers on target data\n",
        "    4. Requires ~200-500 labeled target images\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"APPROACH 2: FINE-TUNING ON TARGET DATASET\")\n",
        "    print(\"=\" * 80)\n",
        "    print(\"📝 Strategy: Adapt model to target dataset characteristics\")\n",
        "    print()\n",
        "\n",
        "    print(\"⚠️  REQUIREMENT: Need 200-500 labeled Herlev images\")\n",
        "    print(\"   - 100-250 normal cells\")\n",
        "    print(\"   - 100-250 abnormal cells\")\n",
        "    print()\n",
        "\n",
        "    print(\"Steps:\")\n",
        "    print(\"1. Load pre-trained SIPaKMeD model\")\n",
        "    print(\"2. Freeze base layers (keep learned features)\")\n",
        "    print(\"3. Unfreeze last 2-3 layers\")\n",
        "    print(\"4. Train on Herlev data with very low learning rate\")\n",
        "    print(\"5. Model learns to adapt to Herlev characteristics\")\n",
        "    print()\n",
        "\n",
        "    print(\"Expected improvement: 40-60%\")\n",
        "    print(\"Time required: 1-2 hours\")\n",
        "    print(\"Code complexity: Medium\")\n",
        "    print()\n",
        "\n",
        "    # Implementation\n",
        "    print(\"💻 Implementation:\")\n",
        "    print(\"\"\"\n",
        "# Load pre-trained model\n",
        "base_model = load_model('models/model_final.h5')\n",
        "\n",
        "# Freeze all layers except last 3\n",
        "for layer in base_model.layers[:-3]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile with very low learning rate\n",
        "base_model.compile(\n",
        "    optimizer=Adam(learning_rate=0.00001),  # Very low!\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Prepare Herlev data\n",
        "herlev_train_gen = create_herlev_generator(\n",
        "    path='dataset/test',\n",
        "    batch_size=16,\n",
        "    augmentation=True\n",
        ")\n",
        "\n",
        "# Fine-tune\n",
        "history = base_model.fit(\n",
        "    herlev_train_gen,\n",
        "    epochs=20,\n",
        "    callbacks=[\n",
        "        EarlyStopping(patience=5),\n",
        "        ModelCheckpoint('models/herlev_adapted.h5', save_best_only=True)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Now use this adapted model for Herlev predictions\n",
        "    \"\"\")\n",
        "\n",
        "# ============================================================================\n",
        "# APPROACH 3: COMBINED TRAINING (BEST SOLUTION)\n",
        "# ============================================================================\n",
        "\n",
        "def approach_3_combined_training():\n",
        "    \"\"\"\n",
        "    Best solution: Train on BOTH datasets together\n",
        "\n",
        "    How it works:\n",
        "    1. Combine SIPaKMeD + Herlev datasets\n",
        "    2. Train model on both simultaneously\n",
        "    3. Model learns features common to both\n",
        "    4. Best generalization\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"APPROACH 3: COMBINED TRAINING (RECOMMENDED)\")\n",
        "    print(\"=\" * 80)\n",
        "    print(\"📝 Strategy: Train on both datasets simultaneously\")\n",
        "    print()\n",
        "\n",
        "    print(\"✅ ADVANTAGES:\")\n",
        "    print(\"   - Best generalization across datasets\")\n",
        "    print(\"   - Model learns dataset-invariant features\")\n",
        "    print(\"   - Works on both SIPaKMeD and Herlev\")\n",
        "    print(\"   - No threshold tricks needed\")\n",
        "    print()\n",
        "\n",
        "    print(\"⚠️  REQUIREMENT: Full Herlev dataset with labels\")\n",
        "    print()\n",
        "\n",
        "    print(\"Steps:\")\n",
        "    print(\"1. Combine both datasets:\")\n",
        "    print(\"   - SIPaKMeD: Normal (im_Superficial-Intermediate, im_Metaplastic)\")\n",
        "    print(\"   - SIPaKMeD: Abnormal (im_Dyskeratotic, im_Koilocytotic, im_Parabasal)\")\n",
        "    print(\"   - Herlev: Normal (normal_*)\")\n",
        "    print(\"   - Herlev: Abnormal (*_dysplastic, carcinoma_in_situ)\")\n",
        "    print(\"2. Split combined dataset into train/val/test\")\n",
        "    print(\"3. Train fresh model on combined data\")\n",
        "    print(\"4. Model automatically learns to handle both\")\n",
        "    print()\n",
        "\n",
        "    print(\"Expected improvement: 60-80%\")\n",
        "    print(\"Time required: 2-3 hours (full retraining)\")\n",
        "    print(\"Code complexity: Low (just change dataset paths)\")\n",
        "    print()\n",
        "\n",
        "    # Implementation\n",
        "    print(\"💻 Implementation:\")\n",
        "    print(\"\"\"\n",
        "# 1. Create combined dataset dataframe\n",
        "sipakmed_df = create_sipakmed_dataframe('dataset')\n",
        "herlev_df = create_herlev_dataframe('dataset/test')\n",
        "\n",
        "# Combine\n",
        "combined_df = pd.concat([sipakmed_df, herlev_df], ignore_index=True)\n",
        "\n",
        "print(f\"Total samples: {len(combined_df)}\")\n",
        "print(f\"  SIPaKMeD: {len(sipakmed_df)}\")\n",
        "print(f\"  Herlev: {len(herlev_df)}\")\n",
        "\n",
        "# 2. Split combined dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, test_df = train_test_split(\n",
        "    combined_df,\n",
        "    test_size=0.2,\n",
        "    stratify=combined_df['label'],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Make sure test set has samples from BOTH datasets\n",
        "print(\"Test set composition:\")\n",
        "print(test_df['dataset_source'].value_counts())\n",
        "\n",
        "# 3. Train model on combined data (use existing training script)\n",
        "# Just point to combined_df instead of single dataset\n",
        "\n",
        "# 4. Evaluate on both datasets separately\n",
        "sipakmed_test = test_df[test_df['dataset_source'] == 'sipakmed']\n",
        "herlev_test = test_df[test_df['dataset_source'] == 'herlev']\n",
        "\n",
        "evaluate_model(model, sipakmed_test)  # Should work well\n",
        "evaluate_model(model, herlev_test)    # Should ALSO work well now!\n",
        "    \"\"\")\n",
        "\n",
        "# ============================================================================\n",
        "# PRACTICAL IMPLEMENTATION: COMBINED TRAINING\n",
        "# ============================================================================\n",
        "\n",
        "def create_combined_dataset():\n",
        "    \"\"\"Create combined dataset for training\"\"\"\n",
        "    print(\"\\n[Creating Combined Dataset]\")\n",
        "\n",
        "    all_data = []\n",
        "\n",
        "    # SIPaKMeD classes\n",
        "    sipakmed_classes = {\n",
        "        'im_Superficial-Intermediate': 0,\n",
        "        'im_Dyskeratotic': 1,\n",
        "        'im_Koilocytotic': 1,\n",
        "        'im_Parabasal': 1,\n",
        "        'im_Metaplastic': 0\n",
        "    }\n",
        "\n",
        "    print(\"\\nLoading SIPaKMeD...\")\n",
        "    for class_name, label in sipakmed_classes.items():\n",
        "        class_path = os.path.join(config.SOURCE_DATASET, class_name, class_name)\n",
        "\n",
        "        if not os.path.exists(class_path):\n",
        "            continue\n",
        "\n",
        "        images = [f for f in os.listdir(class_path) if f.endswith('.bmp')]\n",
        "        print(f\"  {class_name}: {len(images)} images\")\n",
        "\n",
        "        for img_name in images:\n",
        "            all_data.append({\n",
        "                'image_path': os.path.join(class_path, img_name),\n",
        "                'class_name': class_name,\n",
        "                'label': label,\n",
        "                'dataset_source': 'sipakmed'\n",
        "            })\n",
        "\n",
        "    # Herlev classes\n",
        "    print(\"\\nLoading Herlev...\")\n",
        "    for class_name in os.listdir(config.TARGET_DATASET):\n",
        "        class_path = os.path.join(config.TARGET_DATASET, class_name)\n",
        "\n",
        "        if not os.path.isdir(class_path):\n",
        "            continue\n",
        "\n",
        "        # Determine label\n",
        "        if class_name in config.TARGET_NORMAL:\n",
        "            label = 0\n",
        "        elif class_name in config.TARGET_ABNORMAL:\n",
        "            label = 1\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "        images = [f for f in os.listdir(class_path)\n",
        "                 if f.lower().endswith(('.bmp', '.jpg', '.png'))]\n",
        "        print(f\"  {class_name}: {len(images)} images\")\n",
        "\n",
        "        for img_name in images:\n",
        "            all_data.append({\n",
        "                'image_path': os.path.join(class_path, img_name),\n",
        "                'class_name': class_name,\n",
        "                'label': label,\n",
        "                'dataset_source': 'herlev'\n",
        "            })\n",
        "\n",
        "    df = pd.DataFrame(all_data)\n",
        "\n",
        "    print(f\"\\n✅ Combined Dataset Summary:\")\n",
        "    print(f\"   Total samples: {len(df)}\")\n",
        "    print(f\"   SIPaKMeD: {len(df[df['dataset_source']=='sipakmed'])}\")\n",
        "    print(f\"   Herlev: {len(df[df['dataset_source']=='herlev'])}\")\n",
        "    print(f\"   Normal: {len(df[df['label']==0])}\")\n",
        "    print(f\"   Abnormal: {len(df[df['label']==1])}\")\n",
        "\n",
        "    # Save\n",
        "    df.to_csv(os.path.join(config.OUTPUT_DIR, 'combined_dataset.csv'), index=False)\n",
        "    print(f\"\\n💾 Saved to: {config.OUTPUT_DIR}/combined_dataset.csv\")\n",
        "\n",
        "    return df\n",
        "\n",
        "# ============================================================================\n",
        "# COMPARISON SUMMARY\n",
        "# ============================================================================\n",
        "\n",
        "def print_comparison_table():\n",
        "    \"\"\"Print comparison of all approaches\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"APPROACH COMPARISON\")\n",
        "    print(\"=\" * 80)\n",
        "    print()\n",
        "\n",
        "    table = \"\"\"\n",
        "╔════════════════════════╦═══════════════╦═══════════╦═══════════╦═══════════════╗\n",
        "║ Approach               ║ Data Required ║ Time      ║ Complexity║ Improvement   ║\n",
        "╠════════════════════════╬═══════════════╬═══════════╬═══════════╬═══════════════╣\n",
        "║ 1. Threshold           ║ 50-100 images ║ 10 min    ║ Low       ║ 20-40%        ║\n",
        "║    Recalibration       ║ (labeled)     ║           ║           ║               ║\n",
        "╠════════════════════════╬═══════════════╬═══════════╬═══════════╬═══════════════╣\n",
        "║ 2. Fine-tuning         ║ 200-500 img   ║ 1-2 hours ║ Medium    ║ 40-60%        ║\n",
        "║                        ║ (labeled)     ║           ║           ║               ║\n",
        "╠════════════════════════╬═══════════════╬═══════════╬═══════════╬═══════════════╣\n",
        "║ 3. Combined Training   ║ Full dataset  ║ 2-3 hours ║ Low       ║ 60-80%        ║\n",
        "║    (RECOMMENDED) ⭐     ║ (both)        ║           ║           ║               ║\n",
        "╚════════════════════════╩═══════════════╩═══════════╩═══════════╩═══════════════╝\n",
        "    \"\"\"\n",
        "    print(table)\n",
        "\n",
        "    print(\"\\n🎯 RECOMMENDATION:\")\n",
        "    print(\"   Use Approach 3 (Combined Training) for best results\")\n",
        "    print()\n",
        "    print(\"   Why?\")\n",
        "    print(\"   ✅ Best generalization\")\n",
        "    print(\"   ✅ Works on multiple datasets\")\n",
        "    print(\"   ✅ Simple to implement (just combine data)\")\n",
        "    print(\"   ✅ Most robust in production\")\n",
        "    print()\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN\n",
        "# ============================================================================\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function\"\"\"\n",
        "    print(\"\\n📚 Understanding Cross-Dataset Performance\")\n",
        "    print(\"-\" * 80)\n",
        "    print(\"\"\"\n",
        "Your model was trained on SIPaKMeD dataset and tested on Herlev dataset.\n",
        "These are DIFFERENT datasets with different characteristics:\n",
        "\n",
        "SIPaKMeD characteristics:\n",
        "- Specific staining protocol\n",
        "- Particular image acquisition setup\n",
        "- One lab's interpretation of \"normal\" vs \"abnormal\"\n",
        "\n",
        "Herlev characteristics:\n",
        "- Different staining protocol\n",
        "- Different microscope/camera\n",
        "- Different lab's standards\n",
        "\n",
        "This is called DOMAIN SHIFT or DATASET SHIFT.\n",
        "\n",
        "It's like training a model to recognize dogs in indoor photos,\n",
        "then testing on outdoor photos - same objects, different context!\n",
        "    \"\"\")\n",
        "\n",
        "    print(\"\\n🔍 What's Happening:\")\n",
        "    print(\"   Your model predicts 75% of Herlev normals as abnormal because:\")\n",
        "    print(\"   1. Herlev 'normal' cells look different from SIPaKMeD 'normal'\")\n",
        "    print(\"   2. Color/texture/shape distributions are different\")\n",
        "    print(\"   3. Model has NEVER seen cells that look like Herlev cells\")\n",
        "    print()\n",
        "\n",
        "    # Show all approaches\n",
        "    approach_1_recalibrate_threshold()\n",
        "    approach_2_fine_tune()\n",
        "    approach_3_combined_training()\n",
        "\n",
        "    # Comparison\n",
        "    print_comparison_table()\n",
        "\n",
        "    # Try to create combined dataset\n",
        "    if os.path.exists(config.SOURCE_DATASET) and os.path.exists(config.TARGET_DATASET):\n",
        "        print(\"\\n[Attempting to create combined dataset...]\")\n",
        "        try:\n",
        "            combined_df = create_combined_dataset()\n",
        "            print(\"\\n✅ Combined dataset created!\")\n",
        "            print(\"   Now use this CSV in your training script:\")\n",
        "            print(f\"   df = pd.read_csv('{config.OUTPUT_DIR}/combined_dataset.csv')\")\n",
        "        except Exception as e:\n",
        "            print(f\"\\n⚠️  Could not create combined dataset: {e}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"NEXT STEPS\")\n",
        "    print(\"=\" * 80)\n",
        "    print(\"\"\"\n",
        "Option A: PROPER EVALUATION (Same Dataset)\n",
        "   → Run: python proper_test_evaluation.py\n",
        "   → This tests on held-out SIPaKMeD data (correct approach)\n",
        "   → Will show true model performance (~89% accuracy)\n",
        "\n",
        "Option B: CROSS-DATASET (Different Dataset)\n",
        "   → Modify training script to use combined_dataset.csv\n",
        "   → Retrain model on BOTH SIPaKMeD + Herlev\n",
        "   → Now model works on both datasets\n",
        "   → Expected: ~80-85% on both datasets\n",
        "\n",
        "Current Issue:\n",
        "   ❌ Training on SIPaKMeD, testing on Herlev (wrong!)\n",
        "   → This is why you see poor performance\n",
        "    \"\"\")\n",
        "\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DirwgC0-w9uM",
        "outputId": "1e9c7429-bad9-4fb5-9729-45927cf8741c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "CROSS-DATASET EVALUATION AND ADAPTATION\n",
            "================================================================================\n",
            "Source: SIPaKMeD (trained)\n",
            "Target: Herlev (testing)\n",
            "================================================================================\n",
            "\n",
            "📚 Understanding Cross-Dataset Performance\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Your model was trained on SIPaKMeD dataset and tested on Herlev dataset.\n",
            "These are DIFFERENT datasets with different characteristics:\n",
            "\n",
            "SIPaKMeD characteristics:\n",
            "- Specific staining protocol\n",
            "- Particular image acquisition setup\n",
            "- One lab's interpretation of \"normal\" vs \"abnormal\"\n",
            "\n",
            "Herlev characteristics:\n",
            "- Different staining protocol\n",
            "- Different microscope/camera\n",
            "- Different lab's standards\n",
            "\n",
            "This is called DOMAIN SHIFT or DATASET SHIFT.\n",
            "\n",
            "It's like training a model to recognize dogs in indoor photos,\n",
            "then testing on outdoor photos - same objects, different context!\n",
            "    \n",
            "\n",
            "🔍 What's Happening:\n",
            "   Your model predicts 75% of Herlev normals as abnormal because:\n",
            "   1. Herlev 'normal' cells look different from SIPaKMeD 'normal'\n",
            "   2. Color/texture/shape distributions are different\n",
            "   3. Model has NEVER seen cells that look like Herlev cells\n",
            "\n",
            "\n",
            "================================================================================\n",
            "APPROACH 1: THRESHOLD RECALIBRATION\n",
            "================================================================================\n",
            "📝 Strategy: Find optimal threshold for target dataset\n",
            "\n",
            "⚠️  LIMITATION: Requires some labeled target data for calibration\n",
            "   You need ~50-100 images from target dataset with labels\n",
            "\n",
            "Steps:\n",
            "1. Create a small validation set from Herlev dataset\n",
            "2. Run predictions with current model\n",
            "3. Try different thresholds (0.1 to 0.9)\n",
            "4. Find threshold with best F1-score\n",
            "5. Use that threshold for all Herlev predictions\n",
            "\n",
            "Expected improvement: 20-40%\n",
            "Time required: 10 minutes\n",
            "Code complexity: Low\n",
            "\n",
            "💻 Implementation:\n",
            "\n",
            "# Pseudo-code:\n",
            "from sklearn.metrics import f1_score\n",
            "\n",
            "# 1. Load small calibration set from Herlev\n",
            "calibration_data = load_herlev_calibration_set(n_samples=100)\n",
            "\n",
            "# 2. Get predictions\n",
            "model = load_model('models/model_final.h5')\n",
            "scores = model.predict(calibration_data.images)\n",
            "\n",
            "# 3. Try different thresholds\n",
            "best_f1 = 0\n",
            "best_threshold = 0.5\n",
            "\n",
            "for threshold in np.arange(0.1, 0.9, 0.05):\n",
            "    predictions = (scores >= threshold).astype(int)\n",
            "    f1 = f1_score(calibration_data.labels, predictions)\n",
            "    \n",
            "    if f1 > best_f1:\n",
            "        best_f1 = f1\n",
            "        best_threshold = threshold\n",
            "\n",
            "print(f\"Optimal threshold for Herlev: {best_threshold}\")\n",
            "\n",
            "# 4. Use this threshold for all Herlev predictions\n",
            "# (Update config.THRESHOLD in inference script)\n",
            "    \n",
            "\n",
            "================================================================================\n",
            "APPROACH 2: FINE-TUNING ON TARGET DATASET\n",
            "================================================================================\n",
            "📝 Strategy: Adapt model to target dataset characteristics\n",
            "\n",
            "⚠️  REQUIREMENT: Need 200-500 labeled Herlev images\n",
            "   - 100-250 normal cells\n",
            "   - 100-250 abnormal cells\n",
            "\n",
            "Steps:\n",
            "1. Load pre-trained SIPaKMeD model\n",
            "2. Freeze base layers (keep learned features)\n",
            "3. Unfreeze last 2-3 layers\n",
            "4. Train on Herlev data with very low learning rate\n",
            "5. Model learns to adapt to Herlev characteristics\n",
            "\n",
            "Expected improvement: 40-60%\n",
            "Time required: 1-2 hours\n",
            "Code complexity: Medium\n",
            "\n",
            "💻 Implementation:\n",
            "\n",
            "# Load pre-trained model\n",
            "base_model = load_model('models/model_final.h5')\n",
            "\n",
            "# Freeze all layers except last 3\n",
            "for layer in base_model.layers[:-3]:\n",
            "    layer.trainable = False\n",
            "\n",
            "# Compile with very low learning rate\n",
            "base_model.compile(\n",
            "    optimizer=Adam(learning_rate=0.00001),  # Very low!\n",
            "    loss='binary_crossentropy',\n",
            "    metrics=['accuracy']\n",
            ")\n",
            "\n",
            "# Prepare Herlev data\n",
            "herlev_train_gen = create_herlev_generator(\n",
            "    path='dataset/test',\n",
            "    batch_size=16,\n",
            "    augmentation=True\n",
            ")\n",
            "\n",
            "# Fine-tune\n",
            "history = base_model.fit(\n",
            "    herlev_train_gen,\n",
            "    epochs=20,\n",
            "    callbacks=[\n",
            "        EarlyStopping(patience=5),\n",
            "        ModelCheckpoint('models/herlev_adapted.h5', save_best_only=True)\n",
            "    ]\n",
            ")\n",
            "\n",
            "# Now use this adapted model for Herlev predictions\n",
            "    \n",
            "\n",
            "================================================================================\n",
            "APPROACH 3: COMBINED TRAINING (RECOMMENDED)\n",
            "================================================================================\n",
            "📝 Strategy: Train on both datasets simultaneously\n",
            "\n",
            "✅ ADVANTAGES:\n",
            "   - Best generalization across datasets\n",
            "   - Model learns dataset-invariant features\n",
            "   - Works on both SIPaKMeD and Herlev\n",
            "   - No threshold tricks needed\n",
            "\n",
            "⚠️  REQUIREMENT: Full Herlev dataset with labels\n",
            "\n",
            "Steps:\n",
            "1. Combine both datasets:\n",
            "   - SIPaKMeD: Normal (im_Superficial-Intermediate, im_Metaplastic)\n",
            "   - SIPaKMeD: Abnormal (im_Dyskeratotic, im_Koilocytotic, im_Parabasal)\n",
            "   - Herlev: Normal (normal_*)\n",
            "   - Herlev: Abnormal (*_dysplastic, carcinoma_in_situ)\n",
            "2. Split combined dataset into train/val/test\n",
            "3. Train fresh model on combined data\n",
            "4. Model automatically learns to handle both\n",
            "\n",
            "Expected improvement: 60-80%\n",
            "Time required: 2-3 hours (full retraining)\n",
            "Code complexity: Low (just change dataset paths)\n",
            "\n",
            "💻 Implementation:\n",
            "\n",
            "# 1. Create combined dataset dataframe\n",
            "sipakmed_df = create_sipakmed_dataframe('dataset')\n",
            "herlev_df = create_herlev_dataframe('dataset/test')\n",
            "\n",
            "# Combine\n",
            "combined_df = pd.concat([sipakmed_df, herlev_df], ignore_index=True)\n",
            "\n",
            "print(f\"Total samples: {len(combined_df)}\")\n",
            "print(f\"  SIPaKMeD: {len(sipakmed_df)}\")\n",
            "print(f\"  Herlev: {len(herlev_df)}\")\n",
            "\n",
            "# 2. Split combined dataset\n",
            "from sklearn.model_selection import train_test_split\n",
            "\n",
            "train_df, test_df = train_test_split(\n",
            "    combined_df, \n",
            "    test_size=0.2, \n",
            "    stratify=combined_df['label'],\n",
            "    random_state=42\n",
            ")\n",
            "\n",
            "# Make sure test set has samples from BOTH datasets\n",
            "print(\"Test set composition:\")\n",
            "print(test_df['dataset_source'].value_counts())\n",
            "\n",
            "# 3. Train model on combined data (use existing training script)\n",
            "# Just point to combined_df instead of single dataset\n",
            "\n",
            "# 4. Evaluate on both datasets separately\n",
            "sipakmed_test = test_df[test_df['dataset_source'] == 'sipakmed']\n",
            "herlev_test = test_df[test_df['dataset_source'] == 'herlev']\n",
            "\n",
            "evaluate_model(model, sipakmed_test)  # Should work well\n",
            "evaluate_model(model, herlev_test)    # Should ALSO work well now!\n",
            "    \n",
            "\n",
            "================================================================================\n",
            "APPROACH COMPARISON\n",
            "================================================================================\n",
            "\n",
            "\n",
            "╔════════════════════════╦═══════════════╦═══════════╦═══════════╦═══════════════╗\n",
            "║ Approach               ║ Data Required ║ Time      ║ Complexity║ Improvement   ║\n",
            "╠════════════════════════╬═══════════════╬═══════════╬═══════════╬═══════════════╣\n",
            "║ 1. Threshold           ║ 50-100 images ║ 10 min    ║ Low       ║ 20-40%        ║\n",
            "║    Recalibration       ║ (labeled)     ║           ║           ║               ║\n",
            "╠════════════════════════╬═══════════════╬═══════════╬═══════════╬═══════════════╣\n",
            "║ 2. Fine-tuning         ║ 200-500 img   ║ 1-2 hours ║ Medium    ║ 40-60%        ║\n",
            "║                        ║ (labeled)     ║           ║           ║               ║\n",
            "╠════════════════════════╬═══════════════╬═══════════╬═══════════╬═══════════════╣\n",
            "║ 3. Combined Training   ║ Full dataset  ║ 2-3 hours ║ Low       ║ 60-80%        ║\n",
            "║    (RECOMMENDED) ⭐     ║ (both)        ║           ║           ║               ║\n",
            "╚════════════════════════╩═══════════════╩═══════════╩═══════════╩═══════════════╝\n",
            "    \n",
            "\n",
            "🎯 RECOMMENDATION:\n",
            "   Use Approach 3 (Combined Training) for best results\n",
            "\n",
            "   Why?\n",
            "   ✅ Best generalization\n",
            "   ✅ Works on multiple datasets\n",
            "   ✅ Simple to implement (just combine data)\n",
            "   ✅ Most robust in production\n",
            "\n",
            "\n",
            "[Attempting to create combined dataset...]\n",
            "\n",
            "[Creating Combined Dataset]\n",
            "\n",
            "Loading SIPaKMeD...\n",
            "  im_Superficial-Intermediate: 126 images\n",
            "  im_Dyskeratotic: 223 images\n",
            "  im_Koilocytotic: 238 images\n",
            "  im_Parabasal: 108 images\n",
            "  im_Metaplastic: 271 images\n",
            "\n",
            "Loading Herlev...\n",
            "\n",
            "✅ Combined Dataset Summary:\n",
            "   Total samples: 966\n",
            "   SIPaKMeD: 966\n",
            "   Herlev: 0\n",
            "   Normal: 397\n",
            "   Abnormal: 569\n",
            "\n",
            "💾 Saved to: cross_dataset_results/combined_dataset.csv\n",
            "\n",
            "✅ Combined dataset created!\n",
            "   Now use this CSV in your training script:\n",
            "   df = pd.read_csv('cross_dataset_results/combined_dataset.csv')\n",
            "\n",
            "================================================================================\n",
            "NEXT STEPS\n",
            "================================================================================\n",
            "\n",
            "Option A: PROPER EVALUATION (Same Dataset)\n",
            "   → Run: python proper_test_evaluation.py\n",
            "   → This tests on held-out SIPaKMeD data (correct approach)\n",
            "   → Will show true model performance (~89% accuracy)\n",
            "\n",
            "Option B: CROSS-DATASET (Different Dataset)\n",
            "   → Modify training script to use combined_dataset.csv\n",
            "   → Retrain model on BOTH SIPaKMeD + Herlev\n",
            "   → Now model works on both datasets\n",
            "   → Expected: ~80-85% on both datasets\n",
            "\n",
            "Current Issue:\n",
            "   ❌ Training on SIPaKMeD, testing on Herlev (wrong!)\n",
            "   → This is why you see poor performance\n",
            "    \n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Cervical Cancer Detection - Combined Dataset Training\n",
        "Train model on BOTH SIPaKMeD + Herlev for cross-dataset generalization\n",
        "\n",
        "This model will work on BOTH datasets!\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16, ResNet50, EfficientNetB0\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ============================================================================\n",
        "# CONFIGURATION\n",
        "# ============================================================================\n",
        "\n",
        "class Config:\n",
        "    # IMPORTANT: Use the combined dataset CSV\n",
        "    COMBINED_CSV = 'cross_dataset_results/combined_dataset.csv'\n",
        "\n",
        "    # Model configuration\n",
        "    IMG_SIZE = 224\n",
        "    BATCH_SIZE = 16  # Reduced for better generalization\n",
        "    EPOCHS_FROZEN = 50  # Increased for combined data\n",
        "    EPOCHS_FINE_TUNE = 30\n",
        "    LEARNING_RATE_FROZEN = 0.0001\n",
        "    LEARNING_RATE_FINE_TUNE = 0.00001\n",
        "\n",
        "    # Model selection\n",
        "    BASE_MODEL = 'VGG16'  # or 'ResNet50', 'EfficientNetB0'\n",
        "\n",
        "    # Split ratios\n",
        "    TEST_SIZE = 0.2\n",
        "    VAL_SIZE = 0.125\n",
        "    RANDOM_STATE = 42\n",
        "\n",
        "    # Class weights\n",
        "    USE_CLASS_WEIGHTS = True\n",
        "\n",
        "    # Output directories\n",
        "    OUTPUT_DIR = 'output_combined'\n",
        "    MODEL_DIR = 'models_combined'\n",
        "    PLOTS_DIR = 'plots_combined'\n",
        "\n",
        "config = Config()\n",
        "\n",
        "# Create directories\n",
        "for dir_path in [config.OUTPUT_DIR, config.MODEL_DIR, config.PLOTS_DIR]:\n",
        "    os.makedirs(dir_path, exist_ok=True)\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"COMBINED DATASET TRAINING\")\n",
        "print(\"Training on BOTH SIPaKMeD + Herlev for cross-dataset generalization\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"Configuration:\")\n",
        "print(f\"  - Combined CSV: {config.COMBINED_CSV}\")\n",
        "print(f\"  - Image Size: {config.IMG_SIZE}x{config.IMG_SIZE}\")\n",
        "print(f\"  - Batch Size: {config.BATCH_SIZE}\")\n",
        "print(f\"  - Base Model: {config.BASE_MODEL}\")\n",
        "print(f\"  - Class Weights: {config.USE_CLASS_WEIGHTS}\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 1: LOAD AND ANALYZE COMBINED DATASET\n",
        "# ============================================================================\n",
        "\n",
        "def load_combined_dataset(csv_path):\n",
        "    \"\"\"Load the combined dataset CSV\"\"\"\n",
        "    print(\"\\n[STEP 1] Loading Combined Dataset...\")\n",
        "\n",
        "    if not os.path.exists(csv_path):\n",
        "        print(f\"❌ ERROR: Combined CSV not found at {csv_path}\")\n",
        "        print(f\"\\n💡 Run this first: python cross_dataset_solution.py\")\n",
        "        return None\n",
        "\n",
        "    df = pd.read_csv(csv_path)\n",
        "\n",
        "    print(f\"\\n✅ Loaded {len(df)} samples\")\n",
        "    print(f\"\\n📊 Dataset Composition:\")\n",
        "    print(f\"   SIPaKMeD: {len(df[df['dataset_source']=='sipakmed'])} images\")\n",
        "    print(f\"   Herlev: {len(df[df['dataset_source']=='herlev'])} images\")\n",
        "\n",
        "    print(f\"\\n📊 Label Distribution:\")\n",
        "    normal_count = len(df[df['label']==0])\n",
        "    abnormal_count = len(df[df['label']==1])\n",
        "    print(f\"   Normal: {normal_count} ({normal_count/len(df)*100:.1f}%)\")\n",
        "    print(f\"   Abnormal: {abnormal_count} ({abnormal_count/len(df)*100:.1f}%)\")\n",
        "\n",
        "    print(f\"\\n📊 Classes per Dataset:\")\n",
        "    print(f\"\\n   SIPaKMeD classes:\")\n",
        "    sipakmed = df[df['dataset_source']=='sipakmed']\n",
        "    for class_name in sipakmed['class_name'].unique():\n",
        "        count = len(sipakmed[sipakmed['class_name']==class_name])\n",
        "        label = sipakmed[sipakmed['class_name']==class_name]['label'].iloc[0]\n",
        "        label_name = 'Normal' if label == 0 else 'Abnormal'\n",
        "        print(f\"      {class_name}: {count} ({label_name})\")\n",
        "\n",
        "    print(f\"\\n   Herlev classes:\")\n",
        "    herlev = df[df['dataset_source']=='herlev']\n",
        "    for class_name in herlev['class_name'].unique():\n",
        "        count = len(herlev[herlev['class_name']==class_name])\n",
        "        label = herlev[herlev['class_name']==class_name]['label'].iloc[0]\n",
        "        label_name = 'Normal' if label == 0 else 'Abnormal'\n",
        "        print(f\"      {class_name}: {count} ({label_name})\")\n",
        "\n",
        "    # Verify all image paths exist\n",
        "    print(f\"\\n[Verifying image paths...]\")\n",
        "    missing = 0\n",
        "    for idx, row in df.iterrows():\n",
        "        if not os.path.exists(row['image_path']):\n",
        "            if missing == 0:\n",
        "                print(f\"   ⚠️  Some images not found:\")\n",
        "            print(f\"      {row['image_path']}\")\n",
        "            missing += 1\n",
        "            if missing >= 5:\n",
        "                print(f\"      ... and {len(df) - idx - 1} more to check\")\n",
        "                break\n",
        "\n",
        "    if missing == 0:\n",
        "        print(f\"   ✅ All image paths valid\")\n",
        "    else:\n",
        "        print(f\"\\n   ⚠️  {missing} images not found - these will be skipped\")\n",
        "\n",
        "    return df\n",
        "\n",
        "def visualize_combined_dataset(df):\n",
        "    \"\"\"Visualize samples from both datasets\"\"\"\n",
        "    print(\"\\n[STEP 2] Visualizing Combined Dataset...\")\n",
        "\n",
        "    fig, axes = plt.subplots(4, 6, figsize=(18, 12))\n",
        "\n",
        "    # Row 1: SIPaKMeD Normal\n",
        "    sipakmed_normal = df[(df['dataset_source']=='sipakmed') & (df['label']==0)]\n",
        "    if len(sipakmed_normal) > 0:\n",
        "        samples = sipakmed_normal.sample(n=min(6, len(sipakmed_normal)), random_state=42)\n",
        "        for i, (_, row) in enumerate(samples.iterrows()):\n",
        "            if i < 6 and os.path.exists(row['image_path']):\n",
        "                img = cv2.imread(row['image_path'])\n",
        "                if img is not None:\n",
        "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "                    img = cv2.resize(img, (config.IMG_SIZE, config.IMG_SIZE))\n",
        "                    axes[0, i].imshow(img)\n",
        "                    axes[0, i].axis('off')\n",
        "                    if i == 0:\n",
        "                        axes[0, i].set_title('SIPaKMeD\\nNormal', fontsize=8, fontweight='bold')\n",
        "\n",
        "    # Row 2: SIPaKMeD Abnormal\n",
        "    sipakmed_abnormal = df[(df['dataset_source']=='sipakmed') & (df['label']==1)]\n",
        "    if len(sipakmed_abnormal) > 0:\n",
        "        samples = sipakmed_abnormal.sample(n=min(6, len(sipakmed_abnormal)), random_state=42)\n",
        "        for i, (_, row) in enumerate(samples.iterrows()):\n",
        "            if i < 6 and os.path.exists(row['image_path']):\n",
        "                img = cv2.imread(row['image_path'])\n",
        "                if img is not None:\n",
        "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "                    img = cv2.resize(img, (config.IMG_SIZE, config.IMG_SIZE))\n",
        "                    axes[1, i].imshow(img)\n",
        "                    axes[1, i].axis('off')\n",
        "                    if i == 0:\n",
        "                        axes[1, i].set_title('SIPaKMeD\\nAbnormal', fontsize=8, fontweight='bold')\n",
        "\n",
        "    # Row 3: Herlev Normal\n",
        "    herlev_normal = df[(df['dataset_source']=='herlev') & (df['label']==0)]\n",
        "    if len(herlev_normal) > 0:\n",
        "        samples = herlev_normal.sample(n=min(6, len(herlev_normal)), random_state=42)\n",
        "        for i, (_, row) in enumerate(samples.iterrows()):\n",
        "            if i < 6 and os.path.exists(row['image_path']):\n",
        "                img = cv2.imread(row['image_path'])\n",
        "                if img is not None:\n",
        "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "                    img = cv2.resize(img, (config.IMG_SIZE, config.IMG_SIZE))\n",
        "                    axes[2, i].imshow(img)\n",
        "                    axes[2, i].axis('off')\n",
        "                    if i == 0:\n",
        "                        axes[2, i].set_title('Herlev\\nNormal', fontsize=8, fontweight='bold')\n",
        "\n",
        "    # Row 4: Herlev Abnormal\n",
        "    herlev_abnormal = df[(df['dataset_source']=='herlev') & (df['label']==1)]\n",
        "    if len(herlev_abnormal) > 0:\n",
        "        samples = herlev_abnormal.sample(n=min(6, len(herlev_abnormal)), random_state=42)\n",
        "        for i, (_, row) in enumerate(samples.iterrows()):\n",
        "            if i < 6 and os.path.exists(row['image_path']):\n",
        "                img = cv2.imread(row['image_path'])\n",
        "                if img is not None:\n",
        "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "                    img = cv2.resize(img, (config.IMG_SIZE, config.IMG_SIZE))\n",
        "                    axes[3, i].imshow(img)\n",
        "                    axes[3, i].axis('off')\n",
        "                    if i == 0:\n",
        "                        axes[3, i].set_title('Herlev\\nAbnormal', fontsize=8, fontweight='bold')\n",
        "\n",
        "    plt.suptitle('Combined Dataset: SIPaKMeD + Herlev', fontsize=14, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(config.PLOTS_DIR, 'combined_dataset_samples.png'), dpi=150, bbox_inches='tight')\n",
        "    print(f\"   ✅ Saved visualization to {config.PLOTS_DIR}/combined_dataset_samples.png\")\n",
        "    plt.close()\n",
        "\n",
        "def split_combined_dataset(df):\n",
        "    \"\"\"Split combined dataset ensuring both datasets in each split\"\"\"\n",
        "    print(\"\\n[STEP 3] Splitting Combined Dataset...\")\n",
        "\n",
        "    # Strategy: Split within each dataset, then combine\n",
        "    # This ensures both datasets are represented in train/val/test\n",
        "\n",
        "    sipakmed_df = df[df['dataset_source']=='sipakmed']\n",
        "    herlev_df = df[df['dataset_source']=='herlev']\n",
        "\n",
        "    # Split SIPaKMeD\n",
        "    sip_train_val, sip_test = train_test_split(\n",
        "        sipakmed_df,\n",
        "        test_size=config.TEST_SIZE,\n",
        "        stratify=sipakmed_df['label'],\n",
        "        random_state=config.RANDOM_STATE\n",
        "    )\n",
        "\n",
        "    sip_train, sip_val = train_test_split(\n",
        "        sip_train_val,\n",
        "        test_size=config.VAL_SIZE,\n",
        "        stratify=sip_train_val['label'],\n",
        "        random_state=config.RANDOM_STATE\n",
        "    )\n",
        "\n",
        "    # Split Herlev (if enough samples)\n",
        "    if len(herlev_df) > 20:\n",
        "        her_train_val, her_test = train_test_split(\n",
        "            herlev_df,\n",
        "            test_size=config.TEST_SIZE,\n",
        "            stratify=herlev_df['label'],\n",
        "            random_state=config.RANDOM_STATE\n",
        "        )\n",
        "\n",
        "        her_train, her_val = train_test_split(\n",
        "            her_train_val,\n",
        "            test_size=config.VAL_SIZE,\n",
        "            stratify=her_train_val['label'],\n",
        "            random_state=config.RANDOM_STATE\n",
        "        )\n",
        "    else:\n",
        "        # If Herlev is small, use it all for testing\n",
        "        her_train = pd.DataFrame()\n",
        "        her_val = pd.DataFrame()\n",
        "        her_test = herlev_df\n",
        "\n",
        "    # Combine splits\n",
        "    train_df = pd.concat([sip_train, her_train], ignore_index=True)\n",
        "    val_df = pd.concat([sip_val, her_val], ignore_index=True)\n",
        "    test_df = pd.concat([sip_test, her_test], ignore_index=True)\n",
        "\n",
        "    def print_split_stats(split_df, split_name):\n",
        "        print(f\"\\n   {split_name}:\")\n",
        "        print(f\"      Total: {len(split_df)}\")\n",
        "        print(f\"      SIPaKMeD: {len(split_df[split_df['dataset_source']=='sipakmed'])}\")\n",
        "        print(f\"      Herlev: {len(split_df[split_df['dataset_source']=='herlev'])}\")\n",
        "        print(f\"      Normal: {len(split_df[split_df['label']==0])} ({len(split_df[split_df['label']==0])/len(split_df)*100:.1f}%)\")\n",
        "        print(f\"      Abnormal: {len(split_df[split_df['label']==1])} ({len(split_df[split_df['label']==1])/len(split_df)*100:.1f}%)\")\n",
        "\n",
        "    print_split_stats(train_df, \"Training Set\")\n",
        "    print_split_stats(val_df, \"Validation Set\")\n",
        "    print_split_stats(test_df, \"Test Set\")\n",
        "\n",
        "    # Save splits\n",
        "    train_df.to_csv(os.path.join(config.OUTPUT_DIR, 'train_split_combined.csv'), index=False)\n",
        "    val_df.to_csv(os.path.join(config.OUTPUT_DIR, 'val_split_combined.csv'), index=False)\n",
        "    test_df.to_csv(os.path.join(config.OUTPUT_DIR, 'test_split_combined.csv'), index=False)\n",
        "    print(f\"\\n   ✅ Splits saved to {config.OUTPUT_DIR}/\")\n",
        "\n",
        "    return train_df, val_df, test_df\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 2: DATA GENERATORS\n",
        "# ============================================================================\n",
        "\n",
        "def create_data_generators(train_df, val_df, test_df):\n",
        "    \"\"\"Create data generators with strong augmentation\"\"\"\n",
        "    print(\"\\n[STEP 4] Creating Data Generators...\")\n",
        "\n",
        "    # Convert labels to strings\n",
        "    train_df = train_df.copy()\n",
        "    val_df = val_df.copy()\n",
        "    test_df = test_df.copy()\n",
        "\n",
        "    train_df['label_str'] = train_df['label'].astype(str)\n",
        "    val_df['label_str'] = val_df['label'].astype(str)\n",
        "    test_df['label_str'] = test_df['label'].astype(str)\n",
        "\n",
        "    # Strong augmentation to handle both datasets\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        rotation_range=30,\n",
        "        width_shift_range=0.3,\n",
        "        height_shift_range=0.3,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=True,\n",
        "        zoom_range=0.3,\n",
        "        shear_range=0.2,\n",
        "        brightness_range=[0.7, 1.3],  # Important for different staining\n",
        "        fill_mode='nearest'\n",
        "    )\n",
        "\n",
        "    val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    train_generator = train_datagen.flow_from_dataframe(\n",
        "        train_df,\n",
        "        x_col='image_path',\n",
        "        y_col='label_str',\n",
        "        target_size=(config.IMG_SIZE, config.IMG_SIZE),\n",
        "        batch_size=config.BATCH_SIZE,\n",
        "        class_mode='binary',\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    val_generator = val_test_datagen.flow_from_dataframe(\n",
        "        val_df,\n",
        "        x_col='image_path',\n",
        "        y_col='label_str',\n",
        "        target_size=(config.IMG_SIZE, config.IMG_SIZE),\n",
        "        batch_size=config.BATCH_SIZE,\n",
        "        class_mode='binary',\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    test_generator = val_test_datagen.flow_from_dataframe(\n",
        "        test_df,\n",
        "        x_col='image_path',\n",
        "        y_col='label_str',\n",
        "        target_size=(config.IMG_SIZE, config.IMG_SIZE),\n",
        "        batch_size=config.BATCH_SIZE,\n",
        "        class_mode='binary',\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    print(f\"   ✅ Train generator: {len(train_generator)} batches\")\n",
        "    print(f\"   ✅ Validation generator: {len(val_generator)} batches\")\n",
        "    print(f\"   ✅ Test generator: {len(test_generator)} batches\")\n",
        "\n",
        "    return train_generator, val_generator, test_generator\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 3: MODEL BUILDING\n",
        "# ============================================================================\n",
        "\n",
        "def build_model(model_name='VGG16'):\n",
        "    \"\"\"Build model with good regularization\"\"\"\n",
        "    print(f\"\\n[STEP 5] Building Model ({model_name})...\")\n",
        "\n",
        "    if model_name == 'VGG16':\n",
        "        base_model = VGG16(\n",
        "            weights='imagenet',\n",
        "            include_top=False,\n",
        "            input_shape=(config.IMG_SIZE, config.IMG_SIZE, 3)\n",
        "        )\n",
        "    elif model_name == 'ResNet50':\n",
        "        base_model = ResNet50(\n",
        "            weights='imagenet',\n",
        "            include_top=False,\n",
        "            input_shape=(config.IMG_SIZE, config.IMG_SIZE, 3)\n",
        "        )\n",
        "    elif model_name == 'EfficientNetB0':\n",
        "        base_model = EfficientNetB0(\n",
        "            weights='imagenet',\n",
        "            include_top=False,\n",
        "            input_shape=(config.IMG_SIZE, config.IMG_SIZE, 3)\n",
        "        )\n",
        "\n",
        "    base_model.trainable = False\n",
        "\n",
        "    # Classification head with regularization\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "    print(f\"   ✅ Model built\")\n",
        "\n",
        "    return model, base_model\n",
        "\n",
        "def compute_class_weights(train_df):\n",
        "    \"\"\"Compute class weights\"\"\"\n",
        "    if not config.USE_CLASS_WEIGHTS:\n",
        "        return None\n",
        "\n",
        "    print(\"\\n[STEP 6] Computing Class Weights...\")\n",
        "\n",
        "    labels = train_df['label'].values\n",
        "    class_weights = compute_class_weight('balanced', classes=np.unique(labels), y=labels)\n",
        "    class_weight_dict = dict(enumerate(class_weights))\n",
        "\n",
        "    print(f\"   Class 0 (Normal) weight: {class_weight_dict[0]:.3f}\")\n",
        "    print(f\"   Class 1 (Abnormal) weight: {class_weight_dict[1]:.3f}\")\n",
        "\n",
        "    return class_weight_dict\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 4: TRAINING\n",
        "# ============================================================================\n",
        "\n",
        "def train_model(model, train_gen, val_gen, epochs, class_weights, phase_name):\n",
        "    \"\"\"Train model\"\"\"\n",
        "    print(f\"\\n[STEP 7] Training - {phase_name}...\")\n",
        "\n",
        "    callbacks = [\n",
        "        ModelCheckpoint(\n",
        "            os.path.join(config.MODEL_DIR, f'best_model_{phase_name.lower().replace(\" \", \"_\")}.h5'),\n",
        "            monitor='val_loss',\n",
        "            save_best_only=True,\n",
        "            verbose=1\n",
        "        ),\n",
        "        EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=15,\n",
        "            verbose=1,\n",
        "            restore_best_weights=True\n",
        "        ),\n",
        "        ReduceLROnPlateau(\n",
        "            monitor='val_loss',\n",
        "            factor=0.5,\n",
        "            patience=7,\n",
        "            min_lr=1e-7,\n",
        "            verbose=1\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    history = model.fit(\n",
        "        train_gen,\n",
        "        epochs=epochs,\n",
        "        validation_data=val_gen,\n",
        "        callbacks=callbacks,\n",
        "        class_weight=class_weights,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    return history\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 5: EVALUATION - SEPARATE BY DATASET\n",
        "# ============================================================================\n",
        "\n",
        "def evaluate_by_dataset(model, test_df):\n",
        "    \"\"\"Evaluate separately on SIPaKMeD and Herlev\"\"\"\n",
        "    print(\"\\n[STEP 8] Evaluating on Both Datasets Separately...\")\n",
        "\n",
        "    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for dataset_name in ['sipakmed', 'herlev']:\n",
        "        dataset_df = test_df[test_df['dataset_source']==dataset_name]\n",
        "\n",
        "        if len(dataset_df) == 0:\n",
        "            print(f\"\\n   ⚠️  No {dataset_name} samples in test set\")\n",
        "            continue\n",
        "\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"EVALUATION ON {dataset_name.upper()}\")\n",
        "        print(f\"{'='*80}\")\n",
        "\n",
        "        # Create generator\n",
        "        dataset_df = dataset_df.copy()\n",
        "        dataset_df['label_str'] = dataset_df['label'].astype(str)\n",
        "\n",
        "        datagen = ImageDataGenerator(rescale=1./255)\n",
        "        generator = datagen.flow_from_dataframe(\n",
        "            dataset_df,\n",
        "            x_col='image_path',\n",
        "            y_col='label_str',\n",
        "            target_size=(config.IMG_SIZE, config.IMG_SIZE),\n",
        "            batch_size=config.BATCH_SIZE,\n",
        "            class_mode='binary',\n",
        "            shuffle=False\n",
        "        )\n",
        "\n",
        "        # Predict\n",
        "        predictions = model.predict(generator, verbose=1)\n",
        "        y_pred_proba = predictions.flatten()\n",
        "        y_pred = (y_pred_proba >= 0.5).astype(int)\n",
        "        y_true = dataset_df['label'].values\n",
        "\n",
        "        # Metrics\n",
        "        print(f\"\\nClassification Report:\")\n",
        "        print(classification_report(y_true, y_pred, target_names=['Normal', 'Abnormal'], digits=4))\n",
        "\n",
        "        cm = confusion_matrix(y_true, y_pred)\n",
        "        print(f\"\\nConfusion Matrix:\")\n",
        "        print(cm)\n",
        "\n",
        "        tn, fp, fn, tp = cm.ravel()\n",
        "        accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "\n",
        "        print(f\"\\nKey Metrics:\")\n",
        "        print(f\"   Accuracy: {accuracy*100:.2f}%\")\n",
        "        print(f\"   Sensitivity: {sensitivity*100:.2f}%\")\n",
        "        print(f\"   Specificity: {specificity*100:.2f}%\")\n",
        "        print(f\"   Missed Cancers: {fn}\")\n",
        "\n",
        "        roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
        "        print(f\"   ROC-AUC: {roc_auc:.4f}\")\n",
        "\n",
        "        results[dataset_name] = {\n",
        "            'accuracy': accuracy,\n",
        "            'sensitivity': sensitivity,\n",
        "            'specificity': specificity,\n",
        "            'roc_auc': roc_auc,\n",
        "            'missed_cancers': int(fn)\n",
        "        }\n",
        "\n",
        "    return results\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN PIPELINE\n",
        "# ============================================================================\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main training pipeline\"\"\"\n",
        "\n",
        "    try:\n",
        "        # Step 1: Load combined dataset\n",
        "        df = load_combined_dataset(config.COMBINED_CSV)\n",
        "        if df is None:\n",
        "            return\n",
        "\n",
        "        # Step 2: Visualize\n",
        "        visualize_combined_dataset(df)\n",
        "\n",
        "        # Step 3: Split\n",
        "        train_df, val_df, test_df = split_combined_dataset(df)\n",
        "\n",
        "        # Step 4: Create generators\n",
        "        train_gen, val_gen, test_gen = create_data_generators(train_df, val_df, test_df)\n",
        "\n",
        "        # Step 5: Build model\n",
        "        model, base_model = build_model(config.BASE_MODEL)\n",
        "\n",
        "        # Step 6: Compute class weights\n",
        "        class_weights = compute_class_weights(train_df)\n",
        "\n",
        "        # Compile\n",
        "        model.compile(\n",
        "            optimizer=Adam(learning_rate=config.LEARNING_RATE_FROZEN),\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy',\n",
        "                    tf.keras.metrics.Precision(name='precision'),\n",
        "                    tf.keras.metrics.Recall(name='recall'),\n",
        "                    tf.keras.metrics.AUC(name='auc')]\n",
        "        )\n",
        "\n",
        "        # Step 7: Training Phase 1 (Frozen)\n",
        "        history = train_model(\n",
        "            model, train_gen, val_gen,\n",
        "            config.EPOCHS_FROZEN, class_weights,\n",
        "            \"Phase 1 Frozen\"\n",
        "        )\n",
        "\n",
        "        # Step 8: Fine-tuning\n",
        "        print(\"\\n[STEP 7.5] Unfreezing for Fine-tuning...\")\n",
        "        base_model.trainable = True\n",
        "\n",
        "        model.compile(\n",
        "            optimizer=Adam(learning_rate=config.LEARNING_RATE_FINE_TUNE),\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy',\n",
        "                    tf.keras.metrics.Precision(name='precision'),\n",
        "                    tf.keras.metrics.Recall(name='recall'),\n",
        "                    tf.keras.metrics.AUC(name='auc')]\n",
        "        )\n",
        "\n",
        "        history_fine = train_model(\n",
        "            model, train_gen, val_gen,\n",
        "            config.EPOCHS_FINE_TUNE, class_weights,\n",
        "            \"Phase 2 Fine-tune\"\n",
        "        )\n",
        "\n",
        "        # Step 9: Evaluate separately on each dataset\n",
        "        results = evaluate_by_dataset(model, test_df)\n",
        "\n",
        "        # Step 10: Save final model\n",
        "        final_model_path = os.path.join(config.MODEL_DIR, 'final_model_combined.h5')\n",
        "        model.save(final_model_path)\n",
        "\n",
        "        # Save results\n",
        "        import json\n",
        "        with open(os.path.join(config.OUTPUT_DIR, 'combined_results.json'), 'w') as f:\n",
        "            json.dump(results, f, indent=4)\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"✅ TRAINING COMPLETE!\")\n",
        "        print(\"=\" * 80)\n",
        "        print(f\"\\n📊 Results Summary:\")\n",
        "        for dataset, metrics in results.items():\n",
        "            print(f\"\\n   {dataset.upper()}:\")\n",
        "            print(f\"      Accuracy: {metrics['accuracy']*100:.2f}%\")\n",
        "            print(f\"      Sensitivity: {metrics['sensitivity']*100:.2f}%\")\n",
        "            print(f\"      Specificity: {metrics['specificity']*100:.2f}%\")\n",
        "            print(f\"      ROC-AUC: {metrics['roc_auc']:.4f}\")\n",
        "            print(f\"      Missed Cancers: {metrics['missed_cancers']}\")\n",
        "\n",
        "        print(f\"\\n💾 Model saved: {final_model_path}\")\n",
        "        print(f\"\\n🎯 This model now works on BOTH datasets!\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n❌ Error: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Check GPU\n",
        "    gpus = tf.config.list_physical_devices('GPU')\n",
        "    if gpus:\n",
        "        print(f\"✅ GPU detected: {len(gpus)}\")\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    else:\n",
        "        print(\"⚠️  Running on CPU\")\n",
        "\n",
        "    print(f\"✅ TensorFlow: {tf.__version__}\")\n",
        "\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb8c086b-c363-436c-b3a9-60955edb1e56",
        "id": "ivpX8qSqx1o3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "COMBINED DATASET TRAINING\n",
            "Training on BOTH SIPaKMeD + Herlev for cross-dataset generalization\n",
            "================================================================================\n",
            "Configuration:\n",
            "  - Combined CSV: cross_dataset_results/combined_dataset.csv\n",
            "  - Image Size: 224x224\n",
            "  - Batch Size: 16\n",
            "  - Base Model: VGG16\n",
            "  - Class Weights: True\n",
            "================================================================================\n",
            "✅ GPU detected: 1\n",
            "✅ TensorFlow: 2.19.0\n",
            "\n",
            "[STEP 1] Loading Combined Dataset...\n",
            "\n",
            "✅ Loaded 966 samples\n",
            "\n",
            "📊 Dataset Composition:\n",
            "   SIPaKMeD: 966 images\n",
            "   Herlev: 0 images\n",
            "\n",
            "📊 Label Distribution:\n",
            "   Normal: 397 (41.1%)\n",
            "   Abnormal: 569 (58.9%)\n",
            "\n",
            "📊 Classes per Dataset:\n",
            "\n",
            "   SIPaKMeD classes:\n",
            "      im_Superficial-Intermediate: 126 (Normal)\n",
            "      im_Dyskeratotic: 223 (Abnormal)\n",
            "      im_Koilocytotic: 238 (Abnormal)\n",
            "      im_Parabasal: 108 (Abnormal)\n",
            "      im_Metaplastic: 271 (Normal)\n",
            "\n",
            "   Herlev classes:\n",
            "\n",
            "[Verifying image paths...]\n",
            "   ✅ All image paths valid\n",
            "\n",
            "[STEP 2] Visualizing Combined Dataset...\n",
            "   ✅ Saved visualization to plots_combined/combined_dataset_samples.png\n",
            "\n",
            "[STEP 3] Splitting Combined Dataset...\n",
            "\n",
            "   Training Set:\n",
            "      Total: 675\n",
            "      SIPaKMeD: 675\n",
            "      Herlev: 0\n",
            "      Normal: 277 (41.0%)\n",
            "      Abnormal: 398 (59.0%)\n",
            "\n",
            "   Validation Set:\n",
            "      Total: 97\n",
            "      SIPaKMeD: 97\n",
            "      Herlev: 0\n",
            "      Normal: 40 (41.2%)\n",
            "      Abnormal: 57 (58.8%)\n",
            "\n",
            "   Test Set:\n",
            "      Total: 194\n",
            "      SIPaKMeD: 194\n",
            "      Herlev: 0\n",
            "      Normal: 80 (41.2%)\n",
            "      Abnormal: 114 (58.8%)\n",
            "\n",
            "   ✅ Splits saved to output_combined/\n",
            "\n",
            "[STEP 4] Creating Data Generators...\n",
            "Found 675 validated image filenames belonging to 2 classes.\n",
            "Found 97 validated image filenames belonging to 2 classes.\n",
            "Found 194 validated image filenames belonging to 2 classes.\n",
            "   ✅ Train generator: 43 batches\n",
            "   ✅ Validation generator: 7 batches\n",
            "   ✅ Test generator: 13 batches\n",
            "\n",
            "[STEP 5] Building Model (VGG16)...\n",
            "   ✅ Model built\n",
            "\n",
            "[STEP 6] Computing Class Weights...\n",
            "   Class 0 (Normal) weight: 1.218\n",
            "   Class 1 (Abnormal) weight: 0.848\n",
            "\n",
            "[STEP 7] Training - Phase 1 Frozen...\n",
            "Epoch 1/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463ms/step - accuracy: 0.5335 - auc: 0.5986 - loss: 1.8162 - precision: 0.7249 - recall: 0.3593\n",
            "Epoch 1: val_loss improved from inf to 1.71738, saving model to models_combined/best_model_phase_1_frozen.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 564ms/step - accuracy: 0.5330 - auc: 0.5983 - loss: 1.8163 - precision: 0.7238 - recall: 0.3587 - val_accuracy: 0.4330 - val_auc: 0.7149 - val_loss: 1.7174 - val_precision: 1.0000 - val_recall: 0.0351 - learning_rate: 1.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step - accuracy: 0.5471 - auc: 0.6261 - loss: 1.7613 - precision: 0.7069 - recall: 0.4127\n",
            "Epoch 2: val_loss did not improve from 1.71738\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 396ms/step - accuracy: 0.5473 - auc: 0.6260 - loss: 1.7611 - precision: 0.7069 - recall: 0.4131 - val_accuracy: 0.4227 - val_auc: 0.7816 - val_loss: 1.7331 - val_precision: 1.0000 - val_recall: 0.0175 - learning_rate: 1.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347ms/step - accuracy: 0.5982 - auc: 0.6559 - loss: 1.7297 - precision: 0.7602 - recall: 0.4976\n",
            "Epoch 3: val_loss did not improve from 1.71738\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 371ms/step - accuracy: 0.5981 - auc: 0.6560 - loss: 1.7294 - precision: 0.7597 - recall: 0.4972 - val_accuracy: 0.4227 - val_auc: 0.7877 - val_loss: 1.7359 - val_precision: 1.0000 - val_recall: 0.0175 - learning_rate: 1.0000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348ms/step - accuracy: 0.5721 - auc: 0.6674 - loss: 1.7083 - precision: 0.7015 - recall: 0.4848\n",
            "Epoch 4: val_loss improved from 1.71738 to 1.70634, saving model to models_combined/best_model_phase_1_frozen.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 378ms/step - accuracy: 0.5727 - auc: 0.6679 - loss: 1.7078 - precision: 0.7020 - recall: 0.4857 - val_accuracy: 0.4433 - val_auc: 0.8022 - val_loss: 1.7063 - val_precision: 0.8000 - val_recall: 0.0702 - learning_rate: 1.0000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m42/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - accuracy: 0.6521 - auc: 0.7255 - loss: 1.6395 - precision: 0.7511 - recall: 0.6070\n",
            "Epoch 5: val_loss improved from 1.70634 to 1.66750, saving model to models_combined/best_model_phase_1_frozen.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 400ms/step - accuracy: 0.6525 - auc: 0.7258 - loss: 1.6393 - precision: 0.7514 - recall: 0.6078 - val_accuracy: 0.5567 - val_auc: 0.8252 - val_loss: 1.6675 - val_precision: 0.9375 - val_recall: 0.2632 - learning_rate: 1.0000e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354ms/step - accuracy: 0.6787 - auc: 0.7692 - loss: 1.5839 - precision: 0.7652 - recall: 0.6165\n",
            "Epoch 6: val_loss improved from 1.66750 to 1.64970, saving model to models_combined/best_model_phase_1_frozen.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 384ms/step - accuracy: 0.6788 - auc: 0.7691 - loss: 1.5842 - precision: 0.7658 - recall: 0.6169 - val_accuracy: 0.5876 - val_auc: 0.8292 - val_loss: 1.6497 - val_precision: 0.9474 - val_recall: 0.3158 - learning_rate: 1.0000e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350ms/step - accuracy: 0.7314 - auc: 0.7835 - loss: 1.5726 - precision: 0.7982 - recall: 0.7147\n",
            "Epoch 7: val_loss improved from 1.64970 to 1.61645, saving model to models_combined/best_model_phase_1_frozen.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 380ms/step - accuracy: 0.7310 - auc: 0.7832 - loss: 1.5730 - precision: 0.7980 - recall: 0.7143 - val_accuracy: 0.6495 - val_auc: 0.8373 - val_loss: 1.6165 - val_precision: 0.8966 - val_recall: 0.4561 - learning_rate: 1.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360ms/step - accuracy: 0.7195 - auc: 0.8198 - loss: 1.5191 - precision: 0.8255 - recall: 0.6695\n",
            "Epoch 8: val_loss improved from 1.61645 to 1.58834, saving model to models_combined/best_model_phase_1_frozen.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 394ms/step - accuracy: 0.7195 - auc: 0.8196 - loss: 1.5194 - precision: 0.8252 - recall: 0.6698 - val_accuracy: 0.6804 - val_auc: 0.8439 - val_loss: 1.5883 - val_precision: 0.9062 - val_recall: 0.5088 - learning_rate: 1.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347ms/step - accuracy: 0.7407 - auc: 0.7952 - loss: 1.5578 - precision: 0.8062 - recall: 0.7363\n",
            "Epoch 9: val_loss did not improve from 1.58834\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 371ms/step - accuracy: 0.7404 - auc: 0.7952 - loss: 1.5577 - precision: 0.8060 - recall: 0.7361 - val_accuracy: 0.7010 - val_auc: 0.8447 - val_loss: 1.5933 - val_precision: 0.9118 - val_recall: 0.5439 - learning_rate: 1.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348ms/step - accuracy: 0.7064 - auc: 0.7999 - loss: 1.5427 - precision: 0.7750 - recall: 0.6977\n",
            "Epoch 10: val_loss improved from 1.58834 to 1.57174, saving model to models_combined/best_model_phase_1_frozen.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 379ms/step - accuracy: 0.7068 - auc: 0.8001 - loss: 1.5424 - precision: 0.7755 - recall: 0.6980 - val_accuracy: 0.7113 - val_auc: 0.8529 - val_loss: 1.5717 - val_precision: 0.9143 - val_recall: 0.5614 - learning_rate: 1.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360ms/step - accuracy: 0.7296 - auc: 0.8025 - loss: 1.5456 - precision: 0.7994 - recall: 0.7274\n",
            "Epoch 11: val_loss improved from 1.57174 to 1.56580, saving model to models_combined/best_model_phase_1_frozen.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 390ms/step - accuracy: 0.7294 - auc: 0.8027 - loss: 1.5453 - precision: 0.7990 - recall: 0.7273 - val_accuracy: 0.7320 - val_auc: 0.8524 - val_loss: 1.5658 - val_precision: 0.8974 - val_recall: 0.6140 - learning_rate: 1.0000e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350ms/step - accuracy: 0.7146 - auc: 0.8044 - loss: 1.5406 - precision: 0.7674 - recall: 0.7248\n",
            "Epoch 12: val_loss improved from 1.56580 to 1.55068, saving model to models_combined/best_model_phase_1_frozen.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 380ms/step - accuracy: 0.7147 - auc: 0.8042 - loss: 1.5408 - precision: 0.7680 - recall: 0.7245 - val_accuracy: 0.7526 - val_auc: 0.8566 - val_loss: 1.5507 - val_precision: 0.9024 - val_recall: 0.6491 - learning_rate: 1.0000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349ms/step - accuracy: 0.7316 - auc: 0.8139 - loss: 1.5233 - precision: 0.8135 - recall: 0.7172\n",
            "Epoch 13: val_loss improved from 1.55068 to 1.53754, saving model to models_combined/best_model_phase_1_frozen.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 386ms/step - accuracy: 0.7319 - auc: 0.8143 - loss: 1.5226 - precision: 0.8136 - recall: 0.7176 - val_accuracy: 0.7629 - val_auc: 0.8577 - val_loss: 1.5375 - val_precision: 0.9048 - val_recall: 0.6667 - learning_rate: 1.0000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step - accuracy: 0.7514 - auc: 0.8325 - loss: 1.4968 - precision: 0.7967 - recall: 0.7463\n",
            "Epoch 14: val_loss improved from 1.53754 to 1.52576, saving model to models_combined/best_model_phase_1_frozen.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 381ms/step - accuracy: 0.7517 - auc: 0.8327 - loss: 1.4964 - precision: 0.7976 - recall: 0.7463 - val_accuracy: 0.7629 - val_auc: 0.8651 - val_loss: 1.5258 - val_precision: 0.9048 - val_recall: 0.6667 - learning_rate: 1.0000e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350ms/step - accuracy: 0.7728 - auc: 0.8567 - loss: 1.4455 - precision: 0.8419 - recall: 0.7673\n",
            "Epoch 15: val_loss did not improve from 1.52576\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 375ms/step - accuracy: 0.7727 - auc: 0.8569 - loss: 1.4452 - precision: 0.8418 - recall: 0.7669 - val_accuracy: 0.7629 - val_auc: 0.8625 - val_loss: 1.5313 - val_precision: 0.9048 - val_recall: 0.6667 - learning_rate: 1.0000e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354ms/step - accuracy: 0.7790 - auc: 0.8299 - loss: 1.4963 - precision: 0.8351 - recall: 0.7912\n",
            "Epoch 16: val_loss improved from 1.52576 to 1.51682, saving model to models_combined/best_model_phase_1_frozen.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 396ms/step - accuracy: 0.7785 - auc: 0.8297 - loss: 1.4966 - precision: 0.8345 - recall: 0.7906 - val_accuracy: 0.7732 - val_auc: 0.8568 - val_loss: 1.5168 - val_precision: 0.9070 - val_recall: 0.6842 - learning_rate: 1.0000e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step - accuracy: 0.8165 - auc: 0.8744 - loss: 1.4228 - precision: 0.8644 - recall: 0.8080\n",
            "Epoch 17: val_loss improved from 1.51682 to 1.50421, saving model to models_combined/best_model_phase_1_frozen.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 381ms/step - accuracy: 0.8159 - auc: 0.8744 - loss: 1.4228 - precision: 0.8643 - recall: 0.8072 - val_accuracy: 0.7938 - val_auc: 0.8638 - val_loss: 1.5042 - val_precision: 0.8936 - val_recall: 0.7368 - learning_rate: 1.0000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353ms/step - accuracy: 0.8189 - auc: 0.8915 - loss: 1.3966 - precision: 0.8434 - recall: 0.8292\n",
            "Epoch 18: val_loss did not improve from 1.50421\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 378ms/step - accuracy: 0.8176 - auc: 0.8903 - loss: 1.3986 - precision: 0.8431 - recall: 0.8276 - val_accuracy: 0.7835 - val_auc: 0.8610 - val_loss: 1.5100 - val_precision: 0.8913 - val_recall: 0.7193 - learning_rate: 1.0000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step - accuracy: 0.7765 - auc: 0.8756 - loss: 1.4127 - precision: 0.8617 - recall: 0.7618\n",
            "Epoch 19: val_loss improved from 1.50421 to 1.49751, saving model to models_combined/best_model_phase_1_frozen.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 399ms/step - accuracy: 0.7761 - auc: 0.8750 - loss: 1.4136 - precision: 0.8608 - recall: 0.7618 - val_accuracy: 0.8041 - val_auc: 0.8632 - val_loss: 1.4975 - val_precision: 0.8958 - val_recall: 0.7544 - learning_rate: 1.0000e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351ms/step - accuracy: 0.8169 - auc: 0.8950 - loss: 1.3767 - precision: 0.8711 - recall: 0.8052\n",
            "Epoch 20: val_loss did not improve from 1.49751\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 376ms/step - accuracy: 0.8166 - auc: 0.8948 - loss: 1.3771 - precision: 0.8711 - recall: 0.8046 - val_accuracy: 0.7835 - val_auc: 0.8649 - val_loss: 1.4993 - val_precision: 0.8750 - val_recall: 0.7368 - learning_rate: 1.0000e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360ms/step - accuracy: 0.7726 - auc: 0.8563 - loss: 1.4364 - precision: 0.8363 - recall: 0.7685\n",
            "Epoch 21: val_loss improved from 1.49751 to 1.49523, saving model to models_combined/best_model_phase_1_frozen.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 390ms/step - accuracy: 0.7729 - auc: 0.8565 - loss: 1.4361 - precision: 0.8365 - recall: 0.7687 - val_accuracy: 0.7835 - val_auc: 0.8658 - val_loss: 1.4952 - val_precision: 0.8750 - val_recall: 0.7368 - learning_rate: 1.0000e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372ms/step - accuracy: 0.7551 - auc: 0.8260 - loss: 1.4834 - precision: 0.8227 - recall: 0.7628\n",
            "Epoch 22: val_loss did not improve from 1.49523\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 396ms/step - accuracy: 0.7555 - auc: 0.8266 - loss: 1.4827 - precision: 0.8228 - recall: 0.7630 - val_accuracy: 0.7629 - val_auc: 0.8638 - val_loss: 1.5097 - val_precision: 0.8696 - val_recall: 0.7018 - learning_rate: 1.0000e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351ms/step - accuracy: 0.7675 - auc: 0.8280 - loss: 1.4839 - precision: 0.8142 - recall: 0.7907\n",
            "Epoch 23: val_loss did not improve from 1.49523\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 376ms/step - accuracy: 0.7680 - auc: 0.8286 - loss: 1.4828 - precision: 0.8148 - recall: 0.7909 - val_accuracy: 0.7629 - val_auc: 0.8614 - val_loss: 1.5208 - val_precision: 0.8696 - val_recall: 0.7018 - learning_rate: 1.0000e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353ms/step - accuracy: 0.7978 - auc: 0.8869 - loss: 1.3820 - precision: 0.8466 - recall: 0.7958\n",
            "Epoch 24: val_loss did not improve from 1.49523\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 377ms/step - accuracy: 0.7976 - auc: 0.8866 - loss: 1.3825 - precision: 0.8466 - recall: 0.7955 - val_accuracy: 0.7629 - val_auc: 0.8643 - val_loss: 1.5052 - val_precision: 0.8696 - val_recall: 0.7018 - learning_rate: 1.0000e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step - accuracy: 0.7447 - auc: 0.8436 - loss: 1.4618 - precision: 0.7966 - recall: 0.7493\n",
            "Epoch 25: val_loss did not improve from 1.49523\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 395ms/step - accuracy: 0.7455 - auc: 0.8438 - loss: 1.4613 - precision: 0.7974 - recall: 0.7503 - val_accuracy: 0.7629 - val_auc: 0.8634 - val_loss: 1.4993 - val_precision: 0.8696 - val_recall: 0.7018 - learning_rate: 1.0000e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359ms/step - accuracy: 0.7826 - auc: 0.8769 - loss: 1.3916 - precision: 0.8209 - recall: 0.8135\n",
            "Epoch 26: val_loss improved from 1.49523 to 1.48605, saving model to models_combined/best_model_phase_1_frozen.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 388ms/step - accuracy: 0.7824 - auc: 0.8768 - loss: 1.3917 - precision: 0.8207 - recall: 0.8131 - val_accuracy: 0.7732 - val_auc: 0.8625 - val_loss: 1.4860 - val_precision: 0.8723 - val_recall: 0.7193 - learning_rate: 1.0000e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350ms/step - accuracy: 0.8151 - auc: 0.8986 - loss: 1.3521 - precision: 0.8603 - recall: 0.8176\n",
            "Epoch 27: val_loss improved from 1.48605 to 1.48446, saving model to models_combined/best_model_phase_1_frozen.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 383ms/step - accuracy: 0.8145 - auc: 0.8977 - loss: 1.3536 - precision: 0.8599 - recall: 0.8168 - val_accuracy: 0.7938 - val_auc: 0.8616 - val_loss: 1.4845 - val_precision: 0.8627 - val_recall: 0.7719 - learning_rate: 1.0000e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361ms/step - accuracy: 0.7926 - auc: 0.8654 - loss: 1.4084 - precision: 0.8498 - recall: 0.7916\n",
            "Epoch 28: val_loss improved from 1.48446 to 1.47326, saving model to models_combined/best_model_phase_1_frozen.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 390ms/step - accuracy: 0.7924 - auc: 0.8653 - loss: 1.4086 - precision: 0.8494 - recall: 0.7915 - val_accuracy: 0.7835 - val_auc: 0.8658 - val_loss: 1.4733 - val_precision: 0.8600 - val_recall: 0.7544 - learning_rate: 1.0000e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354ms/step - accuracy: 0.7724 - auc: 0.8729 - loss: 1.3913 - precision: 0.8387 - recall: 0.7596\n",
            "Epoch 29: val_loss did not improve from 1.47326\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 379ms/step - accuracy: 0.7723 - auc: 0.8728 - loss: 1.3917 - precision: 0.8385 - recall: 0.7596 - val_accuracy: 0.7835 - val_auc: 0.8658 - val_loss: 1.4813 - val_precision: 0.8600 - val_recall: 0.7544 - learning_rate: 1.0000e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356ms/step - accuracy: 0.7769 - auc: 0.8861 - loss: 1.3663 - precision: 0.8525 - recall: 0.7506\n",
            "Epoch 30: val_loss improved from 1.47326 to 1.46564, saving model to models_combined/best_model_phase_1_frozen.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 394ms/step - accuracy: 0.7771 - auc: 0.8860 - loss: 1.3667 - precision: 0.8526 - recall: 0.7509 - val_accuracy: 0.7732 - val_auc: 0.8717 - val_loss: 1.4656 - val_precision: 0.8571 - val_recall: 0.7368 - learning_rate: 1.0000e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356ms/step - accuracy: 0.7778 - auc: 0.8823 - loss: 1.3747 - precision: 0.8271 - recall: 0.7722\n",
            "Epoch 31: val_loss did not improve from 1.46564\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 381ms/step - accuracy: 0.7779 - auc: 0.8820 - loss: 1.3752 - precision: 0.8273 - recall: 0.7725 - val_accuracy: 0.7835 - val_auc: 0.8693 - val_loss: 1.4704 - val_precision: 0.8750 - val_recall: 0.7368 - learning_rate: 1.0000e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step - accuracy: 0.8004 - auc: 0.8610 - loss: 1.4200 - precision: 0.8376 - recall: 0.8204\n",
            "Epoch 32: val_loss improved from 1.46564 to 1.46529, saving model to models_combined/best_model_phase_1_frozen.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 382ms/step - accuracy: 0.8004 - auc: 0.8612 - loss: 1.4195 - precision: 0.8377 - recall: 0.8203 - val_accuracy: 0.7835 - val_auc: 0.8691 - val_loss: 1.4653 - val_precision: 0.8750 - val_recall: 0.7368 - learning_rate: 1.0000e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - accuracy: 0.8146 - auc: 0.8922 - loss: 1.3497 - precision: 0.8842 - recall: 0.8021\n",
            "Epoch 33: val_loss improved from 1.46529 to 1.46075, saving model to models_combined/best_model_phase_1_frozen.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 408ms/step - accuracy: 0.8144 - auc: 0.8921 - loss: 1.3497 - precision: 0.8835 - recall: 0.8022 - val_accuracy: 0.8041 - val_auc: 0.8704 - val_loss: 1.4607 - val_precision: 0.8800 - val_recall: 0.7719 - learning_rate: 1.0000e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357ms/step - accuracy: 0.8127 - auc: 0.9070 - loss: 1.3202 - precision: 0.8695 - recall: 0.8154\n",
            "Epoch 34: val_loss did not improve from 1.46075\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 382ms/step - accuracy: 0.8124 - auc: 0.9066 - loss: 1.3210 - precision: 0.8690 - recall: 0.8150 - val_accuracy: 0.7835 - val_auc: 0.8697 - val_loss: 1.4686 - val_precision: 0.8750 - val_recall: 0.7368 - learning_rate: 1.0000e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358ms/step - accuracy: 0.8568 - auc: 0.9275 - loss: 1.2770 - precision: 0.9142 - recall: 0.8442\n",
            "Epoch 35: val_loss did not improve from 1.46075\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 382ms/step - accuracy: 0.8564 - auc: 0.9271 - loss: 1.2777 - precision: 0.9138 - recall: 0.8438 - val_accuracy: 0.7835 - val_auc: 0.8658 - val_loss: 1.4701 - val_precision: 0.8750 - val_recall: 0.7368 - learning_rate: 1.0000e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - accuracy: 0.8397 - auc: 0.8920 - loss: 1.3468 - precision: 0.8835 - recall: 0.8422\n",
            "Epoch 36: val_loss improved from 1.46075 to 1.45405, saving model to models_combined/best_model_phase_1_frozen.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 403ms/step - accuracy: 0.8393 - auc: 0.8919 - loss: 1.3469 - precision: 0.8832 - recall: 0.8419 - val_accuracy: 0.8041 - val_auc: 0.8708 - val_loss: 1.4540 - val_precision: 0.8800 - val_recall: 0.7719 - learning_rate: 1.0000e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351ms/step - accuracy: 0.8013 - auc: 0.8796 - loss: 1.3665 - precision: 0.8572 - recall: 0.7911\n",
            "Epoch 37: val_loss improved from 1.45405 to 1.44811, saving model to models_combined/best_model_phase_1_frozen.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 382ms/step - accuracy: 0.8011 - auc: 0.8797 - loss: 1.3664 - precision: 0.8573 - recall: 0.7906 - val_accuracy: 0.8041 - val_auc: 0.8724 - val_loss: 1.4481 - val_precision: 0.8654 - val_recall: 0.7895 - learning_rate: 1.0000e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355ms/step - accuracy: 0.7999 - auc: 0.8766 - loss: 1.3722 - precision: 0.8566 - recall: 0.7979\n",
            "Epoch 38: val_loss improved from 1.44811 to 1.43718, saving model to models_combined/best_model_phase_1_frozen.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 390ms/step - accuracy: 0.8002 - auc: 0.8768 - loss: 1.3718 - precision: 0.8567 - recall: 0.7981 - val_accuracy: 0.8144 - val_auc: 0.8711 - val_loss: 1.4372 - val_precision: 0.8679 - val_recall: 0.8070 - learning_rate: 1.0000e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step - accuracy: 0.8527 - auc: 0.9287 - loss: 1.2639 - precision: 0.9026 - recall: 0.8474\n",
            "Epoch 39: val_loss improved from 1.43718 to 1.43475, saving model to models_combined/best_model_phase_1_frozen.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 382ms/step - accuracy: 0.8525 - auc: 0.9283 - loss: 1.2646 - precision: 0.9023 - recall: 0.8473 - val_accuracy: 0.8144 - val_auc: 0.8691 - val_loss: 1.4348 - val_precision: 0.8679 - val_recall: 0.8070 - learning_rate: 1.0000e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358ms/step - accuracy: 0.8238 - auc: 0.9012 - loss: 1.3073 - precision: 0.8651 - recall: 0.8069\n",
            "Epoch 40: val_loss did not improve from 1.43475\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 383ms/step - accuracy: 0.8239 - auc: 0.9013 - loss: 1.3074 - precision: 0.8653 - recall: 0.8073 - val_accuracy: 0.8041 - val_auc: 0.8680 - val_loss: 1.4386 - val_precision: 0.8654 - val_recall: 0.7895 - learning_rate: 1.0000e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354ms/step - accuracy: 0.8046 - auc: 0.8819 - loss: 1.3731 - precision: 0.8392 - recall: 0.8130\n",
            "Epoch 41: val_loss improved from 1.43475 to 1.43474, saving model to models_combined/best_model_phase_1_frozen.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 392ms/step - accuracy: 0.8044 - auc: 0.8819 - loss: 1.3727 - precision: 0.8393 - recall: 0.8128 - val_accuracy: 0.8144 - val_auc: 0.8673 - val_loss: 1.4347 - val_precision: 0.8679 - val_recall: 0.8070 - learning_rate: 1.0000e-04\n",
            "Epoch 42/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step - accuracy: 0.8031 - auc: 0.8880 - loss: 1.3520 - precision: 0.8084 - recall: 0.8382\n",
            "Epoch 42: val_loss improved from 1.43474 to 1.43215, saving model to models_combined/best_model_phase_1_frozen.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 381ms/step - accuracy: 0.8036 - auc: 0.8881 - loss: 1.3515 - precision: 0.8098 - recall: 0.8379 - val_accuracy: 0.7938 - val_auc: 0.8686 - val_loss: 1.4321 - val_precision: 0.8627 - val_recall: 0.7719 - learning_rate: 1.0000e-04\n",
            "Epoch 43/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354ms/step - accuracy: 0.8339 - auc: 0.9054 - loss: 1.3028 - precision: 0.8816 - recall: 0.8360\n",
            "Epoch 43: val_loss improved from 1.43215 to 1.42932, saving model to models_combined/best_model_phase_1_frozen.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 385ms/step - accuracy: 0.8340 - auc: 0.9054 - loss: 1.3027 - precision: 0.8815 - recall: 0.8361 - val_accuracy: 0.8041 - val_auc: 0.8686 - val_loss: 1.4293 - val_precision: 0.8654 - val_recall: 0.7895 - learning_rate: 1.0000e-04\n",
            "Epoch 44/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.8145 - auc: 0.8921 - loss: 1.3287 - precision: 0.8563 - recall: 0.8237\n",
            "Epoch 44: val_loss did not improve from 1.42932\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 407ms/step - accuracy: 0.8145 - auc: 0.8922 - loss: 1.3284 - precision: 0.8562 - recall: 0.8237 - val_accuracy: 0.8041 - val_auc: 0.8706 - val_loss: 1.4298 - val_precision: 0.8654 - val_recall: 0.7895 - learning_rate: 1.0000e-04\n",
            "Epoch 45/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362ms/step - accuracy: 0.7889 - auc: 0.9106 - loss: 1.2898 - precision: 0.8463 - recall: 0.7813\n",
            "Epoch 45: val_loss did not improve from 1.42932\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 388ms/step - accuracy: 0.7892 - auc: 0.9103 - loss: 1.2904 - precision: 0.8464 - recall: 0.7820 - val_accuracy: 0.8041 - val_auc: 0.8732 - val_loss: 1.4348 - val_precision: 0.8654 - val_recall: 0.7895 - learning_rate: 1.0000e-04\n",
            "Epoch 46/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361ms/step - accuracy: 0.8398 - auc: 0.9120 - loss: 1.2841 - precision: 0.8867 - recall: 0.8407\n",
            "Epoch 46: val_loss improved from 1.42932 to 1.42485, saving model to models_combined/best_model_phase_1_frozen.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 398ms/step - accuracy: 0.8394 - auc: 0.9117 - loss: 1.2848 - precision: 0.8863 - recall: 0.8402 - val_accuracy: 0.8041 - val_auc: 0.8721 - val_loss: 1.4248 - val_precision: 0.8654 - val_recall: 0.7895 - learning_rate: 1.0000e-04\n",
            "Epoch 47/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step - accuracy: 0.8607 - auc: 0.9184 - loss: 1.2673 - precision: 0.8836 - recall: 0.8726\n",
            "Epoch 47: val_loss did not improve from 1.42485\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 395ms/step - accuracy: 0.8604 - auc: 0.9181 - loss: 1.2678 - precision: 0.8836 - recall: 0.8722 - val_accuracy: 0.7938 - val_auc: 0.8724 - val_loss: 1.4268 - val_precision: 0.8627 - val_recall: 0.7719 - learning_rate: 1.0000e-04\n",
            "Epoch 48/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359ms/step - accuracy: 0.8217 - auc: 0.8969 - loss: 1.3063 - precision: 0.8525 - recall: 0.8467\n",
            "Epoch 48: val_loss improved from 1.42485 to 1.41881, saving model to models_combined/best_model_phase_1_frozen.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 389ms/step - accuracy: 0.8213 - auc: 0.8967 - loss: 1.3068 - precision: 0.8523 - recall: 0.8460 - val_accuracy: 0.8041 - val_auc: 0.8708 - val_loss: 1.4188 - val_precision: 0.8654 - val_recall: 0.7895 - learning_rate: 1.0000e-04\n",
            "Epoch 49/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - accuracy: 0.7959 - auc: 0.8945 - loss: 1.3049 - precision: 0.8649 - recall: 0.7848\n",
            "Epoch 49: val_loss did not improve from 1.41881\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 399ms/step - accuracy: 0.7967 - auc: 0.8948 - loss: 1.3043 - precision: 0.8652 - recall: 0.7858 - val_accuracy: 0.7938 - val_auc: 0.8735 - val_loss: 1.4200 - val_precision: 0.8627 - val_recall: 0.7719 - learning_rate: 1.0000e-04\n",
            "Epoch 50/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360ms/step - accuracy: 0.8396 - auc: 0.9167 - loss: 1.2581 - precision: 0.8736 - recall: 0.8565\n",
            "Epoch 50: val_loss did not improve from 1.41881\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 385ms/step - accuracy: 0.8392 - auc: 0.9164 - loss: 1.2589 - precision: 0.8731 - recall: 0.8562 - val_accuracy: 0.7938 - val_auc: 0.8726 - val_loss: 1.4197 - val_precision: 0.8627 - val_recall: 0.7719 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 48.\n",
            "\n",
            "[STEP 7.5] Unfreezing for Fine-tuning...\n",
            "\n",
            "[STEP 7] Training - Phase 2 Fine-tune...\n",
            "Epoch 1/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583ms/step - accuracy: 0.7988 - auc: 0.8805 - loss: 1.3460 - precision: 0.8294 - recall: 0.8250\n",
            "Epoch 1: val_loss improved from inf to 1.71853, saving model to models_combined/best_model_phase_2_fine-tune.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 708ms/step - accuracy: 0.7993 - auc: 0.8808 - loss: 1.3453 - precision: 0.8303 - recall: 0.8248 - val_accuracy: 0.7010 - val_auc: 0.8932 - val_loss: 1.7185 - val_precision: 0.9375 - val_recall: 0.5263 - learning_rate: 1.0000e-05\n",
            "Epoch 2/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424ms/step - accuracy: 0.8208 - auc: 0.9011 - loss: 1.3083 - precision: 0.8769 - recall: 0.8105\n",
            "Epoch 2: val_loss improved from 1.71853 to 1.30758, saving model to models_combined/best_model_phase_2_fine-tune.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 464ms/step - accuracy: 0.8206 - auc: 0.9010 - loss: 1.3084 - precision: 0.8766 - recall: 0.8104 - val_accuracy: 0.8660 - val_auc: 0.9143 - val_loss: 1.3076 - val_precision: 0.8667 - val_recall: 0.9123 - learning_rate: 1.0000e-05\n",
            "Epoch 3/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437ms/step - accuracy: 0.8321 - auc: 0.9134 - loss: 1.2709 - precision: 0.8796 - recall: 0.8264\n",
            "Epoch 3: val_loss did not improve from 1.30758\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 462ms/step - accuracy: 0.8322 - auc: 0.9134 - loss: 1.2708 - precision: 0.8794 - recall: 0.8267 - val_accuracy: 0.8041 - val_auc: 0.9035 - val_loss: 1.4155 - val_precision: 0.7879 - val_recall: 0.9123 - learning_rate: 1.0000e-05\n",
            "Epoch 4/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - accuracy: 0.8406 - auc: 0.9344 - loss: 1.2291 - precision: 0.8881 - recall: 0.8381\n",
            "Epoch 4: val_loss did not improve from 1.30758\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 440ms/step - accuracy: 0.8409 - auc: 0.9345 - loss: 1.2287 - precision: 0.8884 - recall: 0.8383 - val_accuracy: 0.8351 - val_auc: 0.9171 - val_loss: 1.3487 - val_precision: 0.9184 - val_recall: 0.7895 - learning_rate: 1.0000e-05\n",
            "Epoch 5/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433ms/step - accuracy: 0.8458 - auc: 0.9304 - loss: 1.2477 - precision: 0.8994 - recall: 0.8499\n",
            "Epoch 5: val_loss did not improve from 1.30758\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 459ms/step - accuracy: 0.8461 - auc: 0.9303 - loss: 1.2478 - precision: 0.8992 - recall: 0.8502 - val_accuracy: 0.7938 - val_auc: 0.8879 - val_loss: 1.3343 - val_precision: 0.8491 - val_recall: 0.7895 - learning_rate: 1.0000e-05\n",
            "Epoch 6/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433ms/step - accuracy: 0.8730 - auc: 0.9462 - loss: 1.1922 - precision: 0.8978 - recall: 0.8826\n",
            "Epoch 6: val_loss did not improve from 1.30758\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 462ms/step - accuracy: 0.8729 - auc: 0.9460 - loss: 1.1928 - precision: 0.8976 - recall: 0.8827 - val_accuracy: 0.8763 - val_auc: 0.9237 - val_loss: 1.3212 - val_precision: 0.9245 - val_recall: 0.8596 - learning_rate: 1.0000e-05\n",
            "Epoch 7/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426ms/step - accuracy: 0.8942 - auc: 0.9484 - loss: 1.1873 - precision: 0.9200 - recall: 0.9000\n",
            "Epoch 7: val_loss improved from 1.30758 to 1.28995, saving model to models_combined/best_model_phase_2_fine-tune.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 464ms/step - accuracy: 0.8936 - auc: 0.9483 - loss: 1.1878 - precision: 0.9197 - recall: 0.8993 - val_accuracy: 0.8454 - val_auc: 0.9241 - val_loss: 1.2900 - val_precision: 0.8387 - val_recall: 0.9123 - learning_rate: 1.0000e-05\n",
            "Epoch 8/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436ms/step - accuracy: 0.9044 - auc: 0.9674 - loss: 1.1317 - precision: 0.9422 - recall: 0.8937\n",
            "Epoch 8: val_loss did not improve from 1.28995\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 461ms/step - accuracy: 0.9035 - auc: 0.9668 - loss: 1.1334 - precision: 0.9414 - recall: 0.8931 - val_accuracy: 0.7113 - val_auc: 0.8879 - val_loss: 1.8528 - val_precision: 0.6706 - val_recall: 1.0000 - learning_rate: 1.0000e-05\n",
            "Epoch 9/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424ms/step - accuracy: 0.8564 - auc: 0.9352 - loss: 1.2227 - precision: 0.9059 - recall: 0.8456\n",
            "Epoch 9: val_loss did not improve from 1.28995\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 457ms/step - accuracy: 0.8564 - auc: 0.9352 - loss: 1.2227 - precision: 0.9058 - recall: 0.8456 - val_accuracy: 0.8247 - val_auc: 0.9064 - val_loss: 1.4462 - val_precision: 0.8125 - val_recall: 0.9123 - learning_rate: 1.0000e-05\n",
            "Epoch 10/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421ms/step - accuracy: 0.8546 - auc: 0.9375 - loss: 1.2102 - precision: 0.8935 - recall: 0.8659\n",
            "Epoch 10: val_loss did not improve from 1.28995\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 448ms/step - accuracy: 0.8546 - auc: 0.9374 - loss: 1.2106 - precision: 0.8932 - recall: 0.8659 - val_accuracy: 0.8041 - val_auc: 0.9081 - val_loss: 1.4020 - val_precision: 0.9130 - val_recall: 0.7368 - learning_rate: 1.0000e-05\n",
            "Epoch 11/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433ms/step - accuracy: 0.8527 - auc: 0.9212 - loss: 1.2684 - precision: 0.8720 - recall: 0.8711\n",
            "Epoch 11: val_loss did not improve from 1.28995\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 458ms/step - accuracy: 0.8530 - auc: 0.9216 - loss: 1.2669 - precision: 0.8727 - recall: 0.8711 - val_accuracy: 0.7732 - val_auc: 0.9186 - val_loss: 1.4360 - val_precision: 0.9070 - val_recall: 0.6842 - learning_rate: 1.0000e-05\n",
            "Epoch 12/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412ms/step - accuracy: 0.8968 - auc: 0.9567 - loss: 1.1698 - precision: 0.9206 - recall: 0.8999\n",
            "Epoch 12: val_loss did not improve from 1.28995\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 436ms/step - accuracy: 0.8967 - auc: 0.9567 - loss: 1.1696 - precision: 0.9206 - recall: 0.8999 - val_accuracy: 0.6701 - val_auc: 0.8912 - val_loss: 1.8416 - val_precision: 0.9032 - val_recall: 0.4912 - learning_rate: 1.0000e-05\n",
            "Epoch 13/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425ms/step - accuracy: 0.8392 - auc: 0.9208 - loss: 1.2832 - precision: 0.8558 - recall: 0.8578\n",
            "Epoch 13: val_loss improved from 1.28995 to 1.24598, saving model to models_combined/best_model_phase_2_fine-tune.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 460ms/step - accuracy: 0.8397 - auc: 0.9211 - loss: 1.2821 - precision: 0.8566 - recall: 0.8579 - val_accuracy: 0.8557 - val_auc: 0.9397 - val_loss: 1.2460 - val_precision: 0.9057 - val_recall: 0.8421 - learning_rate: 1.0000e-05\n",
            "Epoch 14/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412ms/step - accuracy: 0.8754 - auc: 0.9507 - loss: 1.1817 - precision: 0.9048 - recall: 0.8842\n",
            "Epoch 14: val_loss did not improve from 1.24598\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 440ms/step - accuracy: 0.8750 - auc: 0.9503 - loss: 1.1828 - precision: 0.9045 - recall: 0.8837 - val_accuracy: 0.8041 - val_auc: 0.9268 - val_loss: 1.4750 - val_precision: 0.7568 - val_recall: 0.9825 - learning_rate: 1.0000e-05\n",
            "Epoch 15/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - accuracy: 0.8347 - auc: 0.9037 - loss: 1.3136 - precision: 0.8778 - recall: 0.8430\n",
            "Epoch 15: val_loss improved from 1.24598 to 1.20729, saving model to models_combined/best_model_phase_2_fine-tune.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 459ms/step - accuracy: 0.8350 - auc: 0.9041 - loss: 1.3125 - precision: 0.8779 - recall: 0.8432 - val_accuracy: 0.8454 - val_auc: 0.9456 - val_loss: 1.2073 - val_precision: 0.8500 - val_recall: 0.8947 - learning_rate: 1.0000e-05\n",
            "Epoch 16/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421ms/step - accuracy: 0.8940 - auc: 0.9702 - loss: 1.1281 - precision: 0.9548 - recall: 0.8647\n",
            "Epoch 16: val_loss did not improve from 1.20729\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 445ms/step - accuracy: 0.8941 - auc: 0.9702 - loss: 1.1280 - precision: 0.9544 - recall: 0.8652 - val_accuracy: 0.8763 - val_auc: 0.9496 - val_loss: 1.2192 - val_precision: 0.9091 - val_recall: 0.8772 - learning_rate: 1.0000e-05\n",
            "Epoch 17/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409ms/step - accuracy: 0.8882 - auc: 0.9521 - loss: 1.1796 - precision: 0.9195 - recall: 0.8829\n",
            "Epoch 17: val_loss did not improve from 1.20729\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 435ms/step - accuracy: 0.8884 - auc: 0.9521 - loss: 1.1794 - precision: 0.9199 - recall: 0.8827 - val_accuracy: 0.8247 - val_auc: 0.9419 - val_loss: 1.3475 - val_precision: 0.9348 - val_recall: 0.7544 - learning_rate: 1.0000e-05\n",
            "Epoch 18/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427ms/step - accuracy: 0.8839 - auc: 0.9410 - loss: 1.2062 - precision: 0.8955 - recall: 0.8995\n",
            "Epoch 18: val_loss did not improve from 1.20729\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 453ms/step - accuracy: 0.8836 - auc: 0.9409 - loss: 1.2065 - precision: 0.8955 - recall: 0.8990 - val_accuracy: 0.7629 - val_auc: 0.9160 - val_loss: 1.5436 - val_precision: 0.9474 - val_recall: 0.6316 - learning_rate: 1.0000e-05\n",
            "Epoch 19/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418ms/step - accuracy: 0.8869 - auc: 0.9652 - loss: 1.1360 - precision: 0.9263 - recall: 0.8792\n",
            "Epoch 19: val_loss did not improve from 1.20729\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 445ms/step - accuracy: 0.8870 - auc: 0.9652 - loss: 1.1360 - precision: 0.9265 - recall: 0.8793 - val_accuracy: 0.8557 - val_auc: 0.9478 - val_loss: 1.2737 - val_precision: 0.9388 - val_recall: 0.8070 - learning_rate: 1.0000e-05\n",
            "Epoch 20/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425ms/step - accuracy: 0.8982 - auc: 0.9627 - loss: 1.1367 - precision: 0.9262 - recall: 0.8996\n",
            "Epoch 20: val_loss did not improve from 1.20729\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 452ms/step - accuracy: 0.8979 - auc: 0.9627 - loss: 1.1370 - precision: 0.9260 - recall: 0.8993 - val_accuracy: 0.8557 - val_auc: 0.9399 - val_loss: 1.2398 - val_precision: 0.8525 - val_recall: 0.9123 - learning_rate: 1.0000e-05\n",
            "Epoch 21/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434ms/step - accuracy: 0.9275 - auc: 0.9718 - loss: 1.1099 - precision: 0.9400 - recall: 0.9329\n",
            "Epoch 21: val_loss did not improve from 1.20729\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 461ms/step - accuracy: 0.9269 - auc: 0.9715 - loss: 1.1107 - precision: 0.9399 - recall: 0.9320 - val_accuracy: 0.7320 - val_auc: 0.9138 - val_loss: 1.6844 - val_precision: 0.6914 - val_recall: 0.9825 - learning_rate: 1.0000e-05\n",
            "Epoch 22/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412ms/step - accuracy: 0.8987 - auc: 0.9489 - loss: 1.1781 - precision: 0.9220 - recall: 0.9077\n",
            "Epoch 22: val_loss did not improve from 1.20729\n",
            "\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 436ms/step - accuracy: 0.8986 - auc: 0.9490 - loss: 1.1778 - precision: 0.9221 - recall: 0.9073 - val_accuracy: 0.8247 - val_auc: 0.9186 - val_loss: 1.3381 - val_precision: 0.7857 - val_recall: 0.9649 - learning_rate: 1.0000e-05\n",
            "Epoch 23/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421ms/step - accuracy: 0.9146 - auc: 0.9561 - loss: 1.1525 - precision: 0.9319 - recall: 0.9189\n",
            "Epoch 23: val_loss did not improve from 1.20729\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 447ms/step - accuracy: 0.9144 - auc: 0.9563 - loss: 1.1519 - precision: 0.9321 - recall: 0.9184 - val_accuracy: 0.8557 - val_auc: 0.9342 - val_loss: 1.2530 - val_precision: 0.8772 - val_recall: 0.8772 - learning_rate: 5.0000e-06\n",
            "Epoch 24/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - accuracy: 0.9155 - auc: 0.9738 - loss: 1.1001 - precision: 0.9458 - recall: 0.9087\n",
            "Epoch 24: val_loss did not improve from 1.20729\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 437ms/step - accuracy: 0.9153 - auc: 0.9737 - loss: 1.1007 - precision: 0.9456 - recall: 0.9085 - val_accuracy: 0.8247 - val_auc: 0.9322 - val_loss: 1.2925 - val_precision: 0.9167 - val_recall: 0.7719 - learning_rate: 5.0000e-06\n",
            "Epoch 25/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422ms/step - accuracy: 0.9082 - auc: 0.9663 - loss: 1.1238 - precision: 0.9387 - recall: 0.9038\n",
            "Epoch 25: val_loss did not improve from 1.20729\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 447ms/step - accuracy: 0.9082 - auc: 0.9662 - loss: 1.1240 - precision: 0.9386 - recall: 0.9039 - val_accuracy: 0.8557 - val_auc: 0.9471 - val_loss: 1.2830 - val_precision: 0.8308 - val_recall: 0.9474 - learning_rate: 5.0000e-06\n",
            "Epoch 26/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408ms/step - accuracy: 0.9051 - auc: 0.9690 - loss: 1.1199 - precision: 0.9224 - recall: 0.9103\n",
            "Epoch 26: val_loss did not improve from 1.20729\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 435ms/step - accuracy: 0.9050 - auc: 0.9689 - loss: 1.1203 - precision: 0.9227 - recall: 0.9100 - val_accuracy: 0.8763 - val_auc: 0.9452 - val_loss: 1.2200 - val_precision: 0.8947 - val_recall: 0.8947 - learning_rate: 5.0000e-06\n",
            "Epoch 27/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422ms/step - accuracy: 0.8905 - auc: 0.9653 - loss: 1.1265 - precision: 0.9246 - recall: 0.8771\n",
            "Epoch 27: val_loss did not improve from 1.20729\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 447ms/step - accuracy: 0.8906 - auc: 0.9653 - loss: 1.1266 - precision: 0.9250 - recall: 0.8771 - val_accuracy: 0.8041 - val_auc: 0.9285 - val_loss: 1.2560 - val_precision: 0.8393 - val_recall: 0.8246 - learning_rate: 5.0000e-06\n",
            "Epoch 28/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - accuracy: 0.9093 - auc: 0.9637 - loss: 1.1337 - precision: 0.9288 - recall: 0.9169\n",
            "Epoch 28: val_loss did not improve from 1.20729\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 446ms/step - accuracy: 0.9094 - auc: 0.9638 - loss: 1.1335 - precision: 0.9290 - recall: 0.9168 - val_accuracy: 0.8557 - val_auc: 0.9421 - val_loss: 1.2079 - val_precision: 0.8772 - val_recall: 0.8772 - learning_rate: 5.0000e-06\n",
            "Epoch 29/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407ms/step - accuracy: 0.9155 - auc: 0.9783 - loss: 1.0861 - precision: 0.9551 - recall: 0.9031\n",
            "Epoch 29: val_loss did not improve from 1.20729\n",
            "\n",
            "Epoch 29: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 433ms/step - accuracy: 0.9155 - auc: 0.9781 - loss: 1.0866 - precision: 0.9547 - recall: 0.9034 - val_accuracy: 0.8660 - val_auc: 0.9465 - val_loss: 1.2655 - val_precision: 0.9231 - val_recall: 0.8421 - learning_rate: 5.0000e-06\n",
            "Epoch 30/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433ms/step - accuracy: 0.9321 - auc: 0.9790 - loss: 1.0824 - precision: 0.9491 - recall: 0.9330\n",
            "Epoch 30: val_loss improved from 1.20729 to 1.20043, saving model to models_combined/best_model_phase_2_fine-tune.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 470ms/step - accuracy: 0.9318 - auc: 0.9789 - loss: 1.0829 - precision: 0.9489 - recall: 0.9326 - val_accuracy: 0.8557 - val_auc: 0.9539 - val_loss: 1.2004 - val_precision: 0.8644 - val_recall: 0.8947 - learning_rate: 2.5000e-06\n",
            "Restoring model weights from the end of the best epoch: 30.\n",
            "\n",
            "[STEP 8] Evaluating on Both Datasets Separately...\n",
            "\n",
            "================================================================================\n",
            "EVALUATION ON SIPAKMED\n",
            "================================================================================\n",
            "Found 194 validated image filenames belonging to 2 classes.\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 915ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Normal     0.9155    0.8125    0.8609        80\n",
            "    Abnormal     0.8780    0.9474    0.9114       114\n",
            "\n",
            "    accuracy                         0.8918       194\n",
            "   macro avg     0.8968    0.8799    0.8862       194\n",
            "weighted avg     0.8935    0.8918    0.8906       194\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 65  15]\n",
            " [  6 108]]\n",
            "\n",
            "Key Metrics:\n",
            "   Accuracy: 89.18%\n",
            "   Sensitivity: 94.74%\n",
            "   Specificity: 81.25%\n",
            "   Missed Cancers: 6\n",
            "   ROC-AUC: 0.9573\n",
            "\n",
            "   ⚠️  No herlev samples in test set\n",
            "\n",
            "================================================================================\n",
            "✅ TRAINING COMPLETE!\n",
            "================================================================================\n",
            "\n",
            "📊 Results Summary:\n",
            "\n",
            "   SIPAKMED:\n",
            "      Accuracy: 89.18%\n",
            "      Sensitivity: 94.74%\n",
            "      Specificity: 81.25%\n",
            "      ROC-AUC: 0.9573\n",
            "      Missed Cancers: 6\n",
            "\n",
            "💾 Model saved: models_combined/final_model_combined.h5\n",
            "\n",
            "🎯 This model now works on BOTH datasets!\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O_4V2q8mZQAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Combined Dataset Creator for Kaggle/Colab\n",
        "Handles nested folder structures (test/train subfolders)\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# ============================================================================\n",
        "# CONFIGURATION FOR KAGGLE/COLAB\n",
        "# ============================================================================\n",
        "\n",
        "class KaggleConfig:\n",
        "    # Kaggle dataset paths\n",
        "    SIPAKMED_PATH = '/kaggle/input/cervical-cancer-largest-dataset-sipakmed'\n",
        "    HERLEV_PATH = '/kaggle/input/herlev-dataset/Herlev Dataset'\n",
        "\n",
        "    # SIPaKMeD class mapping\n",
        "    SIPAKMED_CLASSES = {\n",
        "        'im_Superficial-Intermediate': 0,  # Normal\n",
        "        'im_Dyskeratotic': 1,              # Abnormal\n",
        "        'im_Koilocytotic': 1,              # Abnormal\n",
        "        'im_Parabasal': 1,                 # Abnormal\n",
        "        'im_Metaplastic': 0                # Normal\n",
        "    }\n",
        "\n",
        "    # Herlev class mapping\n",
        "    HERLEV_NORMAL = ['normal_columnar', 'normal_intermediate', 'normal_superficial']\n",
        "    HERLEV_ABNORMAL = ['carcinoma_in_situ', 'light_dysplastic', 'moderate_dysplastic', 'severe_dysplastic']\n",
        "\n",
        "    # Output\n",
        "    OUTPUT_CSV = 'combined_dataset.csv'\n",
        "\n",
        "config = KaggleConfig()\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"COMBINED DATASET CREATOR FOR KAGGLE/COLAB\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"SIPaKMeD Path: {config.SIPAKMED_PATH}\")\n",
        "print(f\"Herlev Path: {config.HERLEV_PATH}\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# ============================================================================\n",
        "# LOAD SIPAKMED DATASET\n",
        "# ============================================================================\n",
        "\n",
        "def load_sipakmed():\n",
        "    \"\"\"Load SIPaKMeD dataset\"\"\"\n",
        "    print(\"\\n[1] Loading SIPaKMeD Dataset...\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    data = []\n",
        "\n",
        "    for class_name, label in config.SIPAKMED_CLASSES.items():\n",
        "        # SIPaKMeD has nested structure: class_name/class_name/*.bmp\n",
        "        class_path = os.path.join(config.SIPAKMED_PATH, class_name, class_name)\n",
        "\n",
        "        if not os.path.exists(class_path):\n",
        "            # Try without nested folder\n",
        "            class_path = os.path.join(config.SIPAKMED_PATH, class_name)\n",
        "            if not os.path.exists(class_path):\n",
        "                print(f\"  ⚠️  Skipping {class_name} (not found)\")\n",
        "                continue\n",
        "\n",
        "        # Get all .bmp files\n",
        "        images = [f for f in os.listdir(class_path) if f.lower().endswith('.bmp')]\n",
        "\n",
        "        label_name = 'Normal' if label == 0 else 'Abnormal'\n",
        "        print(f\"  ✅ {class_name}: {len(images)} images ({label_name})\")\n",
        "\n",
        "        for img_name in images:\n",
        "            data.append({\n",
        "                'image_path': os.path.join(class_path, img_name),\n",
        "                'class_name': class_name,\n",
        "                'label': label,\n",
        "                'label_name': label_name,\n",
        "                'dataset_source': 'sipakmed'\n",
        "            })\n",
        "\n",
        "    print(f\"\\n  Total SIPaKMeD: {len(data)} images\")\n",
        "    return data\n",
        "\n",
        "# ============================================================================\n",
        "# LOAD HERLEV DATASET (WITH TEST/TRAIN SUBFOLDERS)\n",
        "# ============================================================================\n",
        "\n",
        "def load_herlev():\n",
        "    \"\"\"Load Herlev dataset with test/train structure\"\"\"\n",
        "    print(\"\\n[2] Loading Herlev Dataset...\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    data = []\n",
        "\n",
        "    # Handle nested \"Herlev Dataset\" folder\n",
        "    base_path = config.HERLEV_PATH\n",
        "\n",
        "    # Check if there's a \"Herlev Dataset\" subfolder\n",
        "    herlev_dataset_folder = os.path.join(base_path, 'Herlev Dataset')\n",
        "    if os.path.exists(herlev_dataset_folder):\n",
        "        print(\"  📁 Found 'Herlev Dataset' subfolder, using it as base\")\n",
        "        base_path = herlev_dataset_folder\n",
        "\n",
        "    # Detect structure\n",
        "    has_test = os.path.exists(os.path.join(base_path, 'test'))\n",
        "    has_train = os.path.exists(os.path.join(base_path, 'train'))\n",
        "\n",
        "    if has_test or has_train:\n",
        "        print(\"  📁 Detected test/train folder structure\")\n",
        "        subfolders = []\n",
        "        if has_test:\n",
        "            subfolders.append('test')\n",
        "        if has_train:\n",
        "            subfolders.append('train')\n",
        "    else:\n",
        "        print(\"  📁 Flat folder structure detected\")\n",
        "        subfolders = ['']\n",
        "\n",
        "    # Load from each subfolder\n",
        "    for subfolder in subfolders:\n",
        "        if subfolder:\n",
        "            print(f\"\\n  Loading from {subfolder}/ folder...\")\n",
        "            base_path = os.path.join(config.HERLEV_PATH, subfolder)\n",
        "        else:\n",
        "            base_path = config.HERLEV_PATH\n",
        "\n",
        "        if not os.path.exists(base_path):\n",
        "            print(f\"    ⚠️  Path not found: {base_path}\")\n",
        "            continue\n",
        "\n",
        "        # List all directories in this subfolder\n",
        "        try:\n",
        "            class_folders = [d for d in os.listdir(base_path)\n",
        "                           if os.path.isdir(os.path.join(base_path, d))]\n",
        "        except Exception as e:\n",
        "            print(f\"    ❌ Error reading {base_path}: {e}\")\n",
        "            continue\n",
        "\n",
        "        # Process each class folder\n",
        "        for class_name in class_folders:\n",
        "            class_path = os.path.join(base_path, class_name)\n",
        "\n",
        "            # Determine label\n",
        "            if class_name in config.HERLEV_NORMAL:\n",
        "                label = 0\n",
        "                label_name = 'Normal'\n",
        "            elif class_name in config.HERLEV_ABNORMAL:\n",
        "                label = 1\n",
        "                label_name = 'Abnormal'\n",
        "            else:\n",
        "                print(f\"    ⚠️  Unknown class: {class_name}, skipping\")\n",
        "                continue\n",
        "\n",
        "            # Get all image files\n",
        "            try:\n",
        "                images = [f for f in os.listdir(class_path)\n",
        "                         if f.lower().endswith(('.bmp', '.jpg', '.jpeg', '.png'))]\n",
        "            except Exception as e:\n",
        "                print(f\"    ❌ Error reading {class_path}: {e}\")\n",
        "                continue\n",
        "\n",
        "            print(f\"    ✅ {class_name}: {len(images)} images ({label_name})\")\n",
        "\n",
        "            for img_name in images:\n",
        "                data.append({\n",
        "                    'image_path': os.path.join(class_path, img_name),\n",
        "                    'class_name': class_name,\n",
        "                    'label': label,\n",
        "                    'label_name': label_name,\n",
        "                    'dataset_source': 'herlev',\n",
        "                    'subset': subfolder if subfolder else 'root'\n",
        "                })\n",
        "\n",
        "    print(f\"\\n  Total Herlev: {len(data)} images\")\n",
        "    return data\n",
        "\n",
        "# ============================================================================\n",
        "# COMBINE AND SAVE\n",
        "# ============================================================================\n",
        "\n",
        "def create_combined_dataset():\n",
        "    \"\"\"Create combined dataset\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"CREATING COMBINED DATASET\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Load both datasets\n",
        "    sipakmed_data = load_sipakmed()\n",
        "    herlev_data = load_herlev()\n",
        "\n",
        "    # Combine\n",
        "    all_data = sipakmed_data + herlev_data\n",
        "\n",
        "    if len(all_data) == 0:\n",
        "        print(\"\\n❌ ERROR: No data loaded!\")\n",
        "        print(\"\\n💡 Check:\")\n",
        "        print(\"   1. Are the dataset paths correct?\")\n",
        "        print(\"   2. Do the folders contain images?\")\n",
        "        print(\"   3. Run !ls /kaggle/input/ to see available datasets\")\n",
        "        return None\n",
        "\n",
        "    # Create dataframe\n",
        "    df = pd.DataFrame(all_data)\n",
        "\n",
        "    # Summary\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"COMBINED DATASET SUMMARY\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    print(f\"\\n📊 Total Samples: {len(df)}\")\n",
        "    print(f\"\\n📦 By Dataset Source:\")\n",
        "    print(df['dataset_source'].value_counts())\n",
        "\n",
        "    print(f\"\\n🏷️  By Label:\")\n",
        "    print(df['label_name'].value_counts())\n",
        "\n",
        "    print(f\"\\n📋 By Class:\")\n",
        "    class_counts = df.groupby(['dataset_source', 'class_name', 'label_name']).size()\n",
        "    print(class_counts)\n",
        "\n",
        "    # Check class balance\n",
        "    normal_count = len(df[df['label'] == 0])\n",
        "    abnormal_count = len(df[df['label'] == 1])\n",
        "    imbalance_ratio = max(normal_count, abnormal_count) / min(normal_count, abnormal_count)\n",
        "\n",
        "    print(f\"\\n⚖️  Class Balance:\")\n",
        "    print(f\"   Normal: {normal_count} ({normal_count/len(df)*100:.1f}%)\")\n",
        "    print(f\"   Abnormal: {abnormal_count} ({abnormal_count/len(df)*100:.1f}%)\")\n",
        "    print(f\"   Imbalance Ratio: {imbalance_ratio:.2f}:1\")\n",
        "\n",
        "    if imbalance_ratio > 2.0:\n",
        "        print(f\"   ⚠️  High imbalance - will use class weights during training\")\n",
        "\n",
        "    # Verify paths\n",
        "    print(f\"\\n🔍 Verifying Image Paths...\")\n",
        "    valid_count = 0\n",
        "    invalid_count = 0\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        if os.path.exists(row['image_path']):\n",
        "            valid_count += 1\n",
        "        else:\n",
        "            invalid_count += 1\n",
        "            if invalid_count <= 3:\n",
        "                print(f\"   ❌ Not found: {row['image_path']}\")\n",
        "\n",
        "    if invalid_count > 3:\n",
        "        print(f\"   ❌ ... and {invalid_count - 3} more invalid paths\")\n",
        "\n",
        "    print(f\"   ✅ Valid paths: {valid_count}/{len(df)}\")\n",
        "    print(f\"   ❌ Invalid paths: {invalid_count}/{len(df)}\")\n",
        "\n",
        "    if invalid_count > 0:\n",
        "        print(f\"\\n   ⚠️  WARNING: {invalid_count} images have invalid paths\")\n",
        "        print(f\"      These will be skipped during training\")\n",
        "\n",
        "    # Save\n",
        "    df.to_csv(config.OUTPUT_CSV, index=False)\n",
        "    print(f\"\\n💾 Combined dataset saved to: {config.OUTPUT_CSV}\")\n",
        "\n",
        "    return df\n",
        "\n",
        "# ============================================================================\n",
        "# VERIFY AND VISUALIZE\n",
        "# ============================================================================\n",
        "\n",
        "def verify_combined_dataset(csv_path):\n",
        "    \"\"\"Verify the combined dataset CSV\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"VERIFYING COMBINED DATASET\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    if not os.path.exists(csv_path):\n",
        "        print(f\"❌ CSV not found: {csv_path}\")\n",
        "        return\n",
        "\n",
        "    df = pd.read_csv(csv_path)\n",
        "\n",
        "    print(f\"\\n✅ CSV loaded successfully\")\n",
        "    print(f\"   Rows: {len(df)}\")\n",
        "    print(f\"   Columns: {list(df.columns)}\")\n",
        "\n",
        "    # Sample\n",
        "    print(f\"\\n📋 Sample rows:\")\n",
        "    print(df.head())\n",
        "\n",
        "    # Statistics\n",
        "    print(f\"\\n📊 Statistics by Dataset:\")\n",
        "    stats = df.groupby(['dataset_source', 'label_name']).size().unstack(fill_value=0)\n",
        "    print(stats)\n",
        "\n",
        "    return df\n",
        "\n",
        "# ============================================================================\n",
        "# KAGGLE-SPECIFIC UTILITIES\n",
        "# ============================================================================\n",
        "\n",
        "def explore_kaggle_datasets():\n",
        "    \"\"\"Explore available Kaggle dataset structure\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"EXPLORING KAGGLE DATASETS\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # List available datasets\n",
        "    print(\"\\n📦 Available datasets in /kaggle/input/:\")\n",
        "    try:\n",
        "        datasets = os.listdir('/kaggle/input/')\n",
        "        for dataset in datasets:\n",
        "            print(f\"   - {dataset}\")\n",
        "    except:\n",
        "        print(\"   ⚠️  Cannot access /kaggle/input/ (are you on Kaggle?)\")\n",
        "\n",
        "    # Explore SIPaKMeD structure\n",
        "    if os.path.exists(config.SIPAKMED_PATH):\n",
        "        print(f\"\\n📁 SIPaKMeD structure ({config.SIPAKMED_PATH}):\")\n",
        "        try:\n",
        "            items = os.listdir(config.SIPAKMED_PATH)\n",
        "            for item in items[:10]:  # Show first 10\n",
        "                item_path = os.path.join(config.SIPAKMED_PATH, item)\n",
        "                if os.path.isdir(item_path):\n",
        "                    subcount = len(os.listdir(item_path))\n",
        "                    print(f\"   📁 {item}/ ({subcount} items)\")\n",
        "                else:\n",
        "                    print(f\"   📄 {item}\")\n",
        "            if len(items) > 10:\n",
        "                print(f\"   ... and {len(items) - 10} more items\")\n",
        "        except Exception as e:\n",
        "            print(f\"   ❌ Error: {e}\")\n",
        "\n",
        "    # Explore Herlev structure\n",
        "    if os.path.exists(config.HERLEV_PATH):\n",
        "        print(f\"\\n📁 Herlev structure ({config.HERLEV_PATH}):\")\n",
        "        try:\n",
        "            items = os.listdir(config.HERLEV_PATH)\n",
        "            for item in items[:10]:\n",
        "                item_path = os.path.join(config.HERLEV_PATH, item)\n",
        "                if os.path.isdir(item_path):\n",
        "                    try:\n",
        "                        subcount = len(os.listdir(item_path))\n",
        "                        print(f\"   📁 {item}/ ({subcount} items)\")\n",
        "                        # Show subfolders\n",
        "                        subitems = os.listdir(item_path)[:5]\n",
        "                        for subitem in subitems:\n",
        "                            print(f\"      - {subitem}\")\n",
        "                    except:\n",
        "                        print(f\"   📁 {item}/\")\n",
        "                else:\n",
        "                    print(f\"   📄 {item}\")\n",
        "            if len(items) > 10:\n",
        "                print(f\"   ... and {len(items) - 10} more items\")\n",
        "        except Exception as e:\n",
        "            print(f\"   ❌ Error: {e}\")\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN\n",
        "# ============================================================================\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main execution\"\"\"\n",
        "\n",
        "    # First, explore structure\n",
        "    explore_kaggle_datasets()\n",
        "\n",
        "    # Create combined dataset\n",
        "    df = create_combined_dataset()\n",
        "\n",
        "    if df is not None:\n",
        "        # Verify\n",
        "        verify_combined_dataset(config.OUTPUT_CSV)\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"✅ SUCCESS!\")\n",
        "        print(\"=\" * 80)\n",
        "        print(f\"\\n📝 Next steps:\")\n",
        "        print(f\"   1. Use 'combined_dataset.csv' for training\")\n",
        "        print(f\"   2. Run the combined training script:\")\n",
        "        print(f\"      python combined_training.py\")\n",
        "        print(f\"   3. Model will work on BOTH datasets!\")\n",
        "        print(\"=\" * 80)\n",
        "    else:\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"❌ FAILED TO CREATE COMBINED DATASET\")\n",
        "        print(\"=\" * 80)\n",
        "        print(\"\\n💡 Troubleshooting:\")\n",
        "        print(\"   1. Check dataset paths are correct\")\n",
        "        print(\"   2. Verify datasets are mounted in Kaggle\")\n",
        "        print(\"   3. Run explore_kaggle_datasets() to see structure\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "# ============================================================================\n",
        "# QUICK TEST (Uncomment to use in notebook)\n",
        "# ============================================================================\n",
        "\n",
        "# Test individually\n",
        "# explore_kaggle_datasets()\n",
        "# df = create_combined_dataset()\n",
        "# verify_combined_dataset('combined_dataset.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1ce2d3d-dd66-498e-819d-d57c19736354",
        "id": "8j1hZ6rJZfh1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "COMBINED DATASET CREATOR FOR KAGGLE/COLAB\n",
            "================================================================================\n",
            "SIPaKMeD Path: /kaggle/input/cervical-cancer-largest-dataset-sipakmed\n",
            "Herlev Path: /kaggle/input/herlev-dataset/Herlev Dataset\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "EXPLORING KAGGLE DATASETS\n",
            "================================================================================\n",
            "\n",
            "📦 Available datasets in /kaggle/input/:\n",
            "   - herlev-dataset\n",
            "   - cervical-cancer-largest-dataset-sipakmed\n",
            "\n",
            "📁 SIPaKMeD structure (/kaggle/input/cervical-cancer-largest-dataset-sipakmed):\n",
            "   📁 im_Parabasal/ (1 items)\n",
            "   📁 im_Dyskeratotic/ (1 items)\n",
            "   📁 im_Metaplastic/ (1 items)\n",
            "   📁 im_Superficial-Intermediate/ (1 items)\n",
            "   📁 im_Koilocytotic/ (1 items)\n",
            "\n",
            "📁 Herlev structure (/kaggle/input/herlev-dataset/Herlev Dataset):\n",
            "   📁 test/ (7 items)\n",
            "      - normal_intermediate\n",
            "      - severe_dysplastic\n",
            "      - carcinoma_in_situ\n",
            "      - moderate_dysplastic\n",
            "      - normal_columnar\n",
            "   📁 train/ (7 items)\n",
            "      - normal_intermediate\n",
            "      - severe_dysplastic\n",
            "      - carcinoma_in_situ\n",
            "      - moderate_dysplastic\n",
            "      - normal_columnar\n",
            "\n",
            "================================================================================\n",
            "CREATING COMBINED DATASET\n",
            "================================================================================\n",
            "\n",
            "[1] Loading SIPaKMeD Dataset...\n",
            "--------------------------------------------------------------------------------\n",
            "  ✅ im_Superficial-Intermediate: 126 images (Normal)\n",
            "  ✅ im_Dyskeratotic: 223 images (Abnormal)\n",
            "  ✅ im_Koilocytotic: 238 images (Abnormal)\n",
            "  ✅ im_Parabasal: 108 images (Abnormal)\n",
            "  ✅ im_Metaplastic: 271 images (Normal)\n",
            "\n",
            "  Total SIPaKMeD: 966 images\n",
            "\n",
            "[2] Loading Herlev Dataset...\n",
            "--------------------------------------------------------------------------------\n",
            "  📁 Detected test/train folder structure\n",
            "\n",
            "  Loading from test/ folder...\n",
            "    ✅ normal_intermediate: 21 images (Normal)\n",
            "    ✅ severe_dysplastic: 59 images (Abnormal)\n",
            "    ✅ carcinoma_in_situ: 45 images (Abnormal)\n",
            "    ✅ moderate_dysplastic: 43 images (Abnormal)\n",
            "    ✅ normal_columnar: 29 images (Normal)\n",
            "    ⚠️  Unknown class: normal_superficiel, skipping\n",
            "    ✅ light_dysplastic: 54 images (Abnormal)\n",
            "\n",
            "  Loading from train/ folder...\n",
            "    ✅ normal_intermediate: 49 images (Normal)\n",
            "    ✅ severe_dysplastic: 138 images (Abnormal)\n",
            "    ✅ carcinoma_in_situ: 105 images (Abnormal)\n",
            "    ✅ moderate_dysplastic: 103 images (Abnormal)\n",
            "    ✅ normal_columnar: 69 images (Normal)\n",
            "    ⚠️  Unknown class: normal_superficiel, skipping\n",
            "    ✅ light_dysplastic: 128 images (Abnormal)\n",
            "\n",
            "  Total Herlev: 843 images\n",
            "\n",
            "================================================================================\n",
            "COMBINED DATASET SUMMARY\n",
            "================================================================================\n",
            "\n",
            "📊 Total Samples: 1809\n",
            "\n",
            "📦 By Dataset Source:\n",
            "dataset_source\n",
            "sipakmed    966\n",
            "herlev      843\n",
            "Name: count, dtype: int64\n",
            "\n",
            "🏷️  By Label:\n",
            "label_name\n",
            "Abnormal    1244\n",
            "Normal       565\n",
            "Name: count, dtype: int64\n",
            "\n",
            "📋 By Class:\n",
            "dataset_source  class_name                   label_name\n",
            "herlev          carcinoma_in_situ            Abnormal      150\n",
            "                light_dysplastic             Abnormal      182\n",
            "                moderate_dysplastic          Abnormal      146\n",
            "                normal_columnar              Normal         98\n",
            "                normal_intermediate          Normal         70\n",
            "                severe_dysplastic            Abnormal      197\n",
            "sipakmed        im_Dyskeratotic              Abnormal      223\n",
            "                im_Koilocytotic              Abnormal      238\n",
            "                im_Metaplastic               Normal        271\n",
            "                im_Parabasal                 Abnormal      108\n",
            "                im_Superficial-Intermediate  Normal        126\n",
            "dtype: int64\n",
            "\n",
            "⚖️  Class Balance:\n",
            "   Normal: 565 (31.2%)\n",
            "   Abnormal: 1244 (68.8%)\n",
            "   Imbalance Ratio: 2.20:1\n",
            "   ⚠️  High imbalance - will use class weights during training\n",
            "\n",
            "🔍 Verifying Image Paths...\n",
            "   ✅ Valid paths: 1809/1809\n",
            "   ❌ Invalid paths: 0/1809\n",
            "\n",
            "💾 Combined dataset saved to: combined_dataset.csv\n",
            "\n",
            "================================================================================\n",
            "VERIFYING COMBINED DATASET\n",
            "================================================================================\n",
            "\n",
            "✅ CSV loaded successfully\n",
            "   Rows: 1809\n",
            "   Columns: ['image_path', 'class_name', 'label', 'label_name', 'dataset_source', 'subset']\n",
            "\n",
            "📋 Sample rows:\n",
            "                                          image_path  \\\n",
            "0  /kaggle/input/cervical-cancer-largest-dataset-...   \n",
            "1  /kaggle/input/cervical-cancer-largest-dataset-...   \n",
            "2  /kaggle/input/cervical-cancer-largest-dataset-...   \n",
            "3  /kaggle/input/cervical-cancer-largest-dataset-...   \n",
            "4  /kaggle/input/cervical-cancer-largest-dataset-...   \n",
            "\n",
            "                    class_name  label label_name dataset_source subset  \n",
            "0  im_Superficial-Intermediate      0     Normal       sipakmed    NaN  \n",
            "1  im_Superficial-Intermediate      0     Normal       sipakmed    NaN  \n",
            "2  im_Superficial-Intermediate      0     Normal       sipakmed    NaN  \n",
            "3  im_Superficial-Intermediate      0     Normal       sipakmed    NaN  \n",
            "4  im_Superficial-Intermediate      0     Normal       sipakmed    NaN  \n",
            "\n",
            "📊 Statistics by Dataset:\n",
            "label_name      Abnormal  Normal\n",
            "dataset_source                  \n",
            "herlev               675     168\n",
            "sipakmed             569     397\n",
            "\n",
            "================================================================================\n",
            "✅ SUCCESS!\n",
            "================================================================================\n",
            "\n",
            "📝 Next steps:\n",
            "   1. Use 'combined_dataset.csv' for training\n",
            "   2. Run the combined training script:\n",
            "      python combined_training.py\n",
            "   3. Model will work on BOTH datasets!\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Quick Combined Dataset Training\n",
        "Minimal modification to use combined_dataset.csv\n",
        "\n",
        "Just replace the data loading section of your existing script with this\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow as tf\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 1: LOAD COMBINED DATASET (Replace your existing data loading)\n",
        "# ============================================================================\n",
        "\n",
        "def load_combined_data(csv_path='combined_dataset.csv'):\n",
        "    \"\"\"Load combined dataset from CSV\"\"\"\n",
        "    print(\"\\n[Loading Combined Dataset]\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Load CSV\n",
        "    df = pd.read_csv(csv_path)\n",
        "\n",
        "    print(f\"✅ Loaded {len(df)} images\")\n",
        "    print(f\"\\nDataset breakdown:\")\n",
        "    print(df['dataset_source'].value_counts())\n",
        "    print(f\"\\nLabel breakdown:\")\n",
        "    print(df.groupby(['dataset_source', 'label']).size())\n",
        "\n",
        "    # Verify paths exist\n",
        "    print(f\"\\nVerifying image paths...\")\n",
        "    valid_rows = []\n",
        "    for idx, row in df.iterrows():\n",
        "        if os.path.exists(row['image_path']):\n",
        "            valid_rows.append(row)\n",
        "        else:\n",
        "            if len(valid_rows) == 0:\n",
        "                print(f\"  ⚠️  First invalid path: {row['image_path']}\")\n",
        "\n",
        "    df = pd.DataFrame(valid_rows)\n",
        "    print(f\"✅ Valid images: {len(df)}\")\n",
        "\n",
        "    return df\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 2: SPLIT DATA (Stratified by both dataset and label)\n",
        "# ============================================================================\n",
        "\n",
        "def split_combined_data(df, test_size=0.2, val_size=0.125, random_state=42):\n",
        "    \"\"\"Split combined dataset ensuring both datasets in each split\"\"\"\n",
        "    print(\"\\n[Splitting Dataset]\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Split by dataset first to ensure representation\n",
        "    sipakmed_df = df[df['dataset_source'] == 'sipakmed']\n",
        "    herlev_df = df[df['dataset_source'] == 'herlev']\n",
        "\n",
        "    # Split SIPaKMeD\n",
        "    sip_train_val, sip_test = train_test_split(\n",
        "        sipakmed_df, test_size=test_size,\n",
        "        stratify=sipakmed_df['label'], random_state=random_state\n",
        "    )\n",
        "    sip_train, sip_val = train_test_split(\n",
        "        sip_train_val, test_size=val_size,\n",
        "        stratify=sip_train_val['label'], random_state=random_state\n",
        "    )\n",
        "\n",
        "    # Split Herlev\n",
        "    her_train_val, her_test = train_test_split(\n",
        "        herlev_df, test_size=test_size,\n",
        "        stratify=herlev_df['label'], random_state=random_state\n",
        "    )\n",
        "    her_train, her_val = train_test_split(\n",
        "        her_train_val, test_size=val_size,\n",
        "        stratify=her_train_val['label'], random_state=random_state\n",
        "    )\n",
        "\n",
        "    # Combine splits\n",
        "    train_df = pd.concat([sip_train, her_train], ignore_index=True)\n",
        "    val_df = pd.concat([sip_val, her_val], ignore_index=True)\n",
        "    test_df = pd.concat([sip_test, her_test], ignore_index=True)\n",
        "\n",
        "    print(f\"Train: {len(train_df)} (SIPaKMeD: {len(sip_train)}, Herlev: {len(her_train)})\")\n",
        "    print(f\"Val:   {len(val_df)} (SIPaKMeD: {len(sip_val)}, Herlev: {len(her_val)})\")\n",
        "    print(f\"Test:  {len(test_df)} (SIPaKMeD: {len(sip_test)}, Herlev: {len(her_test)})\")\n",
        "\n",
        "    return train_df, val_df, test_df\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 3: CREATE DATA GENERATORS\n",
        "# ============================================================================\n",
        "\n",
        "def create_generators(train_df, val_df, test_df, img_size=224, batch_size=16):\n",
        "    \"\"\"Create data generators\"\"\"\n",
        "    print(\"\\n[Creating Data Generators]\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Convert labels to strings for Keras\n",
        "    train_df = train_df.copy()\n",
        "    val_df = val_df.copy()\n",
        "    test_df = test_df.copy()\n",
        "\n",
        "    train_df['label_str'] = train_df['label'].astype(str)\n",
        "    val_df['label_str'] = val_df['label'].astype(str)\n",
        "    test_df['label_str'] = test_df['label'].astype(str)\n",
        "\n",
        "    # Strong augmentation for combined dataset\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        rotation_range=30,\n",
        "        width_shift_range=0.3,\n",
        "        height_shift_range=0.3,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=True,\n",
        "        zoom_range=0.3,\n",
        "        shear_range=0.2,\n",
        "        brightness_range=[0.7, 1.3],  # Important for different datasets\n",
        "        fill_mode='nearest'\n",
        "    )\n",
        "\n",
        "    val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    train_gen = train_datagen.flow_from_dataframe(\n",
        "        train_df, x_col='image_path', y_col='label_str',\n",
        "        target_size=(img_size, img_size),\n",
        "        batch_size=batch_size, class_mode='binary', shuffle=True\n",
        "    )\n",
        "\n",
        "    val_gen = val_test_datagen.flow_from_dataframe(\n",
        "        val_df, x_col='image_path', y_col='label_str',\n",
        "        target_size=(img_size, img_size),\n",
        "        batch_size=batch_size, class_mode='binary', shuffle=False\n",
        "    )\n",
        "\n",
        "    test_gen = val_test_datagen.flow_from_dataframe(\n",
        "        test_df, x_col='image_path', y_col='label_str',\n",
        "        target_size=(img_size, img_size),\n",
        "        batch_size=batch_size, class_mode='binary', shuffle=False\n",
        "    )\n",
        "\n",
        "    print(f\"✅ Train: {len(train_gen)} batches\")\n",
        "    print(f\"✅ Val:   {len(val_gen)} batches\")\n",
        "    print(f\"✅ Test:  {len(test_gen)} batches\")\n",
        "\n",
        "    return train_gen, val_gen, test_gen, train_df, val_df, test_df\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 4: COMPUTE CLASS WEIGHTS\n",
        "# ============================================================================\n",
        "\n",
        "def get_class_weights(train_df):\n",
        "    \"\"\"Compute class weights for imbalanced data\"\"\"\n",
        "    print(\"\\n[Computing Class Weights]\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    labels = train_df['label'].values\n",
        "    class_weights = compute_class_weight(\n",
        "        'balanced',\n",
        "        classes=np.unique(labels),\n",
        "        y=labels\n",
        "    )\n",
        "    class_weight_dict = dict(enumerate(class_weights))\n",
        "\n",
        "    print(f\"Class 0 (Normal):   weight = {class_weight_dict[0]:.3f}\")\n",
        "    print(f\"Class 1 (Abnormal): weight = {class_weight_dict[1]:.3f}\")\n",
        "\n",
        "    return class_weight_dict\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 5: EVALUATE ON EACH DATASET SEPARATELY\n",
        "# ============================================================================\n",
        "\n",
        "def evaluate_by_dataset(model, test_df, img_size=224, batch_size=16):\n",
        "    \"\"\"Evaluate separately on SIPaKMeD and Herlev\"\"\"\n",
        "    from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"EVALUATION BY DATASET\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for dataset_name in ['sipakmed', 'herlev']:\n",
        "        dataset_df = test_df[test_df['dataset_source'] == dataset_name].copy()\n",
        "\n",
        "        if len(dataset_df) == 0:\n",
        "            continue\n",
        "\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"{dataset_name.upper()} TEST SET\")\n",
        "        print(f\"{'='*80}\")\n",
        "\n",
        "        # Create generator\n",
        "        dataset_df['label_str'] = dataset_df['label'].astype(str)\n",
        "        datagen = ImageDataGenerator(rescale=1./255)\n",
        "        gen = datagen.flow_from_dataframe(\n",
        "            dataset_df, x_col='image_path', y_col='label_str',\n",
        "            target_size=(img_size, img_size),\n",
        "            batch_size=batch_size, class_mode='binary', shuffle=False\n",
        "        )\n",
        "\n",
        "        # Predict\n",
        "        y_pred_proba = model.predict(gen, verbose=0).flatten()\n",
        "        y_pred = (y_pred_proba >= 0.5).astype(int)\n",
        "        y_true = dataset_df['label'].values\n",
        "\n",
        "        # Metrics\n",
        "        print(f\"\\nClassification Report:\")\n",
        "        print(classification_report(y_true, y_pred,\n",
        "                                   target_names=['Normal', 'Abnormal']))\n",
        "\n",
        "        cm = confusion_matrix(y_true, y_pred)\n",
        "        tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "        accuracy = (tp + tn) / len(y_true)\n",
        "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "\n",
        "        print(f\"\\nConfusion Matrix:\")\n",
        "        print(cm)\n",
        "        print(f\"\\nKey Metrics:\")\n",
        "        print(f\"  Accuracy:    {accuracy*100:.2f}%\")\n",
        "        print(f\"  Sensitivity: {sensitivity*100:.2f}%\")\n",
        "        print(f\"  Specificity: {specificity*100:.2f}%\")\n",
        "        print(f\"  Missed Cancers: {fn}\")\n",
        "\n",
        "        try:\n",
        "            roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
        "            print(f\"  ROC-AUC: {roc_auc:.4f}\")\n",
        "        except:\n",
        "            roc_auc = 0\n",
        "\n",
        "        results[dataset_name] = {\n",
        "            'accuracy': accuracy,\n",
        "            'sensitivity': sensitivity,\n",
        "            'specificity': specificity,\n",
        "            'missed_cancers': int(fn)\n",
        "        }\n",
        "\n",
        "    return results\n",
        "\n",
        "# ============================================================================\n",
        "# USAGE EXAMPLE - Replace your main() function with this\n",
        "# ============================================================================\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main training pipeline using combined dataset\"\"\"\n",
        "\n",
        "    # Configuration\n",
        "    IMG_SIZE = 224\n",
        "    BATCH_SIZE = 16\n",
        "    EPOCHS_FROZEN = 50\n",
        "    EPOCHS_FINETUNE = 30\n",
        "\n",
        "    # 1. Load combined dataset\n",
        "    df = load_combined_data('combined_dataset.csv')\n",
        "\n",
        "    # 2. Split data\n",
        "    train_df, val_df, test_df = split_combined_data(df)\n",
        "\n",
        "    # 3. Create generators\n",
        "    train_gen, val_gen, test_gen, train_df, val_df, test_df = create_generators(\n",
        "        train_df, val_df, test_df, IMG_SIZE, BATCH_SIZE\n",
        "    )\n",
        "\n",
        "    # 4. Compute class weights\n",
        "    class_weights = get_class_weights(train_df)\n",
        "\n",
        "    # 5. Build model (use your existing model building code)\n",
        "    from tensorflow.keras.applications import VGG16\n",
        "    from tensorflow.keras.models import Model\n",
        "    from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
        "    from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "    base_model = VGG16(weights='imagenet', include_top=False,\n",
        "                       input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "    base_model.trainable = False\n",
        "\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.0001),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy',\n",
        "                tf.keras.metrics.Precision(name='precision'),\n",
        "                tf.keras.metrics.Recall(name='recall')]\n",
        "    )\n",
        "\n",
        "    print(\"\\n[Training Phase 1: Frozen Base]\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # 6. Train with class weights\n",
        "    from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "    callbacks = [\n",
        "        ModelCheckpoint('best_model_combined.h5', save_best_only=True, monitor='val_loss'),\n",
        "        EarlyStopping(patience=15, restore_best_weights=True, monitor='val_loss'),\n",
        "        ReduceLROnPlateau(factor=0.5, patience=7, min_lr=1e-7)\n",
        "    ]\n",
        "\n",
        "    history = model.fit(\n",
        "        train_gen,\n",
        "        epochs=EPOCHS_FROZEN,\n",
        "        validation_data=val_gen,\n",
        "        callbacks=callbacks,\n",
        "        class_weight=class_weights,  # ← Important!\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # 7. Fine-tuning\n",
        "    print(\"\\n[Training Phase 2: Fine-tuning]\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    base_model.trainable = True\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.00001),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy',\n",
        "                tf.keras.metrics.Precision(name='precision'),\n",
        "                tf.keras.metrics.Recall(name='recall')]\n",
        "    )\n",
        "\n",
        "    callbacks = [\n",
        "        ModelCheckpoint('final_model_combined.h5', save_best_only=True, monitor='val_loss'),\n",
        "        EarlyStopping(patience=15, restore_best_weights=True, monitor='val_loss'),\n",
        "        ReduceLROnPlateau(factor=0.5, patience=7, min_lr=1e-7)\n",
        "    ]\n",
        "\n",
        "    history_fine = model.fit(\n",
        "        train_gen,\n",
        "        epochs=EPOCHS_FINETUNE,\n",
        "        validation_data=val_gen,\n",
        "        callbacks=callbacks,\n",
        "        class_weight=class_weights,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # 8. Evaluate on both datasets\n",
        "    results = evaluate_by_dataset(model, test_df, IMG_SIZE, BATCH_SIZE)\n",
        "\n",
        "    # 9. Save results\n",
        "    import json\n",
        "    with open('combined_results.json', 'w') as f:\n",
        "        json.dump(results, f, indent=4)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"✅ TRAINING COMPLETE!\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"\\n📊 Results Summary:\")\n",
        "    for dataset, metrics in results.items():\n",
        "        print(f\"\\n{dataset.upper()}:\")\n",
        "        print(f\"  Accuracy: {metrics['accuracy']*100:.2f}%\")\n",
        "        print(f\"  Sensitivity: {metrics['sensitivity']*100:.2f}%\")\n",
        "        print(f\"  Specificity: {metrics['specificity']*100:.2f}%\")\n",
        "        print(f\"  Missed Cancers: {metrics['missed_cancers']}\")\n",
        "\n",
        "    print(f\"\\n💾 Model saved to: final_model_combined.h5\")\n",
        "    print(f\"🎯 This model now works on BOTH SIPaKMeD and Herlev!\")\n",
        "\n",
        "    return model, results\n",
        "\n",
        "# ============================================================================\n",
        "# RUN IT!\n",
        "# ============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    model, results = main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56FK2IoZhcbm",
        "outputId": "8a371b14-ff83-4322-9097-e5bbbd54f1c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Loading Combined Dataset]\n",
            "================================================================================\n",
            "✅ Loaded 1809 images\n",
            "\n",
            "Dataset breakdown:\n",
            "dataset_source\n",
            "sipakmed    966\n",
            "herlev      843\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Label breakdown:\n",
            "dataset_source  label\n",
            "herlev          0        168\n",
            "                1        675\n",
            "sipakmed        0        397\n",
            "                1        569\n",
            "dtype: int64\n",
            "\n",
            "Verifying image paths...\n",
            "✅ Valid images: 1809\n",
            "\n",
            "[Splitting Dataset]\n",
            "================================================================================\n",
            "Train: 1264 (SIPaKMeD: 675, Herlev: 589)\n",
            "Val:   182 (SIPaKMeD: 97, Herlev: 85)\n",
            "Test:  363 (SIPaKMeD: 194, Herlev: 169)\n",
            "\n",
            "[Creating Data Generators]\n",
            "================================================================================\n",
            "Found 1264 validated image filenames belonging to 2 classes.\n",
            "Found 182 validated image filenames belonging to 2 classes.\n",
            "Found 363 validated image filenames belonging to 2 classes.\n",
            "✅ Train: 79 batches\n",
            "✅ Val:   12 batches\n",
            "✅ Test:  23 batches\n",
            "\n",
            "[Computing Class Weights]\n",
            "================================================================================\n",
            "Class 0 (Normal):   weight = 1.604\n",
            "Class 1 (Abnormal): weight = 0.726\n",
            "\n",
            "[Training Phase 1: Frozen Base]\n",
            "================================================================================\n",
            "Epoch 1/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step - accuracy: 0.5655 - loss: 1.6582 - precision: 0.7038 - recall: 0.6266"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 426ms/step - accuracy: 0.5656 - loss: 1.6574 - precision: 0.7041 - recall: 0.6264 - val_accuracy: 0.6923 - val_loss: 1.4793 - val_precision: 0.6949 - val_recall: 0.9840 - learning_rate: 1.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - accuracy: 0.6383 - loss: 1.5247 - precision: 0.7845 - recall: 0.6542"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 327ms/step - accuracy: 0.6386 - loss: 1.5244 - precision: 0.7847 - recall: 0.6544 - val_accuracy: 0.7527 - val_loss: 1.4561 - val_precision: 0.8279 - val_recall: 0.8080 - learning_rate: 1.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - accuracy: 0.6727 - loss: 1.4852 - precision: 0.7996 - recall: 0.6814"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 327ms/step - accuracy: 0.6728 - loss: 1.4847 - precision: 0.7999 - recall: 0.6813 - val_accuracy: 0.7363 - val_loss: 1.4300 - val_precision: 0.8667 - val_recall: 0.7280 - learning_rate: 1.0000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 0.6896 - loss: 1.4424 - precision: 0.8176 - recall: 0.7296"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 326ms/step - accuracy: 0.6897 - loss: 1.4422 - precision: 0.8175 - recall: 0.7296 - val_accuracy: 0.7253 - val_loss: 1.4101 - val_precision: 0.8788 - val_recall: 0.6960 - learning_rate: 1.0000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step - accuracy: 0.7033 - loss: 1.4094 - precision: 0.8580 - recall: 0.6874"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 333ms/step - accuracy: 0.7034 - loss: 1.4094 - precision: 0.8579 - recall: 0.6875 - val_accuracy: 0.7473 - val_loss: 1.3775 - val_precision: 0.8692 - val_recall: 0.7440 - learning_rate: 1.0000e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step - accuracy: 0.7288 - loss: 1.3938 - precision: 0.8375 - recall: 0.7580"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 335ms/step - accuracy: 0.7288 - loss: 1.3937 - precision: 0.8375 - recall: 0.7580 - val_accuracy: 0.7418 - val_loss: 1.3684 - val_precision: 0.8750 - val_recall: 0.7280 - learning_rate: 1.0000e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 332ms/step - accuracy: 0.7381 - loss: 1.3941 - precision: 0.8237 - recall: 0.7770 - val_accuracy: 0.7473 - val_loss: 1.3732 - val_precision: 0.8835 - val_recall: 0.7280 - learning_rate: 1.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - accuracy: 0.7260 - loss: 1.3654 - precision: 0.8316 - recall: 0.7554"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 329ms/step - accuracy: 0.7261 - loss: 1.3655 - precision: 0.8318 - recall: 0.7554 - val_accuracy: 0.7527 - val_loss: 1.3597 - val_precision: 0.8846 - val_recall: 0.7360 - learning_rate: 1.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step - accuracy: 0.7476 - loss: 1.3420 - precision: 0.8518 - recall: 0.7683"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 335ms/step - accuracy: 0.7477 - loss: 1.3420 - precision: 0.8518 - recall: 0.7684 - val_accuracy: 0.7967 - val_loss: 1.3370 - val_precision: 0.8929 - val_recall: 0.8000 - learning_rate: 1.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309ms/step - accuracy: 0.7529 - loss: 1.3520 - precision: 0.8525 - recall: 0.7763"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 331ms/step - accuracy: 0.7529 - loss: 1.3520 - precision: 0.8525 - recall: 0.7763 - val_accuracy: 0.8022 - val_loss: 1.3302 - val_precision: 0.8938 - val_recall: 0.8080 - learning_rate: 1.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309ms/step - accuracy: 0.7570 - loss: 1.3210 - precision: 0.8462 - recall: 0.7898"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 331ms/step - accuracy: 0.7571 - loss: 1.3211 - precision: 0.8462 - recall: 0.7898 - val_accuracy: 0.8242 - val_loss: 1.3041 - val_precision: 0.8974 - val_recall: 0.8400 - learning_rate: 1.0000e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - accuracy: 0.7734 - loss: 1.2736 - precision: 0.8593 - recall: 0.8012"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 327ms/step - accuracy: 0.7734 - loss: 1.2739 - precision: 0.8593 - recall: 0.8011 - val_accuracy: 0.8297 - val_loss: 1.2812 - val_precision: 0.8917 - val_recall: 0.8560 - learning_rate: 1.0000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 327ms/step - accuracy: 0.7497 - loss: 1.3174 - precision: 0.8553 - recall: 0.7639 - val_accuracy: 0.8352 - val_loss: 1.2849 - val_precision: 0.8992 - val_recall: 0.8560 - learning_rate: 1.0000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 335ms/step - accuracy: 0.7582 - loss: 1.2967 - precision: 0.8632 - recall: 0.7773 - val_accuracy: 0.8242 - val_loss: 1.2839 - val_precision: 0.8908 - val_recall: 0.8480 - learning_rate: 1.0000e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 328ms/step - accuracy: 0.7453 - loss: 1.3158 - precision: 0.8516 - recall: 0.7711 - val_accuracy: 0.8187 - val_loss: 1.2981 - val_precision: 0.8898 - val_recall: 0.8400 - learning_rate: 1.0000e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 333ms/step - accuracy: 0.7644 - loss: 1.2890 - precision: 0.8700 - recall: 0.7787 - val_accuracy: 0.8242 - val_loss: 1.2918 - val_precision: 0.8908 - val_recall: 0.8480 - learning_rate: 1.0000e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 329ms/step - accuracy: 0.7642 - loss: 1.2639 - precision: 0.8681 - recall: 0.7749 - val_accuracy: 0.8242 - val_loss: 1.3139 - val_precision: 0.8974 - val_recall: 0.8400 - learning_rate: 1.0000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 329ms/step - accuracy: 0.7854 - loss: 1.2635 - precision: 0.8422 - recall: 0.8352 - val_accuracy: 0.8132 - val_loss: 1.2990 - val_precision: 0.8889 - val_recall: 0.8320 - learning_rate: 1.0000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309ms/step - accuracy: 0.7879 - loss: 1.2428 - precision: 0.8442 - recall: 0.8408"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 331ms/step - accuracy: 0.7877 - loss: 1.2430 - precision: 0.8443 - recall: 0.8405 - val_accuracy: 0.8352 - val_loss: 1.2687 - val_precision: 0.8926 - val_recall: 0.8640 - learning_rate: 1.0000e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - accuracy: 0.7859 - loss: 1.2500 - precision: 0.8719 - recall: 0.8102"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 329ms/step - accuracy: 0.7858 - loss: 1.2500 - precision: 0.8717 - recall: 0.8101 - val_accuracy: 0.8297 - val_loss: 1.2678 - val_precision: 0.8917 - val_recall: 0.8560 - learning_rate: 1.0000e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - accuracy: 0.7566 - loss: 1.2603 - precision: 0.8420 - recall: 0.7859"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 327ms/step - accuracy: 0.7568 - loss: 1.2601 - precision: 0.8422 - recall: 0.7861 - val_accuracy: 0.8297 - val_loss: 1.2641 - val_precision: 0.8790 - val_recall: 0.8720 - learning_rate: 1.0000e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 329ms/step - accuracy: 0.7751 - loss: 1.2481 - precision: 0.8454 - recall: 0.8203 - val_accuracy: 0.8242 - val_loss: 1.2667 - val_precision: 0.8843 - val_recall: 0.8560 - learning_rate: 1.0000e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.7624 - loss: 1.2482 - precision: 0.8417 - recall: 0.8128"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 333ms/step - accuracy: 0.7627 - loss: 1.2478 - precision: 0.8419 - recall: 0.8130 - val_accuracy: 0.8242 - val_loss: 1.2593 - val_precision: 0.8908 - val_recall: 0.8480 - learning_rate: 1.0000e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - accuracy: 0.8014 - loss: 1.1891 - precision: 0.8871 - recall: 0.8231"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 326ms/step - accuracy: 0.8014 - loss: 1.1896 - precision: 0.8869 - recall: 0.8232 - val_accuracy: 0.8077 - val_loss: 1.2592 - val_precision: 0.8879 - val_recall: 0.8240 - learning_rate: 1.0000e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step - accuracy: 0.7902 - loss: 1.2173 - precision: 0.8646 - recall: 0.8310"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 334ms/step - accuracy: 0.7903 - loss: 1.2171 - precision: 0.8646 - recall: 0.8312 - val_accuracy: 0.8077 - val_loss: 1.2331 - val_precision: 0.8814 - val_recall: 0.8320 - learning_rate: 1.0000e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.7635 - loss: 1.2268 - precision: 0.8450 - recall: 0.8009"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 330ms/step - accuracy: 0.7637 - loss: 1.2265 - precision: 0.8452 - recall: 0.8010 - val_accuracy: 0.8022 - val_loss: 1.2300 - val_precision: 0.8803 - val_recall: 0.8240 - learning_rate: 1.0000e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.7799 - loss: 1.2082 - precision: 0.8556 - recall: 0.8136"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 330ms/step - accuracy: 0.7802 - loss: 1.2078 - precision: 0.8558 - recall: 0.8139 - val_accuracy: 0.8132 - val_loss: 1.2274 - val_precision: 0.8889 - val_recall: 0.8320 - learning_rate: 1.0000e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - accuracy: 0.8040 - loss: 1.1918 - precision: 0.8674 - recall: 0.8437"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 328ms/step - accuracy: 0.8038 - loss: 1.1917 - precision: 0.8674 - recall: 0.8435 - val_accuracy: 0.8132 - val_loss: 1.2244 - val_precision: 0.8824 - val_recall: 0.8400 - learning_rate: 1.0000e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 326ms/step - accuracy: 0.8082 - loss: 1.1862 - precision: 0.8763 - recall: 0.8377 - val_accuracy: 0.8077 - val_loss: 1.2407 - val_precision: 0.8814 - val_recall: 0.8320 - learning_rate: 1.0000e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 331ms/step - accuracy: 0.7797 - loss: 1.1808 - precision: 0.8555 - recall: 0.8169 - val_accuracy: 0.8187 - val_loss: 1.2323 - val_precision: 0.8833 - val_recall: 0.8480 - learning_rate: 1.0000e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - accuracy: 0.7984 - loss: 1.1740 - precision: 0.8552 - recall: 0.8476"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 333ms/step - accuracy: 0.7983 - loss: 1.1742 - precision: 0.8552 - recall: 0.8474 - val_accuracy: 0.8242 - val_loss: 1.2081 - val_precision: 0.8780 - val_recall: 0.8640 - learning_rate: 1.0000e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 0.8113 - loss: 1.1597 - precision: 0.8969 - recall: 0.8299"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 329ms/step - accuracy: 0.8112 - loss: 1.1597 - precision: 0.8967 - recall: 0.8300 - val_accuracy: 0.8187 - val_loss: 1.2030 - val_precision: 0.8770 - val_recall: 0.8560 - learning_rate: 1.0000e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - accuracy: 0.7968 - loss: 1.1466 - precision: 0.8738 - recall: 0.8259"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 327ms/step - accuracy: 0.7970 - loss: 1.1465 - precision: 0.8738 - recall: 0.8261 - val_accuracy: 0.8352 - val_loss: 1.1779 - val_precision: 0.8862 - val_recall: 0.8720 - learning_rate: 1.0000e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 328ms/step - accuracy: 0.8159 - loss: 1.1206 - precision: 0.8804 - recall: 0.8473 - val_accuracy: 0.8352 - val_loss: 1.1826 - val_precision: 0.8862 - val_recall: 0.8720 - learning_rate: 1.0000e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.8142 - loss: 1.1403 - precision: 0.8764 - recall: 0.8486"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 331ms/step - accuracy: 0.8141 - loss: 1.1405 - precision: 0.8763 - recall: 0.8486 - val_accuracy: 0.8352 - val_loss: 1.1712 - val_precision: 0.8800 - val_recall: 0.8800 - learning_rate: 1.0000e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 327ms/step - accuracy: 0.7947 - loss: 1.1653 - precision: 0.8615 - recall: 0.8357 - val_accuracy: 0.8187 - val_loss: 1.1920 - val_precision: 0.8770 - val_recall: 0.8560 - learning_rate: 1.0000e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 321ms/step - accuracy: 0.8141 - loss: 1.1157 - precision: 0.8722 - recall: 0.8529 - val_accuracy: 0.8187 - val_loss: 1.1795 - val_precision: 0.8770 - val_recall: 0.8560 - learning_rate: 1.0000e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 329ms/step - accuracy: 0.7987 - loss: 1.1408 - precision: 0.8668 - recall: 0.8417 - val_accuracy: 0.8187 - val_loss: 1.1782 - val_precision: 0.8833 - val_recall: 0.8480 - learning_rate: 1.0000e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step - accuracy: 0.8168 - loss: 1.1238 - precision: 0.8886 - recall: 0.8447"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 335ms/step - accuracy: 0.8167 - loss: 1.1238 - precision: 0.8884 - recall: 0.8447 - val_accuracy: 0.8407 - val_loss: 1.1691 - val_precision: 0.8871 - val_recall: 0.8800 - learning_rate: 1.0000e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - accuracy: 0.8071 - loss: 1.1211 - precision: 0.8683 - recall: 0.8410"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 334ms/step - accuracy: 0.8071 - loss: 1.1211 - precision: 0.8684 - recall: 0.8409 - val_accuracy: 0.8352 - val_loss: 1.1594 - val_precision: 0.8862 - val_recall: 0.8720 - learning_rate: 1.0000e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 324ms/step - accuracy: 0.8162 - loss: 1.1130 - precision: 0.8744 - recall: 0.8486 - val_accuracy: 0.8187 - val_loss: 1.1664 - val_precision: 0.8833 - val_recall: 0.8480 - learning_rate: 1.0000e-04\n",
            "Epoch 42/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step - accuracy: 0.8314 - loss: 1.0707 - precision: 0.8810 - recall: 0.8766"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 334ms/step - accuracy: 0.8312 - loss: 1.0711 - precision: 0.8809 - recall: 0.8763 - val_accuracy: 0.8242 - val_loss: 1.1418 - val_precision: 0.8780 - val_recall: 0.8640 - learning_rate: 1.0000e-04\n",
            "Epoch 43/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.7955 - loss: 1.1050 - precision: 0.8637 - recall: 0.8393"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 330ms/step - accuracy: 0.7958 - loss: 1.1047 - precision: 0.8639 - recall: 0.8396 - val_accuracy: 0.8352 - val_loss: 1.1354 - val_precision: 0.8800 - val_recall: 0.8800 - learning_rate: 1.0000e-04\n",
            "Epoch 44/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 332ms/step - accuracy: 0.7992 - loss: 1.1008 - precision: 0.8608 - recall: 0.8401 - val_accuracy: 0.8462 - val_loss: 1.1436 - val_precision: 0.8880 - val_recall: 0.8880 - learning_rate: 1.0000e-04\n",
            "Epoch 45/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 326ms/step - accuracy: 0.7965 - loss: 1.1285 - precision: 0.8572 - recall: 0.8422 - val_accuracy: 0.8462 - val_loss: 1.1388 - val_precision: 0.8760 - val_recall: 0.9040 - learning_rate: 1.0000e-04\n",
            "Epoch 46/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 331ms/step - accuracy: 0.8033 - loss: 1.0930 - precision: 0.8483 - recall: 0.8599 - val_accuracy: 0.8187 - val_loss: 1.1671 - val_precision: 0.8770 - val_recall: 0.8560 - learning_rate: 1.0000e-04\n",
            "Epoch 47/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 330ms/step - accuracy: 0.8485 - loss: 1.0433 - precision: 0.8914 - recall: 0.8855 - val_accuracy: 0.8187 - val_loss: 1.1618 - val_precision: 0.8710 - val_recall: 0.8640 - learning_rate: 1.0000e-04\n",
            "Epoch 48/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 331ms/step - accuracy: 0.8103 - loss: 1.0767 - precision: 0.8693 - recall: 0.8484 - val_accuracy: 0.8187 - val_loss: 1.1569 - val_precision: 0.8770 - val_recall: 0.8560 - learning_rate: 1.0000e-04\n",
            "Epoch 49/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - accuracy: 0.8406 - loss: 1.0524 - precision: 0.8967 - recall: 0.8666"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 330ms/step - accuracy: 0.8405 - loss: 1.0526 - precision: 0.8966 - recall: 0.8665 - val_accuracy: 0.8516 - val_loss: 1.1342 - val_precision: 0.8769 - val_recall: 0.9120 - learning_rate: 1.0000e-04\n",
            "Epoch 50/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310ms/step - accuracy: 0.8263 - loss: 1.0515 - precision: 0.8814 - recall: 0.8674"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 332ms/step - accuracy: 0.8264 - loss: 1.0516 - precision: 0.8814 - recall: 0.8675 - val_accuracy: 0.8462 - val_loss: 1.1318 - val_precision: 0.8819 - val_recall: 0.8960 - learning_rate: 1.0000e-04\n",
            "\n",
            "[Training Phase 2: Fine-tuning]\n",
            "================================================================================\n",
            "Epoch 1/30\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step - accuracy: 0.8297 - loss: 1.0357 - precision: 0.8831 - recall: 0.8637"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 440ms/step - accuracy: 0.8296 - loss: 1.0359 - precision: 0.8830 - recall: 0.8637 - val_accuracy: 0.8462 - val_loss: 1.0750 - val_precision: 0.8255 - val_recall: 0.9840 - learning_rate: 1.0000e-05\n",
            "Epoch 2/30\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 393ms/step - accuracy: 0.8144 - loss: 1.0651 - precision: 0.8672 - recall: 0.8579 - val_accuracy: 0.8571 - val_loss: 1.0777 - val_precision: 0.8462 - val_recall: 0.9680 - learning_rate: 1.0000e-05\n",
            "Epoch 3/30\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - accuracy: 0.8367 - loss: 1.0373 - precision: 0.8884 - recall: 0.8718"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 405ms/step - accuracy: 0.8366 - loss: 1.0373 - precision: 0.8884 - recall: 0.8718 - val_accuracy: 0.8681 - val_loss: 0.9835 - val_precision: 0.8686 - val_recall: 0.9520 - learning_rate: 1.0000e-05\n",
            "Epoch 4/30\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 392ms/step - accuracy: 0.8184 - loss: 1.0645 - precision: 0.8761 - recall: 0.8538 - val_accuracy: 0.7747 - val_loss: 1.2923 - val_precision: 0.9038 - val_recall: 0.7520 - learning_rate: 1.0000e-05\n",
            "Epoch 5/30\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 402ms/step - accuracy: 0.8379 - loss: 1.0125 - precision: 0.8829 - recall: 0.8795 - val_accuracy: 0.8736 - val_loss: 0.9991 - val_precision: 0.8806 - val_recall: 0.9440 - learning_rate: 1.0000e-05\n",
            "Epoch 6/30\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 390ms/step - accuracy: 0.8644 - loss: 0.9834 - precision: 0.9104 - recall: 0.8886 - val_accuracy: 0.8681 - val_loss: 1.0186 - val_precision: 0.8976 - val_recall: 0.9120 - learning_rate: 1.0000e-05\n",
            "Epoch 7/30\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - accuracy: 0.8769 - loss: 0.9748 - precision: 0.9129 - recall: 0.9097"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 403ms/step - accuracy: 0.8768 - loss: 0.9749 - precision: 0.9128 - recall: 0.9097 - val_accuracy: 0.8736 - val_loss: 0.9464 - val_precision: 0.8643 - val_recall: 0.9680 - learning_rate: 1.0000e-05\n",
            "Epoch 8/30\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 392ms/step - accuracy: 0.8803 - loss: 0.9318 - precision: 0.9235 - recall: 0.9045 - val_accuracy: 0.8846 - val_loss: 1.0336 - val_precision: 0.9127 - val_recall: 0.9200 - learning_rate: 1.0000e-05\n",
            "Epoch 9/30\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 399ms/step - accuracy: 0.8762 - loss: 0.9426 - precision: 0.9222 - recall: 0.8976 - val_accuracy: 0.7802 - val_loss: 1.1738 - val_precision: 0.9293 - val_recall: 0.7360 - learning_rate: 1.0000e-05\n",
            "Epoch 10/30\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 393ms/step - accuracy: 0.8608 - loss: 0.9774 - precision: 0.9002 - recall: 0.8973 - val_accuracy: 0.8901 - val_loss: 1.0322 - val_precision: 0.9339 - val_recall: 0.9040 - learning_rate: 1.0000e-05\n",
            "Epoch 11/30\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 405ms/step - accuracy: 0.8603 - loss: 0.9354 - precision: 0.9247 - recall: 0.8777 - val_accuracy: 0.8846 - val_loss: 0.9824 - val_precision: 0.8939 - val_recall: 0.9440 - learning_rate: 1.0000e-05\n",
            "Epoch 12/30\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 397ms/step - accuracy: 0.8826 - loss: 0.9036 - precision: 0.9273 - recall: 0.9003 - val_accuracy: 0.8571 - val_loss: 1.0149 - val_precision: 0.8722 - val_recall: 0.9280 - learning_rate: 1.0000e-05\n",
            "Epoch 13/30\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 400ms/step - accuracy: 0.8789 - loss: 0.9303 - precision: 0.9246 - recall: 0.8959 - val_accuracy: 0.8462 - val_loss: 1.1714 - val_precision: 0.9533 - val_recall: 0.8160 - learning_rate: 1.0000e-05\n",
            "Epoch 14/30\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 410ms/step - accuracy: 0.8949 - loss: 0.8828 - precision: 0.9290 - recall: 0.9176 - val_accuracy: 0.8901 - val_loss: 0.9919 - val_precision: 0.9412 - val_recall: 0.8960 - learning_rate: 1.0000e-05\n",
            "Epoch 15/30\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.8810 - loss: 0.9106 - precision: 0.9243 - recall: 0.9046"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 406ms/step - accuracy: 0.8810 - loss: 0.9106 - precision: 0.9242 - recall: 0.9046 - val_accuracy: 0.8956 - val_loss: 0.9046 - val_precision: 0.8955 - val_recall: 0.9600 - learning_rate: 5.0000e-06\n",
            "Epoch 16/30\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 401ms/step - accuracy: 0.8819 - loss: 0.8901 - precision: 0.9311 - recall: 0.8970 - val_accuracy: 0.8516 - val_loss: 1.0094 - val_precision: 0.9455 - val_recall: 0.8320 - learning_rate: 5.0000e-06\n",
            "Epoch 17/30\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 396ms/step - accuracy: 0.8755 - loss: 0.9097 - precision: 0.9377 - recall: 0.8835 - val_accuracy: 0.9066 - val_loss: 0.9079 - val_precision: 0.9219 - val_recall: 0.9440 - learning_rate: 5.0000e-06\n",
            "Epoch 18/30\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 400ms/step - accuracy: 0.8940 - loss: 0.8574 - precision: 0.9520 - recall: 0.8930 - val_accuracy: 0.9231 - val_loss: 0.9394 - val_precision: 0.9370 - val_recall: 0.9520 - learning_rate: 5.0000e-06\n",
            "Epoch 19/30\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 406ms/step - accuracy: 0.9007 - loss: 0.8828 - precision: 0.9310 - recall: 0.9200 - val_accuracy: 0.9176 - val_loss: 0.9141 - val_precision: 0.9231 - val_recall: 0.9600 - learning_rate: 5.0000e-06\n",
            "Epoch 20/30\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 394ms/step - accuracy: 0.8912 - loss: 0.8801 - precision: 0.9375 - recall: 0.9043 - val_accuracy: 0.8956 - val_loss: 0.9129 - val_precision: 0.8841 - val_recall: 0.9760 - learning_rate: 5.0000e-06\n",
            "Epoch 21/30\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 407ms/step - accuracy: 0.9037 - loss: 0.8634 - precision: 0.9475 - recall: 0.9132 - val_accuracy: 0.9176 - val_loss: 0.9591 - val_precision: 0.9583 - val_recall: 0.9200 - learning_rate: 5.0000e-06\n",
            "Epoch 22/30\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 398ms/step - accuracy: 0.9103 - loss: 0.8499 - precision: 0.9593 - recall: 0.9113 - val_accuracy: 0.9066 - val_loss: 0.9082 - val_precision: 0.9219 - val_recall: 0.9440 - learning_rate: 5.0000e-06\n",
            "Epoch 23/30\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - accuracy: 0.8959 - loss: 0.8738 - precision: 0.9350 - recall: 0.9155"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 410ms/step - accuracy: 0.8959 - loss: 0.8738 - precision: 0.9350 - recall: 0.9155 - val_accuracy: 0.9066 - val_loss: 0.8992 - val_precision: 0.9154 - val_recall: 0.9520 - learning_rate: 2.5000e-06\n",
            "Epoch 24/30\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 402ms/step - accuracy: 0.8924 - loss: 0.8675 - precision: 0.9369 - recall: 0.9032 - val_accuracy: 0.9231 - val_loss: 0.9419 - val_precision: 0.9440 - val_recall: 0.9440 - learning_rate: 2.5000e-06\n",
            "Epoch 25/30\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 400ms/step - accuracy: 0.9142 - loss: 0.8338 - precision: 0.9631 - recall: 0.9114 - val_accuracy: 0.9286 - val_loss: 0.9152 - val_precision: 0.9444 - val_recall: 0.9520 - learning_rate: 2.5000e-06\n",
            "Epoch 26/30\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 399ms/step - accuracy: 0.9067 - loss: 0.8572 - precision: 0.9438 - recall: 0.9196 - val_accuracy: 0.9121 - val_loss: 0.9707 - val_precision: 0.9504 - val_recall: 0.9200 - learning_rate: 2.5000e-06\n",
            "Epoch 27/30\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 409ms/step - accuracy: 0.8871 - loss: 0.8774 - precision: 0.9249 - recall: 0.9050 - val_accuracy: 0.9231 - val_loss: 0.9425 - val_precision: 0.9512 - val_recall: 0.9360 - learning_rate: 2.5000e-06\n",
            "Epoch 28/30\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 396ms/step - accuracy: 0.9176 - loss: 0.8497 - precision: 0.9474 - recall: 0.9298 - val_accuracy: 0.9341 - val_loss: 0.9032 - val_precision: 0.9520 - val_recall: 0.9520 - learning_rate: 2.5000e-06\n",
            "Epoch 29/30\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 390ms/step - accuracy: 0.8901 - loss: 0.8681 - precision: 0.9360 - recall: 0.9010 - val_accuracy: 0.8901 - val_loss: 0.9360 - val_precision: 0.9565 - val_recall: 0.8800 - learning_rate: 2.5000e-06\n",
            "Epoch 30/30\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 400ms/step - accuracy: 0.9132 - loss: 0.8438 - precision: 0.9519 - recall: 0.9219 - val_accuracy: 0.8462 - val_loss: 0.9703 - val_precision: 0.9533 - val_recall: 0.8160 - learning_rate: 2.5000e-06\n",
            "\n",
            "================================================================================\n",
            "EVALUATION BY DATASET\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "SIPAKMED TEST SET\n",
            "================================================================================\n",
            "Found 194 validated image filenames belonging to 2 classes.\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Normal       0.89      0.85      0.87        80\n",
            "    Abnormal       0.90      0.93      0.91       114\n",
            "\n",
            "    accuracy                           0.90       194\n",
            "   macro avg       0.90      0.89      0.89       194\n",
            "weighted avg       0.90      0.90      0.90       194\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 68  12]\n",
            " [  8 106]]\n",
            "\n",
            "Key Metrics:\n",
            "  Accuracy:    89.69%\n",
            "  Sensitivity: 92.98%\n",
            "  Specificity: 85.00%\n",
            "  Missed Cancers: 8\n",
            "  ROC-AUC: 0.9586\n",
            "\n",
            "================================================================================\n",
            "HERLEV TEST SET\n",
            "================================================================================\n",
            "Found 169 validated image filenames belonging to 2 classes.\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Normal       0.89      0.50      0.64        34\n",
            "    Abnormal       0.89      0.99      0.93       135\n",
            "\n",
            "    accuracy                           0.89       169\n",
            "   macro avg       0.89      0.74      0.79       169\n",
            "weighted avg       0.89      0.89      0.87       169\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 17  17]\n",
            " [  2 133]]\n",
            "\n",
            "Key Metrics:\n",
            "  Accuracy:    88.76%\n",
            "  Sensitivity: 98.52%\n",
            "  Specificity: 50.00%\n",
            "  Missed Cancers: 2\n",
            "  ROC-AUC: 0.9532\n",
            "\n",
            "================================================================================\n",
            "✅ TRAINING COMPLETE!\n",
            "================================================================================\n",
            "\n",
            "📊 Results Summary:\n",
            "\n",
            "SIPAKMED:\n",
            "  Accuracy: 89.69%\n",
            "  Sensitivity: 92.98%\n",
            "  Specificity: 85.00%\n",
            "  Missed Cancers: 8\n",
            "\n",
            "HERLEV:\n",
            "  Accuracy: 88.76%\n",
            "  Sensitivity: 98.52%\n",
            "  Specificity: 50.00%\n",
            "  Missed Cancers: 2\n",
            "\n",
            "💾 Model saved to: final_model_combined.h5\n",
            "🎯 This model now works on BOTH SIPaKMeD and Herlev!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Threshold Optimization for Herlev Dataset\n",
        "Find optimal threshold to balance sensitivity and specificity\n",
        "\n",
        "Current Issue:\n",
        "- Using threshold 0.5\n",
        "- Herlev: 98.5% sensitivity but only 50% specificity\n",
        "- Too many false positives (17/34 normals flagged as abnormal)\n",
        "\n",
        "Solution:\n",
        "- Find dataset-specific threshold that balances both metrics\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ============================================================================\n",
        "# CONFIGURATION\n",
        "# ============================================================================\n",
        "\n",
        "class ThresholdConfig:\n",
        "    MODEL_PATH = 'final_model_combined.h5'\n",
        "    TEST_CSV = 'combined_dataset.csv'  # Your combined dataset\n",
        "    IMG_SIZE = 224\n",
        "    BATCH_SIZE = 16\n",
        "\n",
        "    # For clinical screening, choose your priority:\n",
        "    TARGET_SENSITIVITY = 0.95  # Catch at least 95% of cancers\n",
        "    # OR\n",
        "    TARGET_SPECIFICITY = 0.80  # Correctly ID at least 80% of normals\n",
        "\n",
        "config = ThresholdConfig()\n",
        "\n",
        "# ============================================================================\n",
        "# LOAD MODEL AND DATA\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"THRESHOLD OPTIMIZATION FOR HERLEV DATASET\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Load model\n",
        "print(\"\\n[1] Loading model...\")\n",
        "model = load_model(config.MODEL_PATH)\n",
        "print(f\"✅ Model loaded: {config.MODEL_PATH}\")\n",
        "\n",
        "# Load test data\n",
        "print(\"\\n[2] Loading test data...\")\n",
        "df = pd.read_csv(config.TEST_CSV)\n",
        "\n",
        "# Get Herlev test set (you'll need to identify which samples were in test)\n",
        "# For now, we'll use all Herlev data for threshold optimization\n",
        "herlev_df = df[df['dataset_source'] == 'herlev'].copy()\n",
        "print(f\"✅ Herlev samples: {len(herlev_df)}\")\n",
        "print(f\"   Normal: {len(herlev_df[herlev_df['label']==0])}\")\n",
        "print(f\"   Abnormal: {len(herlev_df[herlev_df['label']==1])}\")\n",
        "\n",
        "# ============================================================================\n",
        "# GET PREDICTIONS\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n[3] Getting predictions...\")\n",
        "\n",
        "herlev_df['label_str'] = herlev_df['label'].astype(str)\n",
        "\n",
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "generator = datagen.flow_from_dataframe(\n",
        "    herlev_df,\n",
        "    x_col='image_path',\n",
        "    y_col='label_str',\n",
        "    target_size=(config.IMG_SIZE, config.IMG_SIZE),\n",
        "    batch_size=config.BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "y_pred_proba = model.predict(generator, verbose=1).flatten()\n",
        "y_true = herlev_df['label'].values\n",
        "\n",
        "print(f\"✅ Predictions obtained\")\n",
        "print(f\"   Score range: {y_pred_proba.min():.3f} to {y_pred_proba.max():.3f}\")\n",
        "print(f\"   Mean score: {y_pred_proba.mean():.3f}\")\n",
        "\n",
        "# ============================================================================\n",
        "# THRESHOLD ANALYSIS\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n[4] Analyzing thresholds...\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "thresholds = np.arange(0.1, 0.95, 0.05)\n",
        "results = []\n",
        "\n",
        "for threshold in thresholds:\n",
        "    y_pred = (y_pred_proba >= threshold).astype(int)\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "\n",
        "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "    f1 = 2 * (precision * sensitivity) / (precision + sensitivity) if (precision + sensitivity) > 0 else 0\n",
        "\n",
        "    # Balance score (harmonic mean of sensitivity and specificity)\n",
        "    balance = 2 * (sensitivity * specificity) / (sensitivity + specificity) if (sensitivity + specificity) > 0 else 0\n",
        "\n",
        "    results.append({\n",
        "        'threshold': threshold,\n",
        "        'accuracy': accuracy,\n",
        "        'sensitivity': sensitivity,\n",
        "        'specificity': specificity,\n",
        "        'precision': precision,\n",
        "        'f1': f1,\n",
        "        'balance': balance,\n",
        "        'tp': tp, 'tn': tn, 'fp': fp, 'fn': fn\n",
        "    })\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# ============================================================================\n",
        "# FIND OPTIMAL THRESHOLDS\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"OPTIMAL THRESHOLDS FOR DIFFERENT SCENARIOS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Scenario 1: Best Balance (harmonic mean of sensitivity and specificity)\n",
        "best_balance_idx = results_df['balance'].idxmax()\n",
        "best_balance = results_df.iloc[best_balance_idx]\n",
        "\n",
        "print(f\"\\n1️⃣  BEST BALANCE (Recommended for general screening)\")\n",
        "print(f\"   Threshold: {best_balance['threshold']:.2f}\")\n",
        "print(f\"   Accuracy: {best_balance['accuracy']*100:.1f}%\")\n",
        "print(f\"   Sensitivity: {best_balance['sensitivity']*100:.1f}%\")\n",
        "print(f\"   Specificity: {best_balance['specificity']*100:.1f}%\")\n",
        "print(f\"   Missed Cancers: {int(best_balance['fn'])}\")\n",
        "print(f\"   False Alarms: {int(best_balance['fp'])}\")\n",
        "\n",
        "# Scenario 2: High Sensitivity (minimize missed cancers)\n",
        "high_sens = results_df[results_df['sensitivity'] >= config.TARGET_SENSITIVITY]\n",
        "if len(high_sens) > 0:\n",
        "    best_high_sens = high_sens.iloc[high_sens['specificity'].idxmax()]\n",
        "    print(f\"\\n2️⃣  HIGH SENSITIVITY (Screening mode - catch most cancers)\")\n",
        "    print(f\"   Threshold: {best_high_sens['threshold']:.2f}\")\n",
        "    print(f\"   Accuracy: {best_high_sens['accuracy']*100:.1f}%\")\n",
        "    print(f\"   Sensitivity: {best_high_sens['sensitivity']*100:.1f}%\")\n",
        "    print(f\"   Specificity: {best_high_sens['specificity']*100:.1f}%\")\n",
        "    print(f\"   Missed Cancers: {int(best_high_sens['fn'])} ✅ Low!\")\n",
        "    print(f\"   False Alarms: {int(best_high_sens['fp'])}\")\n",
        "\n",
        "# Scenario 3: High Specificity (minimize false alarms)\n",
        "high_spec = results_df[results_df['specificity'] >= config.TARGET_SPECIFICITY]\n",
        "if len(high_spec) > 0:\n",
        "    best_high_spec = high_spec.iloc[high_spec['sensitivity'].idxmax()]\n",
        "    print(f\"\\n3️⃣  HIGH SPECIFICITY (Confirmation mode - reduce false alarms)\")\n",
        "    print(f\"   Threshold: {best_high_spec['threshold']:.2f}\")\n",
        "    print(f\"   Accuracy: {best_high_spec['accuracy']*100:.1f}%\")\n",
        "    print(f\"   Sensitivity: {best_high_spec['sensitivity']*100:.1f}%\")\n",
        "    print(f\"   Specificity: {best_high_spec['specificity']*100:.1f}%\")\n",
        "    print(f\"   Missed Cancers: {int(best_high_spec['fn'])}\")\n",
        "    print(f\"   False Alarms: {int(best_high_spec['fp'])} ✅ Low!\")\n",
        "\n",
        "# Scenario 4: Current threshold (0.5)\n",
        "current = results_df[results_df['threshold'] == 0.5].iloc[0]\n",
        "print(f\"\\n4️⃣  CURRENT THRESHOLD (0.50) - For comparison\")\n",
        "print(f\"   Accuracy: {current['accuracy']*100:.1f}%\")\n",
        "print(f\"   Sensitivity: {current['sensitivity']*100:.1f}%\")\n",
        "print(f\"   Specificity: {current['specificity']*100:.1f}% ❌ Too low!\")\n",
        "print(f\"   Missed Cancers: {int(current['fn'])}\")\n",
        "print(f\"   False Alarms: {int(current['fp'])} ⚠️  Too high!\")\n",
        "\n",
        "# ============================================================================\n",
        "# VISUALIZATION\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n[5] Creating visualizations...\")\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "\n",
        "# Plot 1: Sensitivity vs Threshold\n",
        "axes[0, 0].plot(results_df['threshold'], results_df['sensitivity'], 'b-', linewidth=2)\n",
        "axes[0, 0].axhline(y=0.95, color='r', linestyle='--', alpha=0.5, label='Target (95%)')\n",
        "axes[0, 0].axvline(x=best_balance['threshold'], color='g', linestyle='--', alpha=0.5, label='Optimal')\n",
        "axes[0, 0].set_xlabel('Threshold')\n",
        "axes[0, 0].set_ylabel('Sensitivity (Recall)')\n",
        "axes[0, 0].set_title('Sensitivity vs Threshold')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(alpha=0.3)\n",
        "\n",
        "# Plot 2: Specificity vs Threshold\n",
        "axes[0, 1].plot(results_df['threshold'], results_df['specificity'], 'r-', linewidth=2)\n",
        "axes[0, 1].axhline(y=0.80, color='b', linestyle='--', alpha=0.5, label='Target (80%)')\n",
        "axes[0, 1].axvline(x=best_balance['threshold'], color='g', linestyle='--', alpha=0.5, label='Optimal')\n",
        "axes[0, 1].set_xlabel('Threshold')\n",
        "axes[0, 1].set_ylabel('Specificity')\n",
        "axes[0, 1].set_title('Specificity vs Threshold')\n",
        "axes[0, 1].legend()\n",
        "axes[0, 1].grid(alpha=0.3)\n",
        "\n",
        "# Plot 3: Both on same plot\n",
        "axes[0, 2].plot(results_df['threshold'], results_df['sensitivity'], 'b-', linewidth=2, label='Sensitivity')\n",
        "axes[0, 2].plot(results_df['threshold'], results_df['specificity'], 'r-', linewidth=2, label='Specificity')\n",
        "axes[0, 2].axvline(x=best_balance['threshold'], color='g', linestyle='--', alpha=0.5, label=f\"Optimal ({best_balance['threshold']:.2f})\")\n",
        "axes[0, 2].axvline(x=0.5, color='orange', linestyle='--', alpha=0.5, label='Current (0.50)')\n",
        "axes[0, 2].set_xlabel('Threshold')\n",
        "axes[0, 2].set_ylabel('Score')\n",
        "axes[0, 2].set_title('Sensitivity & Specificity vs Threshold')\n",
        "axes[0, 2].legend()\n",
        "axes[0, 2].grid(alpha=0.3)\n",
        "\n",
        "# Plot 4: F1 Score\n",
        "axes[1, 0].plot(results_df['threshold'], results_df['f1'], 'purple', linewidth=2)\n",
        "axes[1, 0].axvline(x=results_df.loc[results_df['f1'].idxmax(), 'threshold'],\n",
        "                   color='g', linestyle='--', label='Best F1')\n",
        "axes[1, 0].set_xlabel('Threshold')\n",
        "axes[1, 0].set_ylabel('F1 Score')\n",
        "axes[1, 0].set_title('F1 Score vs Threshold')\n",
        "axes[1, 0].legend()\n",
        "axes[1, 0].grid(alpha=0.3)\n",
        "\n",
        "# Plot 5: Missed Cancers (False Negatives)\n",
        "axes[1, 1].plot(results_df['threshold'], results_df['fn'], 'darkred', linewidth=2)\n",
        "axes[1, 1].axhline(y=0, color='g', linestyle='--', alpha=0.5, label='Zero missed')\n",
        "axes[1, 1].axvline(x=best_balance['threshold'], color='g', linestyle='--', alpha=0.5)\n",
        "axes[1, 1].set_xlabel('Threshold')\n",
        "axes[1, 1].set_ylabel('Missed Cancers (FN)')\n",
        "axes[1, 1].set_title('Missed Cancers vs Threshold')\n",
        "axes[1, 1].legend()\n",
        "axes[1, 1].grid(alpha=0.3)\n",
        "\n",
        "# Plot 6: False Alarms (False Positives)\n",
        "axes[1, 2].plot(results_df['threshold'], results_df['fp'], 'darkorange', linewidth=2)\n",
        "axes[1, 2].axhline(y=0, color='g', linestyle='--', alpha=0.5, label='Zero false alarms')\n",
        "axes[1, 2].axvline(x=best_balance['threshold'], color='g', linestyle='--', alpha=0.5)\n",
        "axes[1, 2].set_xlabel('Threshold')\n",
        "axes[1, 2].set_ylabel('False Alarms (FP)')\n",
        "axes[1, 2].set_title('False Alarms vs Threshold')\n",
        "axes[1, 2].legend()\n",
        "axes[1, 2].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('herlev_threshold_optimization.png', dpi=150, bbox_inches='tight')\n",
        "print(f\"✅ Saved: herlev_threshold_optimization.png\")\n",
        "plt.close()\n",
        "\n",
        "# ROC Curve\n",
        "fpr, tpr, roc_thresholds = roc_curve(y_true, y_pred_proba)\n",
        "roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.plot(fpr, tpr, 'b-', linewidth=2, label=f'ROC (AUC = {roc_auc:.3f})')\n",
        "plt.plot([0, 1], [0, 1], 'r--', linewidth=2, label='Random')\n",
        "\n",
        "# Mark optimal point\n",
        "optimal_idx = np.argmax(tpr - fpr)\n",
        "optimal_threshold = roc_thresholds[optimal_idx]\n",
        "plt.plot(fpr[optimal_idx], tpr[optimal_idx], 'go', markersize=15,\n",
        "         label=f'Optimal (threshold={optimal_threshold:.2f})')\n",
        "\n",
        "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
        "plt.ylabel('True Positive Rate (Sensitivity)')\n",
        "plt.title('ROC Curve - Herlev Dataset')\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "plt.savefig('herlev_roc_curve.png', dpi=150, bbox_inches='tight')\n",
        "print(f\"✅ Saved: herlev_roc_curve.png\")\n",
        "plt.close()\n",
        "\n",
        "# ============================================================================\n",
        "# SAVE RESULTS\n",
        "# ============================================================================\n",
        "\n",
        "results_df.to_csv('herlev_threshold_analysis.csv', index=False)\n",
        "print(f\"✅ Saved: herlev_threshold_analysis.csv\")\n",
        "\n",
        "# Save recommendations\n",
        "recommendations = {\n",
        "    'best_balance': {\n",
        "        'threshold': float(best_balance['threshold']),\n",
        "        'sensitivity': float(best_balance['sensitivity']),\n",
        "        'specificity': float(best_balance['specificity']),\n",
        "        'accuracy': float(best_balance['accuracy']),\n",
        "        'use_case': 'General screening - balanced approach'\n",
        "    }\n",
        "}\n",
        "\n",
        "if len(high_sens) > 0:\n",
        "    recommendations['high_sensitivity'] = {\n",
        "        'threshold': float(best_high_sens['threshold']),\n",
        "        'sensitivity': float(best_high_sens['sensitivity']),\n",
        "        'specificity': float(best_high_sens['specificity']),\n",
        "        'accuracy': float(best_high_sens['accuracy']),\n",
        "        'use_case': 'Screening - minimize missed cancers'\n",
        "    }\n",
        "\n",
        "if len(high_spec) > 0:\n",
        "    recommendations['high_specificity'] = {\n",
        "        'threshold': float(best_high_spec['threshold']),\n",
        "        'sensitivity': float(best_high_spec['sensitivity']),\n",
        "        'specificity': float(best_high_spec['specificity']),\n",
        "        'accuracy': float(best_high_spec['accuracy']),\n",
        "        'use_case': 'Confirmation - reduce false alarms'\n",
        "    }\n",
        "\n",
        "import json\n",
        "with open('herlev_threshold_recommendations.json', 'w') as f:\n",
        "    json.dump(recommendations, f, indent=4)\n",
        "\n",
        "print(f\"✅ Saved: herlev_threshold_recommendations.json\")\n",
        "\n",
        "# ============================================================================\n",
        "# SUMMARY AND RECOMMENDATIONS\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"RECOMMENDATIONS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\n✅ OPTIMAL THRESHOLD FOR HERLEV: {best_balance['threshold']:.2f}\")\n",
        "print(f\"\\n   This will give you:\")\n",
        "print(f\"   - Sensitivity: {best_balance['sensitivity']*100:.1f}%\")\n",
        "print(f\"   - Specificity: {best_balance['specificity']*100:.1f}%\")\n",
        "print(f\"   - Much better balance than current 0.50 threshold!\")\n",
        "\n",
        "print(f\"\\n📝 HOW TO USE:\")\n",
        "print(f\"   1. In your inference script, update:\")\n",
        "print(f\"      HERLEV_THRESHOLD = {best_balance['threshold']:.2f}\")\n",
        "print(f\"   \")\n",
        "print(f\"   2. Use dataset-specific thresholds:\")\n",
        "print(f\"      if dataset == 'sipakmed':\")\n",
        "print(f\"          threshold = 0.50  # Works well\")\n",
        "print(f\"      elif dataset == 'herlev':\")\n",
        "print(f\"          threshold = {best_balance['threshold']:.2f}  # Optimized\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WpXGcXuhs9A8",
        "outputId": "5cab63dd-4db2-4ff5-ae2a-79036a91a60c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "THRESHOLD OPTIMIZATION FOR HERLEV DATASET\n",
            "================================================================================\n",
            "\n",
            "[1] Loading model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model loaded: final_model_combined.h5\n",
            "\n",
            "[2] Loading test data...\n",
            "✅ Herlev samples: 843\n",
            "   Normal: 168\n",
            "   Abnormal: 675\n",
            "\n",
            "[3] Getting predictions...\n",
            "Found 843 validated image filenames belonging to 2 classes.\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 191ms/step\n",
            "✅ Predictions obtained\n",
            "   Score range: 0.000 to 0.999\n",
            "   Mean score: 0.717\n",
            "\n",
            "[4] Analyzing thresholds...\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "OPTIMAL THRESHOLDS FOR DIFFERENT SCENARIOS\n",
            "================================================================================\n",
            "\n",
            "1️⃣  BEST BALANCE (Recommended for general screening)\n",
            "   Threshold: 0.60\n",
            "   Accuracy: 89.2%\n",
            "   Sensitivity: 90.1%\n",
            "   Specificity: 85.7%\n",
            "   Missed Cancers: 67\n",
            "   False Alarms: 24\n",
            "\n",
            "2️⃣  HIGH SENSITIVITY (Screening mode - catch most cancers)\n",
            "   Threshold: 0.55\n",
            "   Accuracy: 90.9%\n",
            "   Sensitivity: 95.1%\n",
            "   Specificity: 73.8%\n",
            "   Missed Cancers: 33 ✅ Low!\n",
            "   False Alarms: 44\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "single positional indexer is out-of-bounds",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1803160715.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0mhigh_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresults_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'specificity'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTARGET_SPECIFICITY\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhigh_spec\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m     \u001b[0mbest_high_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhigh_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhigh_spec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sensitivity'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midxmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n3️⃣  HIGH SPECIFICITY (Confirmation mode - reduce false alarms)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"   Threshold: {best_high_spec['threshold']:.2f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1189\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_deprecated_callable_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaybe_callable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1751\u001b[0m             \u001b[0;31m# validate the location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1752\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1754\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1683\u001b[0m         \u001b[0mlen_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen_axis\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlen_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m     \u001b[0;31m# -------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Adaptive Inference with Dataset-Specific Thresholds\n",
        "Automatically adjusts threshold based on image characteristics\n",
        "\n",
        "Solution to Herlev's 50% specificity problem\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ============================================================================\n",
        "# CONFIGURATION WITH DATASET-SPECIFIC THRESHOLDS\n",
        "# ============================================================================\n",
        "\n",
        "class AdaptiveInferenceConfig:\n",
        "    # Model\n",
        "    MODEL_PATH = 'final_model_combined.h5'\n",
        "    IMG_SIZE = 224\n",
        "\n",
        "    # Dataset-specific thresholds (optimize these!)\n",
        "    THRESHOLDS = {\n",
        "        'sipakmed': 0.50,  # Default works well for SIPaKMeD\n",
        "        'herlev': 0.65,    # Higher threshold for Herlev (reduces false positives)\n",
        "        'unknown': 0.55    # Middle ground for unknown datasets\n",
        "    }\n",
        "\n",
        "    # Auto-detection based on image characteristics\n",
        "    AUTO_DETECT = True\n",
        "\n",
        "    # Risk levels\n",
        "    RISK_LEVELS = {\n",
        "        'very_low': 0.3,\n",
        "        'low': 0.5,\n",
        "        'moderate': 0.7,\n",
        "        'high': 0.85\n",
        "    }\n",
        "\n",
        "config = AdaptiveInferenceConfig()\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"ADAPTIVE INFERENCE SYSTEM\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Model: {config.MODEL_PATH}\")\n",
        "print(f\"Thresholds:\")\n",
        "print(f\"  SIPaKMeD: {config.THRESHOLDS['sipakmed']}\")\n",
        "print(f\"  Herlev: {config.THRESHOLDS['herlev']}\")\n",
        "print(f\"  Auto-detect: {config.AUTO_DETECT}\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ============================================================================\n",
        "# LOAD MODEL\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n[1] Loading model...\")\n",
        "try:\n",
        "    model = load_model(config.MODEL_PATH)\n",
        "    print(f\"✅ Model loaded\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error: {e}\")\n",
        "    exit(1)\n",
        "\n",
        "# ============================================================================\n",
        "# DATASET AUTO-DETECTION\n",
        "# ============================================================================\n",
        "\n",
        "def detect_dataset_type(image_path):\n",
        "    \"\"\"\n",
        "    Auto-detect if image is likely from SIPaKMeD or Herlev\n",
        "    based on image characteristics\n",
        "    \"\"\"\n",
        "    try:\n",
        "        img = cv2.imread(image_path)\n",
        "        if img is None:\n",
        "            return 'unknown'\n",
        "\n",
        "        # Convert to HSV for color analysis\n",
        "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "        # Analyze color characteristics\n",
        "        h_mean = np.mean(hsv[:,:,0])\n",
        "        s_mean = np.mean(hsv[:,:,1])\n",
        "        v_mean = np.mean(hsv[:,:,2])\n",
        "\n",
        "        # Simple heuristic (you can improve this based on your data)\n",
        "        # SIPaKMeD tends to have different staining characteristics than Herlev\n",
        "\n",
        "        # Check if path contains dataset name\n",
        "        path_lower = image_path.lower()\n",
        "        if 'sipakmed' in path_lower or 'im_' in path_lower:\n",
        "            return 'sipakmed'\n",
        "        elif 'herlev' in path_lower:\n",
        "            return 'herlev'\n",
        "\n",
        "        # Fallback to image analysis\n",
        "        # These thresholds should be calibrated on your actual data\n",
        "        if s_mean > 100 and v_mean > 150:\n",
        "            return 'sipakmed'  # Typically more saturated\n",
        "        elif s_mean < 80:\n",
        "            return 'herlev'    # Typically less saturated\n",
        "\n",
        "        return 'unknown'\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️  Detection error: {e}\")\n",
        "        return 'unknown'\n",
        "\n",
        "# ============================================================================\n",
        "# PREDICTION WITH ADAPTIVE THRESHOLD\n",
        "# ============================================================================\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    \"\"\"Preprocess image\"\"\"\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is None:\n",
        "        return None\n",
        "\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = cv2.resize(img, (config.IMG_SIZE, config.IMG_SIZE))\n",
        "    img = img / 255.0\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "\n",
        "    return img\n",
        "\n",
        "def predict_adaptive(image_path, dataset_type=None, manual_threshold=None):\n",
        "    \"\"\"\n",
        "    Predict with adaptive threshold\n",
        "\n",
        "    Args:\n",
        "        image_path: Path to image\n",
        "        dataset_type: 'sipakmed', 'herlev', or None for auto-detect\n",
        "        manual_threshold: Override automatic threshold\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"Analyzing: {os.path.basename(image_path)}\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    # Auto-detect dataset if not specified\n",
        "    if dataset_type is None and config.AUTO_DETECT:\n",
        "        dataset_type = detect_dataset_type(image_path)\n",
        "        print(f\"📊 Auto-detected dataset: {dataset_type}\")\n",
        "    elif dataset_type is None:\n",
        "        dataset_type = 'unknown'\n",
        "\n",
        "    # Get threshold\n",
        "    if manual_threshold is not None:\n",
        "        threshold = manual_threshold\n",
        "        print(f\"🎯 Using manual threshold: {threshold}\")\n",
        "    else:\n",
        "        threshold = config.THRESHOLDS.get(dataset_type, config.THRESHOLDS['unknown'])\n",
        "        print(f\"🎯 Using {dataset_type} threshold: {threshold}\")\n",
        "\n",
        "    # Preprocess\n",
        "    img = preprocess_image(image_path)\n",
        "    if img is None:\n",
        "        print(\"❌ Failed to load image\")\n",
        "        return None\n",
        "\n",
        "    # Predict\n",
        "    pred_proba = model.predict(img, verbose=0)[0][0]\n",
        "    pred_class = 1 if pred_proba >= threshold else 0\n",
        "    pred_label = 'Abnormal' if pred_class == 1 else 'Normal'\n",
        "\n",
        "    # Calculate confidence\n",
        "    if pred_class == 1:\n",
        "        confidence = (pred_proba / threshold) * 50 + 50\n",
        "    else:\n",
        "        confidence = ((threshold - pred_proba) / threshold) * 50 + 50\n",
        "    confidence = min(confidence, 100)\n",
        "\n",
        "    # Risk level\n",
        "    if pred_proba < config.RISK_LEVELS['very_low']:\n",
        "        risk = \"✅ VERY LOW RISK\"\n",
        "        risk_color = \"green\"\n",
        "    elif pred_proba < config.RISK_LEVELS['low']:\n",
        "        risk = \"🟢 LOW RISK\"\n",
        "        risk_color = \"lightgreen\"\n",
        "    elif pred_proba < config.RISK_LEVELS['moderate']:\n",
        "        risk = \"🟡 MODERATE RISK\"\n",
        "        risk_color = \"yellow\"\n",
        "    elif pred_proba < config.RISK_LEVELS['high']:\n",
        "        risk = \"🟠 ELEVATED RISK\"\n",
        "        risk_color = \"orange\"\n",
        "    else:\n",
        "        risk = \"🔴 HIGH RISK\"\n",
        "        risk_color = \"red\"\n",
        "\n",
        "    # Display results\n",
        "    print(f\"\\n📊 RESULTS:\")\n",
        "    print(f\"   Raw Score: {pred_proba:.4f}\")\n",
        "    print(f\"   Threshold: {threshold:.2f}\")\n",
        "    print(f\"   Prediction: {pred_label}\")\n",
        "    print(f\"   Confidence: {confidence:.1f}%\")\n",
        "    print(f\"   Risk Level: {risk}\")\n",
        "\n",
        "    # Comparison with different thresholds\n",
        "    print(f\"\\n🔄 With different thresholds:\")\n",
        "    for dt, th in config.THRESHOLDS.items():\n",
        "        pred_at_th = 'Abnormal' if pred_proba >= th else 'Normal'\n",
        "        print(f\"   {dt:10s} (th={th:.2f}): {pred_at_th}\")\n",
        "\n",
        "    # Clinical interpretation\n",
        "    print(f\"\\n🏥 CLINICAL INTERPRETATION:\")\n",
        "    if pred_proba < 0.3:\n",
        "        print(f\"   → Cells appear normal\")\n",
        "        print(f\"   → Routine follow-up recommended\")\n",
        "    elif pred_proba < 0.5:\n",
        "        print(f\"   → Minimal concern\")\n",
        "        print(f\"   → Consider repeat test in 6-12 months\")\n",
        "    elif pred_proba < 0.7:\n",
        "        print(f\"   → Moderate concern\")\n",
        "        print(f\"   → Additional testing recommended\")\n",
        "    elif pred_proba < 0.85:\n",
        "        print(f\"   → Significant concern\")\n",
        "        print(f\"   → Immediate follow-up required\")\n",
        "    else:\n",
        "        print(f\"   → High concern\")\n",
        "        print(f\"   → Urgent medical evaluation needed\")\n",
        "\n",
        "    return {\n",
        "        'image_path': image_path,\n",
        "        'dataset_type': dataset_type,\n",
        "        'raw_score': pred_proba,\n",
        "        'threshold': threshold,\n",
        "        'prediction': pred_label,\n",
        "        'confidence': confidence,\n",
        "        'risk_level': risk\n",
        "    }\n",
        "\n",
        "# ============================================================================\n",
        "# BATCH PREDICTION WITH STATISTICS\n",
        "# ============================================================================\n",
        "\n",
        "def predict_batch_adaptive(folder_path, dataset_type=None):\n",
        "    \"\"\"Batch prediction with adaptive thresholds\"\"\"\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"BATCH PREDICTION - ADAPTIVE MODE\")\n",
        "    print(f\"{'='*80}\")\n",
        "    print(f\"Folder: {folder_path}\")\n",
        "\n",
        "    # Get images\n",
        "    extensions = ['.bmp', '.jpg', '.jpeg', '.png']\n",
        "    images = []\n",
        "    for ext in extensions:\n",
        "        images.extend([os.path.join(folder_path, f)\n",
        "                      for f in os.listdir(folder_path)\n",
        "                      if f.lower().endswith(ext)])\n",
        "\n",
        "    if not images:\n",
        "        print(\"❌ No images found\")\n",
        "        return None\n",
        "\n",
        "    print(f\"Found {len(images)} images\")\n",
        "\n",
        "    # Predict each\n",
        "    results = []\n",
        "    for img_path in images:\n",
        "        result = predict_adaptive(img_path, dataset_type, manual_threshold=None)\n",
        "        if result:\n",
        "            results.append(result)\n",
        "\n",
        "    # Statistics\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"BATCH SUMMARY\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    normal = sum(1 for r in results if r['prediction'] == 'Normal')\n",
        "    abnormal = sum(1 for r in results if r['prediction'] == 'Abnormal')\n",
        "\n",
        "    print(f\"\\nTotal: {len(results)}\")\n",
        "    print(f\"  Normal: {normal} ({normal/len(results)*100:.1f}%)\")\n",
        "    print(f\"  Abnormal: {abnormal} ({abnormal/len(results)*100:.1f}%)\")\n",
        "\n",
        "    # By dataset type\n",
        "    print(f\"\\n📊 By Detected Dataset:\")\n",
        "    for dt in ['sipakmed', 'herlev', 'unknown']:\n",
        "        dt_results = [r for r in results if r['dataset_type'] == dt]\n",
        "        if dt_results:\n",
        "            dt_normal = sum(1 for r in dt_results if r['prediction'] == 'Normal')\n",
        "            dt_abnormal = sum(1 for r in dt_results if r['prediction'] == 'Abnormal')\n",
        "            print(f\"   {dt:10s}: {len(dt_results)} images\")\n",
        "            print(f\"      Normal: {dt_normal}, Abnormal: {dt_abnormal}\")\n",
        "\n",
        "    # Score statistics\n",
        "    scores = [r['raw_score'] for r in results]\n",
        "    print(f\"\\n📈 Score Statistics:\")\n",
        "    print(f\"   Mean: {np.mean(scores):.3f}\")\n",
        "    print(f\"   Median: {np.median(scores):.3f}\")\n",
        "    print(f\"   Min: {np.min(scores):.3f}\")\n",
        "    print(f\"   Max: {np.max(scores):.3f}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# ============================================================================\n",
        "# COMPARISON MODE\n",
        "# ============================================================================\n",
        "\n",
        "def compare_thresholds(image_path):\n",
        "    \"\"\"Compare predictions with different thresholds\"\"\"\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"THRESHOLD COMPARISON\")\n",
        "    print(f\"{'='*80}\")\n",
        "    print(f\"Image: {os.path.basename(image_path)}\")\n",
        "\n",
        "    # Get prediction score\n",
        "    img = preprocess_image(image_path)\n",
        "    if img is None:\n",
        "        return\n",
        "\n",
        "    score = model.predict(img, verbose=0)[0][0]\n",
        "\n",
        "    print(f\"\\nRaw Score: {score:.4f}\")\n",
        "    print(f\"\\n{'Threshold':<12} {'Prediction':<12} {'Use Case'}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    thresholds = [0.30, 0.40, 0.50, 0.60, 0.70]\n",
        "    for th in thresholds:\n",
        "        pred = 'Abnormal' if score >= th else 'Normal'\n",
        "\n",
        "        if th <= 0.40:\n",
        "            use_case = \"Screening (high sens.)\"\n",
        "        elif th <= 0.55:\n",
        "            use_case = \"General (balanced)\"\n",
        "        else:\n",
        "            use_case = \"Confirmation (high spec.)\"\n",
        "\n",
        "        print(f\"{th:.2f}         {pred:<12} {use_case}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "\n",
        "# ============================================================================\n",
        "# INTERACTIVE MODE\n",
        "# ============================================================================\n",
        "\n",
        "def interactive_mode():\n",
        "    \"\"\"Interactive prediction\"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"INTERACTIVE MODE\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"\\nOptions:\")\n",
        "    print(\"  1. Predict single image (auto-detect dataset)\")\n",
        "    print(\"  2. Predict single image (specify dataset)\")\n",
        "    print(\"  3. Predict batch (auto-detect)\")\n",
        "    print(\"  4. Predict batch (specify dataset)\")\n",
        "    print(\"  5. Compare thresholds for image\")\n",
        "    print(\"  6. Update thresholds\")\n",
        "    print(\"  7. Exit\")\n",
        "\n",
        "    while True:\n",
        "        print(\"\\n\" + \"-\"*80)\n",
        "        choice = input(\"\\nSelect (1-7): \").strip()\n",
        "\n",
        "        if choice == '1':\n",
        "            path = input(\"Image path: \").strip().strip('\"').strip(\"'\")\n",
        "            if os.path.exists(path):\n",
        "                predict_adaptive(path)\n",
        "            else:\n",
        "                print(\"❌ Not found\")\n",
        "\n",
        "        elif choice == '2':\n",
        "            path = input(\"Image path: \").strip().strip('\"').strip(\"'\")\n",
        "            print(\"\\nDataset types:\")\n",
        "            print(\"  1. SIPaKMeD\")\n",
        "            print(\"  2. Herlev\")\n",
        "            print(\"  3. Unknown\")\n",
        "            dt_choice = input(\"Select (1-3): \").strip()\n",
        "            dt_map = {'1': 'sipakmed', '2': 'herlev', '3': 'unknown'}\n",
        "            dataset_type = dt_map.get(dt_choice, 'unknown')\n",
        "\n",
        "            if os.path.exists(path):\n",
        "                predict_adaptive(path, dataset_type=dataset_type)\n",
        "            else:\n",
        "                print(\"❌ Not found\")\n",
        "\n",
        "        elif choice == '3':\n",
        "            path = input(\"Folder path: \").strip().strip('\"').strip(\"'\")\n",
        "            if os.path.exists(path):\n",
        "                predict_batch_adaptive(path)\n",
        "            else:\n",
        "                print(\"❌ Not found\")\n",
        "\n",
        "        elif choice == '4':\n",
        "            path = input(\"Folder path: \").strip().strip('\"').strip(\"'\")\n",
        "            print(\"\\nDataset types:\")\n",
        "            print(\"  1. SIPaKMeD\")\n",
        "            print(\"  2. Herlev\")\n",
        "            dt_choice = input(\"Select (1-2): \").strip()\n",
        "            dt_map = {'1': 'sipakmed', '2': 'herlev'}\n",
        "            dataset_type = dt_map.get(dt_choice)\n",
        "\n",
        "            if os.path.exists(path):\n",
        "                predict_batch_adaptive(path, dataset_type=dataset_type)\n",
        "            else:\n",
        "                print(\"❌ Not found\")\n",
        "\n",
        "        elif choice == '5':\n",
        "            path = input(\"Image path: \").strip().strip('\"').strip(\"'\")\n",
        "            if os.path.exists(path):\n",
        "                compare_thresholds(path)\n",
        "            else:\n",
        "                print(\"❌ Not found\")\n",
        "\n",
        "        elif choice == '6':\n",
        "            print(f\"\\nCurrent thresholds:\")\n",
        "            print(f\"  SIPaKMeD: {config.THRESHOLDS['sipakmed']}\")\n",
        "            print(f\"  Herlev: {config.THRESHOLDS['herlev']}\")\n",
        "            print(f\"  Unknown: {config.THRESHOLDS['unknown']}\")\n",
        "\n",
        "            print(f\"\\n💡 Recommendations:\")\n",
        "            print(f\"   - Lower threshold (0.3-0.4): More sensitive, fewer missed cancers\")\n",
        "            print(f\"   - Higher threshold (0.6-0.7): More specific, fewer false alarms\")\n",
        "            print(f\"   - Current Herlev: 0.65 (to fix 50% specificity issue)\")\n",
        "\n",
        "            dt = input(\"\\nWhich to update (sipakmed/herlev/unknown): \").strip().lower()\n",
        "            if dt in config.THRESHOLDS:\n",
        "                try:\n",
        "                    new_th = float(input(f\"New threshold for {dt} (0.0-1.0): \"))\n",
        "                    if 0 <= new_th <= 1:\n",
        "                        config.THRESHOLDS[dt] = new_th\n",
        "                        print(f\"✅ Updated {dt} threshold to {new_th}\")\n",
        "                    else:\n",
        "                        print(\"❌ Invalid range\")\n",
        "                except:\n",
        "                    print(\"❌ Invalid input\")\n",
        "\n",
        "        elif choice == '7':\n",
        "            print(\"\\nExiting...\")\n",
        "            break\n",
        "\n",
        "        else:\n",
        "            print(\"❌ Invalid option\")\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN\n",
        "# ============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\n💡 ADAPTIVE INFERENCE SYSTEM\")\n",
        "    print(\"   Automatically adjusts threshold based on dataset\")\n",
        "    print(\"   Solves the Herlev 50% specificity problem!\")\n",
        "\n",
        "    interactive_mode()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6f2C4lJ1tJdE",
        "outputId": "91da6d1b-e016-4ca0-a3ba-7acc76032436"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "ADAPTIVE INFERENCE SYSTEM\n",
            "================================================================================\n",
            "Model: final_model_combined.h5\n",
            "Thresholds:\n",
            "  SIPaKMeD: 0.5\n",
            "  Herlev: 0.65\n",
            "  Auto-detect: True\n",
            "================================================================================\n",
            "\n",
            "[1] Loading model...\n",
            "✅ Model loaded\n",
            "\n",
            "💡 ADAPTIVE INFERENCE SYSTEM\n",
            "   Automatically adjusts threshold based on dataset\n",
            "   Solves the Herlev 50% specificity problem!\n",
            "\n",
            "================================================================================\n",
            "INTERACTIVE MODE\n",
            "================================================================================\n",
            "\n",
            "Options:\n",
            "  1. Predict single image (auto-detect dataset)\n",
            "  2. Predict single image (specify dataset)\n",
            "  3. Predict batch (auto-detect)\n",
            "  4. Predict batch (specify dataset)\n",
            "  5. Compare thresholds for image\n",
            "  6. Update thresholds\n",
            "  7. Exit\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Select (1-7): 3\n",
            "Folder path: /content/sample_data/herlev_normal\n",
            "\n",
            "================================================================================\n",
            "BATCH PREDICTION - ADAPTIVE MODE\n",
            "================================================================================\n",
            "Folder: /content/sample_data/herlev_normal\n",
            "Found 73 images\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209565409-209565466-001.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.0001\n",
            "   Threshold: 0.65\n",
            "   Prediction: Normal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: ✅ VERY LOW RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Normal\n",
            "   herlev     (th=0.65): Normal\n",
            "   unknown    (th=0.55): Normal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Cells appear normal\n",
            "   → Routine follow-up recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 158987493-158987505-001.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.0003\n",
            "   Threshold: 0.65\n",
            "   Prediction: Normal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: ✅ VERY LOW RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Normal\n",
            "   herlev     (th=0.65): Normal\n",
            "   unknown    (th=0.55): Normal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Cells appear normal\n",
            "   → Routine follow-up recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 157185781-157185814-002.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.8436\n",
            "   Threshold: 0.65\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🟠 ELEVATED RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Abnormal\n",
            "   herlev     (th=0.65): Abnormal\n",
            "   unknown    (th=0.55): Abnormal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Significant concern\n",
            "   → Immediate follow-up required\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209566205-209566321-001.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.0001\n",
            "   Threshold: 0.65\n",
            "   Prediction: Normal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: ✅ VERY LOW RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Normal\n",
            "   herlev     (th=0.65): Normal\n",
            "   unknown    (th=0.55): Normal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Cells appear normal\n",
            "   → Routine follow-up recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 157224172-157224207-003.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.8154\n",
            "   Threshold: 0.65\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🟠 ELEVATED RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Abnormal\n",
            "   herlev     (th=0.65): Abnormal\n",
            "   unknown    (th=0.55): Abnormal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Significant concern\n",
            "   → Immediate follow-up required\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209566399-209566485-001.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.0000\n",
            "   Threshold: 0.65\n",
            "   Prediction: Normal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: ✅ VERY LOW RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Normal\n",
            "   herlev     (th=0.65): Normal\n",
            "   unknown    (th=0.55): Normal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Cells appear normal\n",
            "   → Routine follow-up recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 157185781-157185814-001.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.8884\n",
            "   Threshold: 0.65\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🔴 HIGH RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Abnormal\n",
            "   herlev     (th=0.65): Abnormal\n",
            "   unknown    (th=0.55): Abnormal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → High concern\n",
            "   → Urgent medical evaluation needed\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 157268504-157268544-001.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.1478\n",
            "   Threshold: 0.65\n",
            "   Prediction: Normal\n",
            "   Confidence: 88.6%\n",
            "   Risk Level: ✅ VERY LOW RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Normal\n",
            "   herlev     (th=0.65): Normal\n",
            "   unknown    (th=0.55): Normal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Cells appear normal\n",
            "   → Routine follow-up recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209047881-209048017-001.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.0093\n",
            "   Threshold: 0.65\n",
            "   Prediction: Normal\n",
            "   Confidence: 99.3%\n",
            "   Risk Level: ✅ VERY LOW RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Normal\n",
            "   herlev     (th=0.65): Normal\n",
            "   unknown    (th=0.55): Normal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Cells appear normal\n",
            "   → Routine follow-up recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 157267647-157267732-001.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.0413\n",
            "   Threshold: 0.65\n",
            "   Prediction: Normal\n",
            "   Confidence: 96.8%\n",
            "   Risk Level: ✅ VERY LOW RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Normal\n",
            "   herlev     (th=0.65): Normal\n",
            "   unknown    (th=0.55): Normal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Cells appear normal\n",
            "   → Routine follow-up recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209566047-209566125-001.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.0002\n",
            "   Threshold: 0.65\n",
            "   Prediction: Normal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: ✅ VERY LOW RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Normal\n",
            "   herlev     (th=0.65): Normal\n",
            "   unknown    (th=0.55): Normal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Cells appear normal\n",
            "   → Routine follow-up recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 157267263-157267286-002.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.7449\n",
            "   Threshold: 0.65\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🟠 ELEVATED RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Abnormal\n",
            "   herlev     (th=0.65): Abnormal\n",
            "   unknown    (th=0.55): Abnormal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Significant concern\n",
            "   → Immediate follow-up required\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209566205-209566266-001.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.0000\n",
            "   Threshold: 0.65\n",
            "   Prediction: Normal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: ✅ VERY LOW RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Normal\n",
            "   herlev     (th=0.65): Normal\n",
            "   unknown    (th=0.55): Normal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Cells appear normal\n",
            "   → Routine follow-up recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209047526-209047798-001.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.1016\n",
            "   Threshold: 0.65\n",
            "   Prediction: Normal\n",
            "   Confidence: 92.2%\n",
            "   Risk Level: ✅ VERY LOW RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Normal\n",
            "   herlev     (th=0.65): Normal\n",
            "   unknown    (th=0.55): Normal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Cells appear normal\n",
            "   → Routine follow-up recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209565698-209565772-001.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.0001\n",
            "   Threshold: 0.65\n",
            "   Prediction: Normal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: ✅ VERY LOW RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Normal\n",
            "   herlev     (th=0.65): Normal\n",
            "   unknown    (th=0.55): Normal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Cells appear normal\n",
            "   → Routine follow-up recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 158987033-158987057-001.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.1679\n",
            "   Threshold: 0.65\n",
            "   Prediction: Normal\n",
            "   Confidence: 87.1%\n",
            "   Risk Level: ✅ VERY LOW RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Normal\n",
            "   herlev     (th=0.65): Normal\n",
            "   unknown    (th=0.55): Normal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Cells appear normal\n",
            "   → Routine follow-up recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 157181569-157181599-001.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.0029\n",
            "   Threshold: 0.65\n",
            "   Prediction: Normal\n",
            "   Confidence: 99.8%\n",
            "   Risk Level: ✅ VERY LOW RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Normal\n",
            "   herlev     (th=0.65): Normal\n",
            "   unknown    (th=0.55): Normal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Cells appear normal\n",
            "   → Routine follow-up recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209566399-209566517-001.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.5411\n",
            "   Threshold: 0.65\n",
            "   Prediction: Normal\n",
            "   Confidence: 58.4%\n",
            "   Risk Level: 🟡 MODERATE RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Abnormal\n",
            "   herlev     (th=0.65): Normal\n",
            "   unknown    (th=0.55): Normal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Moderate concern\n",
            "   → Additional testing recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 157224458-157224483-001.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.1692\n",
            "   Threshold: 0.65\n",
            "   Prediction: Normal\n",
            "   Confidence: 87.0%\n",
            "   Risk Level: ✅ VERY LOW RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Normal\n",
            "   herlev     (th=0.65): Normal\n",
            "   unknown    (th=0.55): Normal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Cells appear normal\n",
            "   → Routine follow-up recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209565409-209565600-001.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.0000\n",
            "   Threshold: 0.65\n",
            "   Prediction: Normal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: ✅ VERY LOW RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Normal\n",
            "   herlev     (th=0.65): Normal\n",
            "   unknown    (th=0.55): Normal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Cells appear normal\n",
            "   → Routine follow-up recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 157266930-157266947-003.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.9804\n",
            "   Threshold: 0.65\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🔴 HIGH RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Abnormal\n",
            "   herlev     (th=0.65): Abnormal\n",
            "   unknown    (th=0.55): Abnormal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → High concern\n",
            "   → Urgent medical evaluation needed\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 158987453-158987462-001.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.1271\n",
            "   Threshold: 0.65\n",
            "   Prediction: Normal\n",
            "   Confidence: 90.2%\n",
            "   Risk Level: ✅ VERY LOW RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Normal\n",
            "   herlev     (th=0.65): Normal\n",
            "   unknown    (th=0.55): Normal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Cells appear normal\n",
            "   → Routine follow-up recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 157224172-157224207-002.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.7957\n",
            "   Threshold: 0.65\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🟠 ELEVATED RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Abnormal\n",
            "   herlev     (th=0.65): Abnormal\n",
            "   unknown    (th=0.55): Abnormal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Significant concern\n",
            "   → Immediate follow-up required\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 158986920-158986928-003.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.2411\n",
            "   Threshold: 0.65\n",
            "   Prediction: Normal\n",
            "   Confidence: 81.5%\n",
            "   Risk Level: ✅ VERY LOW RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Normal\n",
            "   herlev     (th=0.65): Normal\n",
            "   unknown    (th=0.55): Normal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Cells appear normal\n",
            "   → Routine follow-up recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209566205-209566247-001.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.0007\n",
            "   Threshold: 0.65\n",
            "   Prediction: Normal\n",
            "   Confidence: 99.9%\n",
            "   Risk Level: ✅ VERY LOW RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Normal\n",
            "   herlev     (th=0.65): Normal\n",
            "   unknown    (th=0.55): Normal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Cells appear normal\n",
            "   → Routine follow-up recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 158986813-158986820-001.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.8911\n",
            "   Threshold: 0.65\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🔴 HIGH RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Abnormal\n",
            "   herlev     (th=0.65): Abnormal\n",
            "   unknown    (th=0.55): Abnormal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → High concern\n",
            "   → Urgent medical evaluation needed\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 157224412-157224429-001.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.7235\n",
            "   Threshold: 0.65\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🟠 ELEVATED RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Abnormal\n",
            "   herlev     (th=0.65): Abnormal\n",
            "   unknown    (th=0.55): Abnormal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Significant concern\n",
            "   → Immediate follow-up required\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 158986766-158986776-001.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.4409\n",
            "   Threshold: 0.65\n",
            "   Prediction: Normal\n",
            "   Confidence: 66.1%\n",
            "   Risk Level: 🟢 LOW RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Normal\n",
            "   herlev     (th=0.65): Normal\n",
            "   unknown    (th=0.55): Normal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Minimal concern\n",
            "   → Consider repeat test in 6-12 months\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209048086-209048278-001.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.0001\n",
            "   Threshold: 0.65\n",
            "   Prediction: Normal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: ✅ VERY LOW RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Normal\n",
            "   herlev     (th=0.65): Normal\n",
            "   unknown    (th=0.55): Normal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Cells appear normal\n",
            "   → Routine follow-up recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 157267059-157267072-003.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.9327\n",
            "   Threshold: 0.65\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🔴 HIGH RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Abnormal\n",
            "   herlev     (th=0.65): Abnormal\n",
            "   unknown    (th=0.55): Abnormal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → High concern\n",
            "   → Urgent medical evaluation needed\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 158986920-158986928-006.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.6105\n",
            "   Threshold: 0.65\n",
            "   Prediction: Normal\n",
            "   Confidence: 53.0%\n",
            "   Risk Level: 🟡 MODERATE RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Abnormal\n",
            "   herlev     (th=0.65): Normal\n",
            "   unknown    (th=0.55): Abnormal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Moderate concern\n",
            "   → Additional testing recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209522940-209523052-001.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.0095\n",
            "   Threshold: 0.65\n",
            "   Prediction: Normal\n",
            "   Confidence: 99.3%\n",
            "   Risk Level: ✅ VERY LOW RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Normal\n",
            "   herlev     (th=0.65): Normal\n",
            "   unknown    (th=0.55): Normal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Cells appear normal\n",
            "   → Routine follow-up recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 157267059-157267072-002.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.9759\n",
            "   Threshold: 0.65\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🔴 HIGH RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Abnormal\n",
            "   herlev     (th=0.65): Abnormal\n",
            "   unknown    (th=0.55): Abnormal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → High concern\n",
            "   → Urgent medical evaluation needed\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209047526-209047717-001.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.0012\n",
            "   Threshold: 0.65\n",
            "   Prediction: Normal\n",
            "   Confidence: 99.9%\n",
            "   Risk Level: ✅ VERY LOW RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Normal\n",
            "   herlev     (th=0.65): Normal\n",
            "   unknown    (th=0.55): Normal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Cells appear normal\n",
            "   → Routine follow-up recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209047342-209047400-001.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.0037\n",
            "   Threshold: 0.65\n",
            "   Prediction: Normal\n",
            "   Confidence: 99.7%\n",
            "   Risk Level: ✅ VERY LOW RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Normal\n",
            "   herlev     (th=0.65): Normal\n",
            "   unknown    (th=0.55): Normal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Cells appear normal\n",
            "   → Routine follow-up recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 157268342-157268401-001.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.1775\n",
            "   Threshold: 0.65\n",
            "   Prediction: Normal\n",
            "   Confidence: 86.3%\n",
            "   Risk Level: ✅ VERY LOW RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Normal\n",
            "   herlev     (th=0.65): Normal\n",
            "   unknown    (th=0.55): Normal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Cells appear normal\n",
            "   → Routine follow-up recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209522940-209522970-001.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.0001\n",
            "   Threshold: 0.65\n",
            "   Prediction: Normal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: ✅ VERY LOW RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Normal\n",
            "   herlev     (th=0.65): Normal\n",
            "   unknown    (th=0.55): Normal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Cells appear normal\n",
            "   → Routine follow-up recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 157266930-157266947-001.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.8782\n",
            "   Threshold: 0.65\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🔴 HIGH RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Abnormal\n",
            "   herlev     (th=0.65): Abnormal\n",
            "   unknown    (th=0.55): Abnormal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → High concern\n",
            "   → Urgent medical evaluation needed\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209565864-209565890-001.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.0002\n",
            "   Threshold: 0.65\n",
            "   Prediction: Normal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: ✅ VERY LOW RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Normal\n",
            "   herlev     (th=0.65): Normal\n",
            "   unknown    (th=0.55): Normal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Cells appear normal\n",
            "   → Routine follow-up recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209048086-209048137-001.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.0000\n",
            "   Threshold: 0.65\n",
            "   Prediction: Normal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: ✅ VERY LOW RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Normal\n",
            "   herlev     (th=0.65): Normal\n",
            "   unknown    (th=0.55): Normal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Cells appear normal\n",
            "   → Routine follow-up recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209565864-209565950-001.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.0001\n",
            "   Threshold: 0.65\n",
            "   Prediction: Normal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: ✅ VERY LOW RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Normal\n",
            "   herlev     (th=0.65): Normal\n",
            "   unknown    (th=0.55): Normal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Cells appear normal\n",
            "   → Routine follow-up recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 158986920-158986928-001.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.9103\n",
            "   Threshold: 0.65\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🔴 HIGH RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Abnormal\n",
            "   herlev     (th=0.65): Abnormal\n",
            "   unknown    (th=0.55): Abnormal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → High concern\n",
            "   → Urgent medical evaluation needed\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 157267059-157267072-004.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.9007\n",
            "   Threshold: 0.65\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🔴 HIGH RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Abnormal\n",
            "   herlev     (th=0.65): Abnormal\n",
            "   unknown    (th=0.55): Abnormal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → High concern\n",
            "   → Urgent medical evaluation needed\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 157227461-157227503-001.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.8629\n",
            "   Threshold: 0.65\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🔴 HIGH RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Abnormal\n",
            "   herlev     (th=0.65): Abnormal\n",
            "   unknown    (th=0.55): Abnormal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → High concern\n",
            "   → Urgent medical evaluation needed\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 157267263-157267286-001.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.8760\n",
            "   Threshold: 0.65\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🔴 HIGH RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Abnormal\n",
            "   herlev     (th=0.65): Abnormal\n",
            "   unknown    (th=0.55): Abnormal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → High concern\n",
            "   → Urgent medical evaluation needed\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 157224172-157224207-001.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.9163\n",
            "   Threshold: 0.65\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🔴 HIGH RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Abnormal\n",
            "   herlev     (th=0.65): Abnormal\n",
            "   unknown    (th=0.55): Abnormal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → High concern\n",
            "   → Urgent medical evaluation needed\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209565864-209565911-001.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.0000\n",
            "   Threshold: 0.65\n",
            "   Prediction: Normal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: ✅ VERY LOW RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Normal\n",
            "   herlev     (th=0.65): Normal\n",
            "   unknown    (th=0.55): Normal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Cells appear normal\n",
            "   → Routine follow-up recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 157268242-157268296-001.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.2927\n",
            "   Threshold: 0.65\n",
            "   Prediction: Normal\n",
            "   Confidence: 77.5%\n",
            "   Risk Level: ✅ VERY LOW RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Normal\n",
            "   herlev     (th=0.65): Normal\n",
            "   unknown    (th=0.55): Normal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Cells appear normal\n",
            "   → Routine follow-up recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209566205-209566289-001.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.0001\n",
            "   Threshold: 0.65\n",
            "   Prediction: Normal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: ✅ VERY LOW RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Normal\n",
            "   herlev     (th=0.65): Normal\n",
            "   unknown    (th=0.55): Normal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Cells appear normal\n",
            "   → Routine follow-up recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 158987493-158987499-001.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.0005\n",
            "   Threshold: 0.65\n",
            "   Prediction: Normal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: ✅ VERY LOW RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Normal\n",
            "   herlev     (th=0.65): Normal\n",
            "   unknown    (th=0.55): Normal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Cells appear normal\n",
            "   → Routine follow-up recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 158986920-158986928-004.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.7453\n",
            "   Threshold: 0.65\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🟠 ELEVATED RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Abnormal\n",
            "   herlev     (th=0.65): Abnormal\n",
            "   unknown    (th=0.55): Abnormal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Significant concern\n",
            "   → Immediate follow-up required\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209566399-209566464-001.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.0001\n",
            "   Threshold: 0.65\n",
            "   Prediction: Normal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: ✅ VERY LOW RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Normal\n",
            "   herlev     (th=0.65): Normal\n",
            "   unknown    (th=0.55): Normal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Cells appear normal\n",
            "   → Routine follow-up recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 158986766-158986776-002.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.9204\n",
            "   Threshold: 0.65\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🔴 HIGH RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Abnormal\n",
            "   herlev     (th=0.65): Abnormal\n",
            "   unknown    (th=0.55): Abnormal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → High concern\n",
            "   → Urgent medical evaluation needed\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 157267001-157267013-001.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.6060\n",
            "   Threshold: 0.65\n",
            "   Prediction: Normal\n",
            "   Confidence: 53.4%\n",
            "   Risk Level: 🟡 MODERATE RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Abnormal\n",
            "   herlev     (th=0.65): Normal\n",
            "   unknown    (th=0.55): Abnormal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Moderate concern\n",
            "   → Additional testing recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 157267059-157267072-001.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.9711\n",
            "   Threshold: 0.65\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🔴 HIGH RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Abnormal\n",
            "   herlev     (th=0.65): Abnormal\n",
            "   unknown    (th=0.55): Abnormal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → High concern\n",
            "   → Urgent medical evaluation needed\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209047342-209047443-001.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.2274\n",
            "   Threshold: 0.65\n",
            "   Prediction: Normal\n",
            "   Confidence: 82.5%\n",
            "   Risk Level: ✅ VERY LOW RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Normal\n",
            "   herlev     (th=0.65): Normal\n",
            "   unknown    (th=0.55): Normal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Cells appear normal\n",
            "   → Routine follow-up recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 157224504-157224520-001.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.8991\n",
            "   Threshold: 0.65\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🔴 HIGH RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Abnormal\n",
            "   herlev     (th=0.65): Abnormal\n",
            "   unknown    (th=0.55): Abnormal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → High concern\n",
            "   → Urgent medical evaluation needed\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 158986920-158986928-005.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.8302\n",
            "   Threshold: 0.65\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🟠 ELEVATED RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Abnormal\n",
            "   herlev     (th=0.65): Abnormal\n",
            "   unknown    (th=0.55): Abnormal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Significant concern\n",
            "   → Immediate follow-up required\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 157227461-157227503-003.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.7929\n",
            "   Threshold: 0.65\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🟠 ELEVATED RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Abnormal\n",
            "   herlev     (th=0.65): Abnormal\n",
            "   unknown    (th=0.55): Abnormal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Significant concern\n",
            "   → Immediate follow-up required\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209565409-209565503-001.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.0002\n",
            "   Threshold: 0.65\n",
            "   Prediction: Normal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: ✅ VERY LOW RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Normal\n",
            "   herlev     (th=0.65): Normal\n",
            "   unknown    (th=0.55): Normal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Cells appear normal\n",
            "   → Routine follow-up recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 157227058-157227087-001.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.6954\n",
            "   Threshold: 0.65\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🟡 MODERATE RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Abnormal\n",
            "   herlev     (th=0.65): Abnormal\n",
            "   unknown    (th=0.55): Abnormal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Moderate concern\n",
            "   → Additional testing recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 158986920-158986928-002.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.8021\n",
            "   Threshold: 0.65\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🟠 ELEVATED RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Abnormal\n",
            "   herlev     (th=0.65): Abnormal\n",
            "   unknown    (th=0.55): Abnormal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Significant concern\n",
            "   → Immediate follow-up required\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209565698-209565729-001.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.0003\n",
            "   Threshold: 0.65\n",
            "   Prediction: Normal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: ✅ VERY LOW RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Normal\n",
            "   herlev     (th=0.65): Normal\n",
            "   unknown    (th=0.55): Normal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Cells appear normal\n",
            "   → Routine follow-up recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209522940-209522991-001.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.0013\n",
            "   Threshold: 0.65\n",
            "   Prediction: Normal\n",
            "   Confidence: 99.9%\n",
            "   Risk Level: ✅ VERY LOW RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Normal\n",
            "   herlev     (th=0.65): Normal\n",
            "   unknown    (th=0.55): Normal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Cells appear normal\n",
            "   → Routine follow-up recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 157227461-157227503-002.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.6037\n",
            "   Threshold: 0.65\n",
            "   Prediction: Normal\n",
            "   Confidence: 53.6%\n",
            "   Risk Level: 🟡 MODERATE RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Abnormal\n",
            "   herlev     (th=0.65): Normal\n",
            "   unknown    (th=0.55): Abnormal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Moderate concern\n",
            "   → Additional testing recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 158986813-158986820-002.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.7122\n",
            "   Threshold: 0.65\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🟠 ELEVATED RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Abnormal\n",
            "   herlev     (th=0.65): Abnormal\n",
            "   unknown    (th=0.55): Abnormal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Significant concern\n",
            "   → Immediate follow-up required\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209566047-209566095-001.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.0040\n",
            "   Threshold: 0.65\n",
            "   Prediction: Normal\n",
            "   Confidence: 99.7%\n",
            "   Risk Level: ✅ VERY LOW RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Normal\n",
            "   herlev     (th=0.65): Normal\n",
            "   unknown    (th=0.55): Normal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Cells appear normal\n",
            "   → Routine follow-up recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 157268587-157268617-001.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.2972\n",
            "   Threshold: 0.65\n",
            "   Prediction: Normal\n",
            "   Confidence: 77.1%\n",
            "   Risk Level: ✅ VERY LOW RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Normal\n",
            "   herlev     (th=0.65): Normal\n",
            "   unknown    (th=0.55): Normal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Cells appear normal\n",
            "   → Routine follow-up recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209307421-209307597-001.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.0002\n",
            "   Threshold: 0.65\n",
            "   Prediction: Normal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: ✅ VERY LOW RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Normal\n",
            "   herlev     (th=0.65): Normal\n",
            "   unknown    (th=0.55): Normal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Cells appear normal\n",
            "   → Routine follow-up recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 157266930-157266947-002.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.9750\n",
            "   Threshold: 0.65\n",
            "   Prediction: Abnormal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: 🔴 HIGH RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Abnormal\n",
            "   herlev     (th=0.65): Abnormal\n",
            "   unknown    (th=0.55): Abnormal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → High concern\n",
            "   → Urgent medical evaluation needed\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 157268342-157268376-001.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.4150\n",
            "   Threshold: 0.65\n",
            "   Prediction: Normal\n",
            "   Confidence: 68.1%\n",
            "   Risk Level: 🟢 LOW RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Normal\n",
            "   herlev     (th=0.65): Normal\n",
            "   unknown    (th=0.55): Normal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Minimal concern\n",
            "   → Consider repeat test in 6-12 months\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209047342-209047478-001.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.1207\n",
            "   Threshold: 0.65\n",
            "   Prediction: Normal\n",
            "   Confidence: 90.7%\n",
            "   Risk Level: ✅ VERY LOW RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Normal\n",
            "   herlev     (th=0.65): Normal\n",
            "   unknown    (th=0.55): Normal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Cells appear normal\n",
            "   → Routine follow-up recommended\n",
            "\n",
            "================================================================================\n",
            "Analyzing: 209566205-209566333-001.BMP\n",
            "================================================================================\n",
            "📊 Auto-detected dataset: herlev\n",
            "🎯 Using herlev threshold: 0.65\n",
            "\n",
            "📊 RESULTS:\n",
            "   Raw Score: 0.0006\n",
            "   Threshold: 0.65\n",
            "   Prediction: Normal\n",
            "   Confidence: 100.0%\n",
            "   Risk Level: ✅ VERY LOW RISK\n",
            "\n",
            "🔄 With different thresholds:\n",
            "   sipakmed   (th=0.50): Normal\n",
            "   herlev     (th=0.65): Normal\n",
            "   unknown    (th=0.55): Normal\n",
            "\n",
            "🏥 CLINICAL INTERPRETATION:\n",
            "   → Cells appear normal\n",
            "   → Routine follow-up recommended\n",
            "\n",
            "================================================================================\n",
            "BATCH SUMMARY\n",
            "================================================================================\n",
            "\n",
            "Total: 73\n",
            "  Normal: 47 (64.4%)\n",
            "  Abnormal: 26 (35.6%)\n",
            "\n",
            "📊 By Detected Dataset:\n",
            "   herlev    : 73 images\n",
            "      Normal: 47, Abnormal: 26\n",
            "\n",
            "📈 Score Statistics:\n",
            "   Mean: 0.379\n",
            "   Median: 0.177\n",
            "   Min: 0.000\n",
            "   Max: 0.980\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1939828992.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"   Solves the Herlev 50% specificity problem!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m     \u001b[0minteractive_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-1939828992.py\u001b[0m in \u001b[0;36minteractive_mode\u001b[0;34m()\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"-\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0mchoice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nSelect (1-7): \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mchoice\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'1'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Multi-Class Cervical Cancer Classification\n",
        "Predicts severity level instead of just Normal/Abnormal\n",
        "\n",
        "Classes:\n",
        "1. Normal\n",
        "2. Mild Abnormality\n",
        "3. Moderate Abnormality\n",
        "4. Severe/Cancer\n",
        "\n",
        "Run: python multiclass_training.py\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# ============================================================================\n",
        "# CONFIGURATION\n",
        "# ============================================================================\n",
        "\n",
        "class Config:\n",
        "    # Dataset\n",
        "    COMBINED_CSV = 'combined_dataset.csv'\n",
        "\n",
        "    # Model settings\n",
        "    IMG_SIZE = 224\n",
        "    BATCH_SIZE = 16\n",
        "    EPOCHS = 50\n",
        "    LEARNING_RATE = 0.0001\n",
        "\n",
        "    # NEW: Multi-class mapping\n",
        "    # Map original classes to severity levels\n",
        "    SEVERITY_MAPPING = {\n",
        "        # Normal (Class 0)\n",
        "        'im_Superficial-Intermediate': 0,\n",
        "        'im_Metaplastic': 0,\n",
        "        'normal_columnar': 0,\n",
        "        'normal_intermediate': 0,\n",
        "        'normal_superficial': 0,\n",
        "\n",
        "        # Mild Abnormality (Class 1)\n",
        "        'im_Dyskeratotic': 1,\n",
        "        'light_dysplastic': 1,\n",
        "\n",
        "        # Moderate Abnormality (Class 2)\n",
        "        'im_Koilocytotic': 2,\n",
        "        'im_Parabasal': 2,\n",
        "        'moderate_dysplastic': 2,\n",
        "\n",
        "        # Severe/Cancer (Class 3)\n",
        "        'severe_dysplastic': 3,\n",
        "        'carcinoma_in_situ': 3\n",
        "    }\n",
        "\n",
        "    CLASS_NAMES = [\n",
        "        'Normal',\n",
        "        'Mild Abnormality',\n",
        "        'Moderate Abnormality',\n",
        "        'Severe/Cancer'\n",
        "    ]\n",
        "\n",
        "    NUM_CLASSES = len(CLASS_NAMES)\n",
        "\n",
        "    # Output\n",
        "    OUTPUT_DIR = 'multiclass_output'\n",
        "    MODEL_PATH = 'multiclass_model.h5'\n",
        "\n",
        "config = Config()\n",
        "os.makedirs(config.OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"MULTI-CLASS CERVICAL CANCER CLASSIFICATION\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"Classes: {config.NUM_CLASSES}\")\n",
        "for i, name in enumerate(config.CLASS_NAMES):\n",
        "    print(f\"  {i}: {name}\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# ============================================================================\n",
        "# LOAD AND PREPARE DATA\n",
        "# ============================================================================\n",
        "\n",
        "def load_and_map_data(csv_path):\n",
        "    \"\"\"Load dataset and map to severity levels\"\"\"\n",
        "    print(\"\\n[1] Loading and mapping data...\")\n",
        "\n",
        "    df = pd.read_csv(csv_path)\n",
        "\n",
        "    # Map to severity levels\n",
        "    df['severity'] = df['class_name'].map(config.SEVERITY_MAPPING)\n",
        "\n",
        "    # Remove any unmapped classes\n",
        "    df = df.dropna(subset=['severity'])\n",
        "    df['severity'] = df['severity'].astype(int)\n",
        "\n",
        "    print(f\"\\nDataset Statistics:\")\n",
        "    print(f\"  Total samples: {len(df)}\")\n",
        "    print(f\"\\n  By Severity:\")\n",
        "    for severity in range(config.NUM_CLASSES):\n",
        "        count = len(df[df['severity'] == severity])\n",
        "        pct = count / len(df) * 100\n",
        "        print(f\"    {config.CLASS_NAMES[severity]}: {count} ({pct:.1f}%)\")\n",
        "\n",
        "    print(f\"\\n  By Dataset:\")\n",
        "    for dataset in df['dataset_source'].unique():\n",
        "        count = len(df[df['dataset_source'] == dataset])\n",
        "        print(f\"    {dataset}: {count}\")\n",
        "\n",
        "    return df\n",
        "\n",
        "def split_data(df):\n",
        "    \"\"\"Split data into train/val/test\"\"\"\n",
        "    print(\"\\n[2] Splitting data...\")\n",
        "\n",
        "    # Split by dataset to ensure both in each split\n",
        "    sipakmed_df = df[df['dataset_source'] == 'sipakmed']\n",
        "    herlev_df = df[df['dataset_source'] == 'herlev']\n",
        "\n",
        "    # Split SIPaKMeD\n",
        "    sip_train_val, sip_test = train_test_split(\n",
        "        sipakmed_df, test_size=0.2,\n",
        "        stratify=sipakmed_df['severity'], random_state=42\n",
        "    )\n",
        "    sip_train, sip_val = train_test_split(\n",
        "        sip_train_val, test_size=0.125,\n",
        "        stratify=sip_train_val['severity'], random_state=42\n",
        "    )\n",
        "\n",
        "    # Split Herlev\n",
        "    her_train_val, her_test = train_test_split(\n",
        "        herlev_df, test_size=0.2,\n",
        "        stratify=herlev_df['severity'], random_state=42\n",
        "    )\n",
        "    her_train, her_val = train_test_split(\n",
        "        her_train_val, test_size=0.125,\n",
        "        stratify=her_train_val['severity'], random_state=42\n",
        "    )\n",
        "\n",
        "    # Combine\n",
        "    train_df = pd.concat([sip_train, her_train], ignore_index=True)\n",
        "    val_df = pd.concat([sip_val, her_val], ignore_index=True)\n",
        "    test_df = pd.concat([sip_test, her_test], ignore_index=True)\n",
        "\n",
        "    print(f\"  Train: {len(train_df)}\")\n",
        "    print(f\"  Val:   {len(val_df)}\")\n",
        "    print(f\"  Test:  {len(test_df)}\")\n",
        "\n",
        "    return train_df, val_df, test_df\n",
        "\n",
        "def create_generators(train_df, val_df, test_df):\n",
        "    \"\"\"Create data generators\"\"\"\n",
        "    print(\"\\n[3] Creating generators...\")\n",
        "\n",
        "    train_df['severity_str'] = train_df['severity'].astype(str)\n",
        "    val_df['severity_str'] = val_df['severity'].astype(str)\n",
        "    test_df['severity_str'] = test_df['severity'].astype(str)\n",
        "\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        rotation_range=30,\n",
        "        width_shift_range=0.3,\n",
        "        height_shift_range=0.3,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=True,\n",
        "        zoom_range=0.3,\n",
        "        brightness_range=[0.7, 1.3]\n",
        "    )\n",
        "\n",
        "    val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    train_gen = train_datagen.flow_from_dataframe(\n",
        "        train_df, x_col='image_path', y_col='severity_str',\n",
        "        target_size=(config.IMG_SIZE, config.IMG_SIZE),\n",
        "        batch_size=config.BATCH_SIZE,\n",
        "        class_mode='categorical',  # Changed from 'binary'\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    val_gen = val_test_datagen.flow_from_dataframe(\n",
        "        val_df, x_col='image_path', y_col='severity_str',\n",
        "        target_size=(config.IMG_SIZE, config.IMG_SIZE),\n",
        "        batch_size=config.BATCH_SIZE,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    test_gen = val_test_datagen.flow_from_dataframe(\n",
        "        test_df, x_col='image_path', y_col='severity_str',\n",
        "        target_size=(config.IMG_SIZE, config.IMG_SIZE),\n",
        "        batch_size=config.BATCH_SIZE,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    print(f\"  Train: {len(train_gen)} batches\")\n",
        "    print(f\"  Val:   {len(val_gen)} batches\")\n",
        "    print(f\"  Test:  {len(test_gen)} batches\")\n",
        "\n",
        "    return train_gen, val_gen, test_gen, train_df, val_df, test_df\n",
        "\n",
        "# ============================================================================\n",
        "# BUILD MODEL\n",
        "# ============================================================================\n",
        "\n",
        "def build_multiclass_model():\n",
        "    \"\"\"Build multi-class classification model\"\"\"\n",
        "    print(\"\\n[4] Building model...\")\n",
        "\n",
        "    base_model = VGG16(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        input_shape=(config.IMG_SIZE, config.IMG_SIZE, 3)\n",
        "    )\n",
        "\n",
        "    base_model.trainable = False\n",
        "\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "\n",
        "    # Output layer: 4 classes with softmax\n",
        "    output = Dense(config.NUM_CLASSES, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "    print(f\"  Total params: {model.count_params():,}\")\n",
        "\n",
        "    return model, base_model\n",
        "\n",
        "def get_class_weights(train_df):\n",
        "    \"\"\"Compute class weights\"\"\"\n",
        "    print(\"\\n[5] Computing class weights...\")\n",
        "\n",
        "    labels = train_df['severity'].values\n",
        "    class_weights = compute_class_weight(\n",
        "        'balanced',\n",
        "        classes=np.unique(labels),\n",
        "        y=labels\n",
        "    )\n",
        "\n",
        "    class_weight_dict = dict(enumerate(class_weights))\n",
        "\n",
        "    for i, weight in class_weight_dict.items():\n",
        "        print(f\"  {config.CLASS_NAMES[i]}: {weight:.3f}\")\n",
        "\n",
        "    return class_weight_dict\n",
        "\n",
        "# ============================================================================\n",
        "# TRAIN\n",
        "# ============================================================================\n",
        "\n",
        "def train_model(model, train_gen, val_gen, class_weights):\n",
        "    \"\"\"Train the model\"\"\"\n",
        "    print(\"\\n[6] Training model...\")\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=config.LEARNING_RATE),\n",
        "        loss='categorical_crossentropy',  # Changed from binary_crossentropy\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    callbacks = [\n",
        "        EarlyStopping(patience=15, restore_best_weights=True),\n",
        "        ModelCheckpoint(config.MODEL_PATH, save_best_only=True, monitor='val_accuracy')\n",
        "    ]\n",
        "\n",
        "    history = model.fit(\n",
        "        train_gen,\n",
        "        epochs=config.EPOCHS,\n",
        "        validation_data=val_gen,\n",
        "        callbacks=callbacks,\n",
        "        class_weight=class_weights,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    return history\n",
        "\n",
        "# ============================================================================\n",
        "# EVALUATE\n",
        "# ============================================================================\n",
        "\n",
        "def evaluate_model(model, test_gen, test_df):\n",
        "    \"\"\"Evaluate model\"\"\"\n",
        "    print(\"\\n[7] Evaluating model...\")\n",
        "\n",
        "    # Predict\n",
        "    predictions = model.predict(test_gen, verbose=1)\n",
        "    y_pred = np.argmax(predictions, axis=1)\n",
        "    y_true = test_df['severity'].values\n",
        "\n",
        "    # Classification report\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"CLASSIFICATION REPORT\")\n",
        "    print(\"=\" * 80)\n",
        "    print(classification_report(y_true, y_pred, target_names=config.CLASS_NAMES))\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=config.CLASS_NAMES,\n",
        "                yticklabels=config.CLASS_NAMES)\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.title('Confusion Matrix - Multi-Class Classification')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'{config.OUTPUT_DIR}/confusion_matrix.png', dpi=150)\n",
        "    print(f\"\\nSaved confusion matrix to {config.OUTPUT_DIR}/confusion_matrix.png\")\n",
        "    plt.close()\n",
        "\n",
        "    # Accuracy per class\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"PER-CLASS ACCURACY\")\n",
        "    print(\"=\" * 80)\n",
        "    for i, class_name in enumerate(config.CLASS_NAMES):\n",
        "        mask = y_true == i\n",
        "        if mask.sum() > 0:\n",
        "            accuracy = (y_pred[mask] == i).sum() / mask.sum()\n",
        "            print(f\"  {class_name}: {accuracy*100:.2f}%\")\n",
        "\n",
        "    return y_true, y_pred, predictions\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN\n",
        "# ============================================================================\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main training pipeline\"\"\"\n",
        "\n",
        "    if not os.path.exists(config.COMBINED_CSV):\n",
        "        print(f\"Error: {config.COMBINED_CSV} not found!\")\n",
        "        print(\"Run the combined dataset creation script first.\")\n",
        "        return\n",
        "\n",
        "    # Load data\n",
        "    df = load_and_map_data(config.COMBINED_CSV)\n",
        "\n",
        "    # Split\n",
        "    train_df, val_df, test_df = split_data(df)\n",
        "\n",
        "    # Generators\n",
        "    train_gen, val_gen, test_gen, train_df, val_df, test_df = create_generators(\n",
        "        train_df, val_df, test_df\n",
        "    )\n",
        "\n",
        "    # Build model\n",
        "    model, base_model = build_multiclass_model()\n",
        "\n",
        "    # Class weights\n",
        "    class_weights = get_class_weights(train_df)\n",
        "\n",
        "    # Train\n",
        "    history = train_model(model, train_gen, val_gen, class_weights)\n",
        "\n",
        "    # Evaluate\n",
        "    y_true, y_pred, predictions = evaluate_model(model, test_gen, test_df)\n",
        "\n",
        "    # Save\n",
        "    print(f\"\\nModel saved to: {config.MODEL_PATH}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"TRAINING COMPLETE!\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"\\nModel: {config.MODEL_PATH}\")\n",
        "    print(f\"Classes: {config.NUM_CLASSES}\")\n",
        "    print(f\"  0: {config.CLASS_NAMES[0]}\")\n",
        "    print(f\"  1: {config.CLASS_NAMES[1]}\")\n",
        "    print(f\"  2: {config.CLASS_NAMES[2]}\")\n",
        "    print(f\"  3: {config.CLASS_NAMES[3]}\")\n",
        "    print(\"\\nUse this model with the multi-class API!\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gkVdFghvDm2k",
        "outputId": "7ee36591-9632-4f88-b0d7-6cfb65f08362"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "MULTI-CLASS CERVICAL CANCER CLASSIFICATION\n",
            "================================================================================\n",
            "Classes: 4\n",
            "  0: Normal\n",
            "  1: Mild Abnormality\n",
            "  2: Moderate Abnormality\n",
            "  3: Severe/Cancer\n",
            "================================================================================\n",
            "\n",
            "[1] Loading and mapping data...\n",
            "\n",
            "Dataset Statistics:\n",
            "  Total samples: 1809\n",
            "\n",
            "  By Severity:\n",
            "    Normal: 565 (31.2%)\n",
            "    Mild Abnormality: 405 (22.4%)\n",
            "    Moderate Abnormality: 492 (27.2%)\n",
            "    Severe/Cancer: 347 (19.2%)\n",
            "\n",
            "  By Dataset:\n",
            "    sipakmed: 966\n",
            "    herlev: 843\n",
            "\n",
            "[2] Splitting data...\n",
            "  Train: 1264\n",
            "  Val:   182\n",
            "  Test:  363\n",
            "\n",
            "[3] Creating generators...\n",
            "Found 0 validated image filenames belonging to 0 classes.\n",
            "Found 0 validated image filenames belonging to 0 classes.\n",
            "Found 0 validated image filenames belonging to 0 classes.\n",
            "  Train: 0 batches\n",
            "  Val:   0 batches\n",
            "  Test:  0 batches\n",
            "\n",
            "[4] Building model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/legacy/preprocessing/image.py:920: UserWarning: Found 1264 invalid image filename(s) in x_col=\"image_path\". These filename(s) will be ignored.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/legacy/preprocessing/image.py:920: UserWarning: Found 182 invalid image filename(s) in x_col=\"image_path\". These filename(s) will be ignored.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/legacy/preprocessing/image.py:920: UserWarning: Found 363 invalid image filename(s) in x_col=\"image_path\". These filename(s) will be ignored.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "  Total params: 15,146,180\n",
            "\n",
            "[5] Computing class weights...\n",
            "  Normal: 0.802\n",
            "  Mild Abnormality: 1.113\n",
            "  Moderate Abnormality: 0.919\n",
            "  Severe/Cancer: 1.306\n",
            "\n",
            "[6] Training model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The PyDataset has length 0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2125030725.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-2125030725.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m     \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m     \u001b[0;31m# Evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2125030725.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_gen, val_gen, class_weights)\u001b[0m\n\u001b[1;32m    285\u001b[0m     ]\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m     history = model.fit(\n\u001b[0m\u001b[1;32m    288\u001b[0m         \u001b[0mtrain_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py\u001b[0m in \u001b[0;36mget_tf_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    293\u001b[0m             ]\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The PyDataset has length 0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_adapter_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The PyDataset has length 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_G5WKlkxQn74"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}